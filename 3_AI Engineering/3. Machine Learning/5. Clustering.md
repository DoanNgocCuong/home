■ Cluster Analysis: Basic Concepts
■ Partitioning Methods
■ Hierarchical Methods
■ Density-Based Methods
■ Grid-Based Methods
■ Evaluation of Clustering


# 3. Hierachical Methods

Distance between Clusters

■ Single link: smallest distance between an element in one cluster and
an element in the other, i.e., dist(Ki, Kj) = min(tip, tjq)
■ Complete link: largest distance between an element in one cluster and
an element in the other, i.e., dist(Ki, Kj) = max(tip, tjq)
■ Average: avg distance between an element in one cluster and an
element in the other, i.e., dist(Ki, Kj) = avg(tip, tjq)
■ Centroid: distance between the centroids of two clusters, i.e., dist(Ki,
Kj) = dist(Ci, Cj)
■ Medoid: distance between the medoids of two clusters, i.e., dist(Ki, Kj)
= dist(Mi, Mj)
■ Medoid: a chosen, centrally located object in the cluster


Centroid, Radius and Diameter of a
Cluster (for numerical data sets)
■ Centroid: the “middle” of a cluster

■ Radius: square root of average distance from any
point of the cluster to its centroid

■ Diameter: square root of average mean squared
distance between all pairs of points in the cluster


# 

Dưới đây là bảng so sánh và giải thích đơn giản về các khái niệm cho học sinh cấp 2:

---

### **So sánh các cách đo khoảng cách giữa các cụm**

|**Phương pháp**|**Định nghĩa đơn giản**|**Ưu điểm**|**Nhược điểm**|
|---|---|---|---|
|**Single Link**|Khoảng cách **ngắn nhất** giữa 2 điểm, một từ mỗi cụm.|Tốt cho cụm có hình dạng kéo dài.|Nhạy cảm với nhiễu, dễ tạo cụm dạng chuỗi.|
|**Complete Link**|Khoảng cách **dài nhất** giữa 2 điểm, một từ mỗi cụm.|Tạo cụm nhỏ gọn, rõ ràng.|Bỏ qua mối liên kết dạng chuỗi giữa các cụm.|
|**Average**|**Trung bình** khoảng cách giữa tất cả các cặp điểm, một từ mỗi cụm.|Cân bằng giữa Single và Complete Link.|Có thể chậm với dữ liệu lớn.|
|**Centroid**|Khoảng cách giữa **trọng tâm** (điểm trung bình) của 2 cụm.|Dễ tính toán với cụm hình tròn.|Không hiệu quả nếu cụm không đối xứng.|
|**Medoid**|Khoảng cách giữa **điểm trung tâm** nhất trong mỗi cụm (giống centroid nhưng dùng điểm thật).|Ít bị ảnh hưởng bởi ngoại lệ hơn centroid.|Khó tính toán khi dữ liệu lớn.|

---

### **So sánh các tính chất của một cụm**

| **Thuật ngữ** | **Định nghĩa đơn giản**                                                     | **Cách tính**                                                     | **Ý nghĩa thực tế**                      |
| ------------- | --------------------------------------------------------------------------- | ----------------------------------------------------------------- | ---------------------------------------- |
| **Centroid**  | **Trọng tâm cụm** – điểm ở giữa, đại diện cho cụm.                          | Lấy trung bình tất cả các tọa độ của các điểm trong cụm.          | Cho biết vị trí trung tâm của cụm.       |
| **Radius**    | **Bán kính** – khoảng cách trung bình từ các điểm trong cụm đến trọng tâm.  | $\sqrt{\text{Trung bình các khoảng cách từ điểm đến trọng tâm}}$. | Đo độ chặt chẽ của cụm so với trọng tâm. |
| **Diameter**  | **Đường kính** – khoảng cách trung bình giữa tất cả các cặp điểm trong cụm. | $\sqrt{\text{Trung bình các khoảng cách giữa mọi cặp điểm}}$.     | Đo độ lớn và trải dài của cụm.           |

---

### **Ví dụ minh họa:**

Giả sử có 4 điểm trong cụm: A(1,1)A(1,1), B(2,2)B(2,2), C(3,3)C(3,3), D(4,4)D(4,4):

1. **Centroid**: Lấy trung bình tọa độ:
    
    Centroid=(1+2+3+44,1+2+3+44)=(2.5,2.5)\text{Centroid} = \left( \frac{1+2+3+4}{4}, \frac{1+2+3+4}{4} \right) = (2.5, 2.5)
2. **Radius**: Tính khoảng cách từ từng điểm đến centroid rồi lấy trung bình.
    
    Radius=Trung bıˋnh caˊc khoảng caˊch từ điểm đeˆˊn (2.5, 2.5)\text{Radius} = \sqrt{\text{Trung bình các khoảng cách từ điểm đến (2.5, 2.5)}}
3. **Diameter**: Tính khoảng cách giữa mọi cặp điểm, rồi lấy trung bình.
    
    Diameter=Trung bıˋnh caˊc khoảng caˊch giữa A, B, C, D\text{Diameter} = \sqrt{\text{Trung bình các khoảng cách giữa A, B, C, D}}

---

Cách giải thích này có dễ hiểu không? Nếu cần minh họa thêm bằng đồ thị, mình có thể giúp nhé! 😊


# 4. Density-Based Clustering Methods

### **Ví dụ thực tế: Clustering dựa trên mật độ**

Hãy tưởng tượng bạn đang ở trong một công viên, nơi mọi người tụ tập thành các nhóm trò chuyện. Nhiệm vụ của bạn là tìm ra các nhóm (cụm) dựa trên khoảng cách giữa mọi người.

---

### **Giả định**:

1. **Eps (Epsilon)**:
    
    - Bạn định nghĩa "người gần nhau" là khi họ đứng cách nhau **≤ 2 mét**.
2. **MinPts (Minimum Points)**:
    
    - Một nhóm được gọi là **cụm** nếu có ít nhất **4 người đứng gần nhau**.

---

### **Cách hoạt động**:

#### **Bước 1**: Xác định một người bất kỳ

Bạn chọn một người tên **Anna** và bắt đầu kiểm tra những người đứng trong bán kính **2 mét** xung quanh Anna.

- Nếu Anna có ít nhất **3 người bạn đứng gần cô ấy** (tổng cộng 4 người, bao gồm cả Anna), cô ấy được coi là **trung tâm của cụm** (điểm lõi).
- Nếu không, Anna không thể bắt đầu một cụm (có thể cô ấy chỉ là một điểm nhiễu).

---

#### **Bước 2**: Mở rộng cụm

Nếu Anna là điểm lõi, bạn tiếp tục kiểm tra những người đứng gần **bạn của Anna** (trong phạm vi 2 mét).

- Nếu bạn của Anna cũng có đủ người gần họ, cụm sẽ được mở rộng ra.
- Nếu không, họ chỉ là **điểm biên**, nhưng vẫn thuộc cụm của Anna.

---

#### **Bước 3**: Loại bỏ người đứng một mình

Một người như **John**, đứng một mình cách xa mọi người hơn 2 mét, sẽ bị coi là **nhiễu**. Anh ấy không thuộc cụm nào cả.

---

### **Ví dụ minh họa trực quan**:

1. **Anna**:
    
    - Có 4 người đứng trong vòng 2 mét → Anna là **điểm lõi**.
    - Anna và những người gần cô ấy tạo thành **một cụm**.
2. **John**:
    
    - Không có ai trong vòng 2 mét → John là **nhiễu**.
3. **Lisa**:
    
    - Chỉ có 2 người gần cô ấy, nhưng lại nằm gần cụm của Anna → Lisa là **điểm biên**, thuộc cụm của Anna.

---

### **Kết quả cuối cùng**:

- Công viên được chia thành các cụm dựa trên nhóm người đứng gần nhau.
- Những người đứng riêng lẻ không thuộc cụm nào và được coi là nhiễu.

---

### **Ý nghĩa thực tế**

Cách này rất hữu ích trong việc phát hiện:

- Các nhóm dữ liệu có hình dạng bất kỳ (giống như nhóm người đứng rải rác).
- Loại bỏ "nhiễu" – những dữ liệu không có ý nghĩa (như John đứng một mình).

---

Nếu cần minh họa bằng hình vẽ (như sơ đồ các điểm trong công viên), mình sẽ hỗ trợ thêm nhé! 😊


### **Clustering dựa trên mật độ (Density-Based Clustering) – Giải thích dễ hiểu**

---

### **Khái niệm cơ bản**

Clustering dựa trên mật độ là cách nhóm các điểm dữ liệu thành cụm dựa vào **mật độ các điểm gần nhau**.

- Nếu có nhiều điểm gần nhau → Tạo thành một cụm.
- Nếu một điểm nằm ở nơi ít hoặc không có điểm xung quanh → Được coi là nhiễu (không thuộc cụm nào).

---

### **2 tham số quan trọng**

1. **Eps (Epsilon)**:
    
    - **Bán kính**: Xác định khoảng cách gần nhất để xét một điểm thuộc vùng lân cận.
    - Ví dụ: Nếu Eps=1 cmEps = 1 \, \text{cm}Eps=1cm, hai điểm cách nhau ≤ 1 cm được coi là "gần nhau".
2. **MinPts (Minimum Points)**:
    
    - **Số điểm tối thiểu**: Cần có trong vùng lân cận để tạo thành cụm.
    - Ví dụ: Nếu MinPts=5MinPts = 5MinPts=5, phải có ít nhất 5 điểm trong vùng lân cận thì cụm mới được tạo.

---

### **Các loại điểm**

1. **Điểm lõi (Core Point)**:
    
    - Là điểm **nằm trong vùng Eps** và có ít nhất **MinPts điểm lân cận**.
    - Ví dụ: Điểm AAA có 5 điểm khác trong vòng 1 cm → Điểm AAA là điểm lõi.
2. **Điểm biên (Border Point)**:
    
    - Là điểm **nằm trong vùng Eps của một điểm lõi**, nhưng không có đủ MinPts để tự thành lõi.
    - Ví dụ: Điểm BBB chỉ có 2 điểm xung quanh nhưng gần một điểm lõi AAA.
3. **Điểm nhiễu (Noise Point)**:
    
    - Là điểm không thuộc cụm nào cả.
    - Ví dụ: Điểm CCC không gần điểm lõi nào và không có đủ điểm xung quanh.

---

### **Cách hoạt động**

1. Chọn một điểm bất kỳ trong dữ liệu.
2. Tìm các điểm xung quanh nó trong vùng Eps.
3. Kiểm tra:
    - Nếu có đủ **MinPts**, điểm đó là **điểm lõi**, bắt đầu cụm mới.
    - Nếu không đủ, kiểm tra xem nó có phải **điểm biên** hay **nhiễu**.
4. Tiếp tục mở rộng cụm từ các điểm lõi bằng cách kết nối chúng qua các điểm lân cận.
5. Kết thúc khi tất cả điểm đã được kiểm tra.

---

### **Ví dụ minh họa**

- **Giả sử**:
    - Eps=2 cmEps = 2 \, \text{cm}Eps=2cm.
    - MinPts=4MinPts = 4MinPts=4.

1. **Bước 1**: Bắt đầu với điểm AAA, tìm tất cả các điểm cách A≤2 cmA \leq 2 \, \text{cm}A≤2cm.
    
    - Nếu có **ít nhất 4 điểm** trong vùng này, AAA là điểm lõi và cụm bắt đầu.
2. **Bước 2**: Tiếp tục mở rộng cụm từ AAA, tìm các điểm lân cận khác.
    
3. **Bước 3**: Nếu có điểm nào không thuộc cụm nào và không đủ lân cận → Đó là nhiễu.
    

---

### **Ưu điểm**

- Tìm được các cụm có hình dạng bất kỳ (không cần là hình tròn).
- Loại bỏ được các điểm nhiễu (không làm rối cụm).

### **Nhược điểm**

- Cần chọn EpsEpsEps và MinPtsMinPtsMinPts phù hợp, nếu không cụm có thể không chính xác.

---

Hy vọng giải thích này dễ hiểu hơn! Nếu cần minh họa bằng hình, mình sẽ thêm nhé. 😊

4o

##### You said:

giải thích qua 1 ví dụ đơn giản dễ hiểu thực tế trực quan

###### ChatGPT said:

ChatGPT

### **Ví dụ thực tế: Clustering dựa trên mật độ**

Hãy tưởng tượng bạn đang ở trong một công viên, nơi mọi người tụ tập thành các nhóm trò chuyện. Nhiệm vụ của bạn là tìm ra các nhóm (cụm) dựa trên khoảng cách giữa mọi người.

---

### **Giả định**:

1. **Eps (Epsilon)**:
    
    - Bạn định nghĩa "người gần nhau" là khi họ đứng cách nhau **≤ 2 mét**.
2. **MinPts (Minimum Points)**:
    
    - Một nhóm được gọi là **cụm** nếu có ít nhất **4 người đứng gần nhau**.

---

### **Cách hoạt động**:

#### **Bước 1**: Xác định một người bất kỳ

Bạn chọn một người tên **Anna** và bắt đầu kiểm tra những người đứng trong bán kính **2 mét** xung quanh Anna.

- Nếu Anna có ít nhất **3 người bạn đứng gần cô ấy** (tổng cộng 4 người, bao gồm cả Anna), cô ấy được coi là **trung tâm của cụm** (điểm lõi).
- Nếu không, Anna không thể bắt đầu một cụm (có thể cô ấy chỉ là một điểm nhiễu).

---

#### **Bước 2**: Mở rộng cụm

Nếu Anna là điểm lõi, bạn tiếp tục kiểm tra những người đứng gần **bạn của Anna** (trong phạm vi 2 mét).

- Nếu bạn của Anna cũng có đủ người gần họ, cụm sẽ được mở rộng ra.
- Nếu không, họ chỉ là **điểm biên**, nhưng vẫn thuộc cụm của Anna.

---

#### **Bước 3**: Loại bỏ người đứng một mình

Một người như **John**, đứng một mình cách xa mọi người hơn 2 mét, sẽ bị coi là **nhiễu**. Anh ấy không thuộc cụm nào cả.

---

### **Ví dụ minh họa trực quan**:

1. **Anna**:
    
    - Có 4 người đứng trong vòng 2 mét → Anna là **điểm lõi**.
    - Anna và những người gần cô ấy tạo thành **một cụm**.
2. **John**:
    
    - Không có ai trong vòng 2 mét → John là **nhiễu**.
3. **Lisa**:
    
    - Chỉ có 2 người gần cô ấy, nhưng lại nằm gần cụm của Anna → Lisa là **điểm biên**, thuộc cụm của Anna.

---

### **Kết quả cuối cùng**:

- Công viên được chia thành các cụm dựa trên nhóm người đứng gần nhau.
- Những người đứng riêng lẻ không thuộc cụm nào và được coi là nhiễu.

---

### **Ý nghĩa thực tế**

Cách này rất hữu ích trong việc phát hiện:

- Các nhóm dữ liệu có hình dạng bất kỳ (giống như nhóm người đứng rải rác).
- Loại bỏ "nhiễu" – những dữ liệu không có ý nghĩa (như John đứng một mình).

---

Nếu cần minh họa bằng hình vẽ (như sơ đồ các điểm trong công viên), mình sẽ hỗ trợ thêm nhé! 😊

4o

##### You said:

Density-Based Clustering: Basic Concepts Density-Reachable and Density- Connected nói về toán học, so sánh nhanh các thuật toán này

###### ChatGPT said:

ChatGPT

### **Density-Based Clustering: Density-Reachable và Density-Connected**

Trong các thuật toán clustering dựa trên mật độ như DBSCAN, các khái niệm **density-reachable** và **density-connected** là cốt lõi để xác định mối quan hệ giữa các điểm dữ liệu. Hãy xem chi tiết:

---

### **1. Density-Reachable (Mật độ khả đạt)**

- **Định nghĩa**: Một điểm ppp được gọi là **density-reachable** từ điểm qqq nếu:
    
    1. qqq là một **core point** (điểm lõi), nghĩa là vùng lân cận EpsEpsEps-neighborhood của qqq có ít nhất MinPtsMinPtsMinPts điểm.
    2. ppp nằm trong vùng EpsEpsEps-neighborhood của qqq.
- **Mở rộng**: Nếu ppp không trực tiếp nằm trong vùng EpsEpsEps-neighborhood của qqq, nó vẫn có thể được gọi là density-reachable từ qqq nếu tồn tại một chuỗi các core points [q1,q2,...,qn][q_1, q_2, ..., q_n][q1​,q2​,...,qn​] sao cho qiq_iqi​ và qi+1q_{i+1}qi+1​ là trực tiếp density-reachable.
    
- **Ví dụ toán học**:
    
    NEps(q)={p∈D ∣ dist(p,q)≤Eps}\text{NEps}(q) = \{ p \in D \, | \, \text{dist}(p, q) \leq Eps \}NEps(q)={p∈D∣dist(p,q)≤Eps}
    
    Nếu p∈NEps(q)p \in \text{NEps}(q)p∈NEps(q) và qqq là core point, thì ppp density-reachable từ qqq.
    

---

### **2. Density-Connected (Mật độ kết nối)**

- **Định nghĩa**: Hai điểm ppp và qqq được gọi là **density-connected** nếu:
    
    1. Có một điểm trung gian ooo (core point) sao cho:
        - ppp là density-reachable từ ooo.
        - qqq cũng là density-reachable từ ooo.
- **Ý nghĩa**: Density-connected dùng để liên kết hai điểm không trực tiếp gần nhau nhưng nằm trong cùng một cụm thông qua các core points.
    
- **Ví dụ toán học**: Nếu ppp density-reachable từ ooo và qqq density-reachable từ ooo, thì ppp và qqq density-connected.
    

---

### **So sánh nhanh các thuật toán Density-Based**

|**Thuật toán**|**Đặc điểm chính**|**Ưu điểm**|**Nhược điểm**|
|---|---|---|---|
|**DBSCAN**|- Dựa trên EpsEpsEps và MinPtsMinPtsMinPts.  <br>- Phân cụm dựa trên mật độ và loại bỏ nhiễu.|- Tìm cụm hình dạng bất kỳ.  <br>- Xử lý nhiễu hiệu quả.  <br>- Một lần quét dữ liệu.|- Nhạy cảm với việc chọn EpsEpsEps và MinPtsMinPtsMinPts.  <br>- Không tốt với cụm mật độ không đồng đều.|
|**OPTICS**|- Giống DBSCAN nhưng cho phép cụm mật độ không đồng đều.  <br>- Phân cấp các cụm.|- Xử lý tốt dữ liệu có mật độ không đồng đều.  <br>- Không cần cố định EpsEpsEps.|- Khó chọn ngưỡng để cắt cụm.  <br>- Phức tạp hơn DBSCAN.|
|**DENCLUE**|- Sử dụng hàm mật độ toán học (hàm kernel) để định nghĩa cụm.|- Độ chính xác cao.  <br>- Hiệu quả với dữ liệu lớn.|- Cần thiết lập đúng tham số kernel.  <br>- Khó hiểu hơn DBSCAN.|
|**CLIQUE**|- Kết hợp phương pháp dựa trên lưới và mật độ để tìm cụm.|- Tìm được cụm đa chiều.  <br>- Tốt cho dữ liệu lớn.|- Độ chính xác giảm với dữ liệu không phân bố đều.  <br>- Kém hiệu quả với dữ liệu phức tạp.|

---

### **So sánh Density-Reachable và Density-Connected**

|**Khái niệm**|**Ý nghĩa toán học**|**Ứng dụng**|
|---|---|---|
|**Density-Reachable**|ppp density-reachable từ qqq nếu tồn tại chuỗi các core points kết nối ppp và qqq.|Phát hiện cụm từ một điểm lõi.|
|**Density-Connected**|ppp và qqq density-connected nếu có một điểm lõi ooo kết nối cả ppp và qqq.|Xác định liệu hai điểm thuộc cùng cụm hay không.|

---

Nếu bạn cần thêm minh họa hoặc ví dụ trực quan, mình sẽ hỗ trợ thêm! 😊

4o

##### You said:

```
DBSCAN: Density-Based Spatial 
Clustering of Applications with Noise
■ Relies on a density-based notion of cluster: A cluster
is defined as a maximal set of density-connected
points
■ Discovers clusters of arbitrary shape in spatial
databases with noise

Core
Border

Outlier

Eps = 1cm
MinPts = 5

32

32

25/09/2024

17

DBSCAN: Sensitive to Parameters

33

33

OPTICS: A Cluster-Ordering Method

(1999)

■ OPTICS: Ordering Points To Identify the Clustering Structure
■ Ankerst, Breunig, Kriegel, and Sander (SIGMOD’99)

■ Produces a special order of the database wrt its density-
based clustering structure

■ This cluster-ordering contains info equiv to the density-based
clusterings corresponding to a broad range of parameter
settings
■ Good for both automatic and interactive cluster analysis,
including finding intrinsic clustering structure
■ Can be represented graphically or using visualization
techniques
```

Giải thích 1 cách dễ hiểu trực quan 4 methods dưới dạng bảng

###### ChatGPT said:

ChatGPT

### **Bảng So Sánh 4 Phương Pháp Clustering Dựa Trên Mật Độ**

|**Thuật toán**|**Đặc điểm chính**|**Ưu điểm**|**Nhược điểm**|**Ví dụ thực tế**|
|---|---|---|---|---|
|**DBSCAN**|- Dựa trên tham số EpsEpsEps (bán kính lân cận) và MinPtsMinPtsMinPts (số điểm tối thiểu).|- Tìm cụm có hình dạng bất kỳ.  <br>- Loại bỏ nhiễu hiệu quả.  <br>- Phân cụm nhanh.|- Nhạy cảm với việc chọn EpsEpsEps và MinPtsMinPtsMinPts.  <br>- Không tốt với cụm có mật độ không đồng đều.|Nhóm các ngôi nhà gần nhau thành khu dân cư.|
|**OPTICS**|- Cải tiến DBSCAN, hỗ trợ cụm với mật độ không đồng đều.  <br>- Sắp xếp điểm dựa trên mật độ.|- Tìm cụm với mật độ thay đổi.  <br>- Không cần cố định EpsEpsEps.  <br>- Phân cấp cụm dễ dàng.|- Khó xác định ngưỡng cắt cụm từ kết quả.  <br>- Chậm hơn DBSCAN với dữ liệu lớn.|Xếp các quầy hàng gần nhau ở chợ với mật độ khác nhau.|
|**DENCLUE**|- Dùng hàm mật độ liên tục (hàm kernel) để xác định cụm.|- Chính xác cao.  <br>- Tìm cụm với dữ liệu lớn, phức tạp.|- Khó thiết lập tham số kernel.  <br>- Không trực quan như DBSCAN.|Phân cụm khách hàng dựa trên hành vi mua sắm.|
|**CLIQUE**|- Kết hợp clustering theo mật độ và lưới (grid-based).|- Tìm cụm tốt trong không gian nhiều chiều.  <br>- Hiệu quả với dữ liệu lớn.|- Hiệu quả giảm khi dữ liệu không đều hoặc phân tán.|Phân cụm người dùng theo sở thích trên mạng xã hội.|

---

### **So sánh trực quan qua ví dụ DBSCAN**

- **Eps** = 1 cm, **MinPts** = 5:
    - **Core Point (Điểm lõi)**: Một điểm trong vùng EpsEpsEps có ít nhất 5 điểm lân cận.
    - **Border Point (Điểm biên)**: Một điểm nằm gần một điểm lõi nhưng không đủ điểm để tự làm lõi.
    - **Outlier (Điểm nhiễu)**: Một điểm không thuộc cụm nào vì nó cách xa các điểm khác.

**Ví dụ thực tế**:

- **Điểm lõi**: Anna đứng trong một nhóm 5 người gần nhau.
- **Điểm biên**: Lisa đứng cạnh nhóm Anna nhưng không đủ bạn xung quanh.
- **Điểm nhiễu**: John đứng một mình cách xa mọi người.

---

Nếu bạn cần thêm minh họa bằng đồ thị hoặc hình ảnh, mình sẵn sàng hỗ trợ thêm nhé! 😊

4o

##### You said:

Ví dụ thực tế/ví dụ trực quan trong bảng (để so sánh 4 methods với nhau đó)

###### ChatGPT said:

ChatGPT

### **So sánh 4 phương pháp clustering dựa trên mật độ với ví dụ thực tế**

|**Thuật toán**|**Đặc điểm chính**|**Ví dụ thực tế trực quan**|
|---|---|---|
|**DBSCAN**|- Tìm cụm dựa trên mật độ với tham số EpsEpsEps và MinPtsMinPtsMinPts.|**Công viên đông người:** Nhóm những người đứng gần nhau (trong bán kính 2m) thành cụm và loại bỏ người đứng một mình.|
|**OPTICS**|- Cải tiến từ DBSCAN, hỗ trợ cụm có mật độ không đồng đều và phân cụm phân cấp.|**Khu chợ với mật độ thay đổi:** Các quầy hàng ở khu chợ được xếp thành cụm ngay cả khi khoảng cách giữa chúng khác nhau.|
|**DENCLUE**|- Sử dụng hàm mật độ liên tục (hàm kernel) để phát hiện cụm, cho phép cụm mượt mà hơn.|**Phân tích đường giao thông:** Phát hiện các tuyến đường đông đúc dựa trên mật độ xe ở các đoạn đường khác nhau.|
|**CLIQUE**|- Dựa trên lưới (grid) kết hợp mật độ để phát hiện cụm trong không gian nhiều chiều.|**Trung tâm thương mại:** Nhóm các cửa hàng có sản phẩm giống nhau, dù ở các tầng khác nhau trong tòa nhà.|

---

### **Chi tiết ví dụ minh họa**

#### **1. DBSCAN (Công viên đông người)**

- **Eps = 2m**, **MinPts = 5**:
    - Một nhóm người đứng gần nhau trong bán kính 2m với ít nhất 5 người sẽ tạo thành một cụm.
    - Người đứng một mình hoặc cách xa nhóm trên 2m sẽ bị coi là nhiễu.

#### **2. OPTICS (Khu chợ với mật độ thay đổi)**

- Ở một khu chợ, các quầy hàng có thể nằm sát nhau (dày đặc) hoặc cách xa hơn (thưa thớt).
- OPTICS không cần cố định bán kính EpsEpsEps, nên nó vẫn nhóm được các quầy hàng thành cụm dù mật độ khác nhau.

#### **3. DENCLUE (Phân tích đường giao thông)**

- Dùng hàm mật độ liên tục để tìm các đoạn đường đông xe (cụm có mật độ cao).
- Ví dụ: Một đoạn đường có nhiều xe cộ qua lại liên tục sẽ được coi là cụm.

#### **4. CLIQUE (Trung tâm thương mại)**

- Tòa nhà nhiều tầng, mỗi tầng có các cửa hàng khác nhau.
- CLIQUE sử dụng lưới (grid) để tìm cụm, ví dụ: nhóm các cửa hàng bán quần áo ở tầng 1 và tầng 2 vào cùng một cụm.

---

### **Tóm tắt ý nghĩa**

- **DBSCAN**: Tốt cho dữ liệu có mật độ đồng đều, tìm cụm nhanh.
- **OPTICS**: Xử lý dữ liệu có mật độ thay đổi tốt, phát hiện cụm phức tạp.
- **DENCLUE**: Chính xác hơn cho dữ liệu lớn, tìm cụm mượt mà.
- **CLIQUE**: Hiệu quả với không gian nhiều chiều, áp dụng tốt khi dữ liệu được chia thành các ô lưới.

Hy vọng các ví dụ thực tế này giúp bạn hình dung rõ hơn sự khác biệt giữa các phương pháp! 😊

4o

  

SU w


# 5. Gird 

```
Grid-Based Clustering Method
■ Using multi-resolution grid data structure
■ Several interesting methods
■ STING (a STatistical INformation Grid approach) by
Wang, Yang and Muntz (1997)
■ CLIQUE: Agrawal, et al. (SIGMOD’98)
■ Both grid-based and subspace clustering
■ WaveCluster by Sheikholeslami, Chatterjee, and
Zhang (VLDB’98)
■ A multi-resolution clustering approach using
wavelet method

36

36

25/09/2024

19

STING: A Statistical Information Grid

Approach
■ Wang, Yang and Muntz (VLDB’97)
■ The spatial area is divided into rectangular cells
■ There are several levels of cells corresponding to
different levels of resolution

37

37

The STING Clustering Method
■ Each cell at a high level is partitioned into a number of smaller
cells in the next lower level
■ Statistical info of each cell is calculated and stored beforehand
and is used to answer queries
■ Parameters of higher level cells can be easily calculated from
parameters of lower level cell
■ count, mean, s, min, max
■ type of distribution—normal, uniform, etc.
■ Use a top-down approach to answer spatial data queries
■ Start from a pre-selected layer—typically with a small number of
cells
■ For each cell in the current level compute the confidence interval

38

38

25/09/2024

20

STING Algorithm and Its Analysis
■ Remove the irrelevant cells from further consideration
■ When finish examining the current layer, proceed to
the next lower level
■ Repeat this process until the bottom layer is reached
■ Advantages:
■ Query-independent, easy to parallelize, incremental
update
■ O(K), where K is the number of grid cells at the
lowest level
■ Disadvantages:
■ All the cluster boundaries are either horizontal or
vertical, and no diagonal boundary is detected

39

39

40

CLIQUE (Clustering In QUEst)
■ Agrawal, Gehrke, Gunopulos, Raghavan (SIGMOD’98)
■ Automatically identifying subspaces of a high dimensional data
space that allow better clustering than original space
■ CLIQUE can be considered as both density-based and grid-based
■ It partitions each dimension into the same number of equal
length interval

■ It partitions an m-dimensional data space into non-
overlapping rectangular units

■ A unit is dense if the fraction of total data points contained in
the unit exceeds the input model parameter
■ A cluster is a maximal set of connected dense units within a
subspace

40

25/09/2024

21

41

CLIQUE: The Major Steps

■ Partition the data space and find the number of points
that lie inside each cell of the partition.
■ Identify the subspaces that contain clusters using the
Apriori principle
■ Identify clusters
■ Determine dense units in all subspaces of interests
■ Determine connected dense units in all subspaces
of interests.
■ Generate minimal description for the clusters
■ Determine maximal regions that cover a cluster of
connected dense units for each cluster
■ Determination of minimal cover for each cluster
```

| **Phương pháp** | **Đặc điểm chính**                                                                                             | **Ưu điểm**                                                                  | **Nhược điểm**                                                                            | **Ví dụ thực tế trực quan**                                                       |
| --------------- | -------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------- |
| **STING**       | - Sử dụng **lưới đa cấp độ** để chia không gian thành các ô (cell).                                            | - Trả lời truy vấn nhanh.  <br>- Dễ dàng mở rộng và cập nhật dữ liệu.        | - Đường biên cụm chỉ nằm ngang hoặc dọc (không phát hiện đường chéo).                     | **Phân tích bản đồ địa lý:** Nhóm các khu vực địa lý theo mật độ dân cư.          |
| **CLIQUE**      | - Kết hợp clustering dựa trên lưới và mật độ.  <br>- Tìm **subspace (không gian con)** tốt nhất để clustering. | - Tốt với dữ liệu đa chiều.  <br>- Tìm cụm tự động trong các không gian phụ. | - Độ chính xác giảm với dữ liệu không đồng đều hoặc không phân bố rõ ràng.                | **Phân tích giao dịch khách hàng:** Nhóm khách hàng dựa trên các sản phẩm đã mua. |
| **WaveCluster** | - Dùng **phương pháp wavelet** để phát hiện cụm ở nhiều cấp độ phân giải khác nhau.                            | - Phát hiện cụm nhanh chóng.  <br>- Hiệu quả với dữ liệu lớn, nhiễu cao.     | - Yêu cầu kiến thức sâu về wavelet.  <br>- Thực hiện phức tạp hơn so với STING và CLIQUE. | **Phân tích ảnh vệ tinh:** Nhóm các vùng đất với mật độ xây dựng khác nhau.       |


| **Phương pháp** | **Đặc điểm chính**                                                                                             | **Ưu điểm**                                                                  | **Nhược điểm**                                                                            | **Ví dụ thực tế trực quan**                                                       |
| --------------- | -------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------- |
| **STING**       | - Sử dụng **lưới đa cấp độ** để chia không gian thành các ô (cell).                                            | - Trả lời truy vấn nhanh.  <br>- Dễ dàng mở rộng và cập nhật dữ liệu.        | - Đường biên cụm chỉ nằm ngang hoặc dọc (không phát hiện đường chéo).                     | **Phân tích bản đồ địa lý:** Nhóm các khu vực địa lý theo mật độ dân cư.          |
| **CLIQUE**      | - Kết hợp clustering dựa trên lưới và mật độ.  <br>- Tìm **subspace (không gian con)** tốt nhất để clustering. | - Tốt với dữ liệu đa chiều.  <br>- Tìm cụm tự động trong các không gian phụ. | - Độ chính xác giảm với dữ liệu không đồng đều hoặc không phân bố rõ ràng.                | **Phân tích giao dịch khách hàng:** Nhóm khách hàng dựa trên các sản phẩm đã mua. |
| **WaveCluster** | - Dùng **phương pháp wavelet** để phát hiện cụm ở nhiều cấp độ phân giải khác nhau.                            | - Phát hiện cụm nhanh chóng.  <br>- Hiệu quả với dữ liệu lớn, nhiễu cao.     | - Yêu cầu kiến thức sâu về wavelet.  <br>- Thực hiện phức tạp hơn so với STING và CLIQUE. | **Phân tích ảnh vệ tinh:** Nhóm các vùng đất với mật độ xây dựng khác nhau.       |

### **Ví dụ thực tế phân biệt các phương pháp Grid-Based Clustering**

Dưới đây là một kịch bản thực tế áp dụng cả 3 phương pháp **STING**, **CLIQUE**, và **WaveCluster** để thấy rõ sự khác biệt:

---

### **Kịch bản chung: Phân tích cửa hàng bán lẻ**

Một trung tâm thương mại lớn muốn nhóm các cửa hàng dựa trên:

1. **Doanh thu hàng tháng** (trục X).
2. **Số lượng khách ghé thăm mỗi tháng** (trục Y).

Dữ liệu được thể hiện trên đồ thị 2D, mỗi điểm là một cửa hàng, với:

- **Trục X (Doanh thu):** Từ 0 đến 100 triệu đồng.
- **Trục Y (Khách ghé thăm):** Từ 0 đến 10,000 lượt.

---

### **1. STING: Phân tích theo cấp độ lưới**

- **Cách hoạt động**:
    
    - Chia không gian (doanh thu và lượt khách) thành **các ô hình chữ nhật** theo nhiều cấp độ phân giải.
    - **Cấp 1 (cao nhất):** Toàn bộ không gian chia thành 4 ô lớn.
    - **Cấp 2:** Mỗi ô chia nhỏ hơn thành 4 ô con.
    - Tiếp tục đi xuống đến cấp thấp nhất.
    - Các ô có mật độ cửa hàng cao (nhiều điểm) sẽ được giữ lại để tạo cụm.
- **Kết quả**:
    
    - **Cụm 1:** Các cửa hàng trong ô có doanh thu từ 70-100 triệu và 6,000-10,000 lượt khách.
    - **Cụm 2:** Các cửa hàng nhỏ hơn, doanh thu 10-30 triệu, khách ghé thăm 2,000-4,000.
- **Nhược điểm rõ ràng**:
    
    - Các đường biên cụm chỉ thẳng theo trục X hoặc Y, không mượt mà.

---

### **2. CLIQUE: Phân tích đa chiều với subspace**

- **Cách hoạt động**:
    
    - Chia không gian dữ liệu (doanh thu, khách ghé thăm) thành các ô vuông nhỏ bằng nhau.
    - Áp dụng nguyên tắc **Apriori** để xác định các **ô dày đặc** (có nhiều cửa hàng).
    - Kết nối các ô dày đặc trong không gian con (subspace) để tạo cụm.
- **Kết quả**:
    
    - CLIQUE phát hiện rằng chỉ trong **subspace "Khách ghé thăm"**, các cửa hàng có hơn 5,000 lượt khách tạo thành một cụm riêng, bất kể doanh thu.
    - Trong subspace "Doanh thu", các cửa hàng có doanh thu từ 50-100 triệu là một cụm khác.
- **Ưu điểm rõ ràng**:
    
    - Nhận ra mối liên hệ khác biệt trong các **không gian con**, không phụ thuộc toàn bộ dữ liệu.

---

### **3. WaveCluster: Phân tích bằng wavelet**

- **Cách hoạt động**:
    
    - Dùng phương pháp wavelet để phát hiện cụm.
    - Xử lý dữ liệu ở nhiều cấp độ phân giải.
    - Các cụm được phát hiện dựa trên mật độ và hình dạng mượt mà, không bị ràng buộc bởi các ô lưới.
- **Kết quả**:
    
    - Phát hiện cụm mượt mà, chẳng hạn:
        - Một cụm hình elip gồm các cửa hàng có doanh thu cao (>60 triệu) nhưng lượng khách không quá đông (3,000-5,000 lượt).
        - Một cụm khác hình bất kỳ với các cửa hàng nhỏ lẻ.
- **Ưu điểm rõ ràng**:
    
    - Cụm có hình dạng tự nhiên hơn, không bị giới hạn bởi lưới.

---

### **Tóm tắt sự khác biệt qua ví dụ**

|**Phương pháp**|**Kết quả cụm**|**Điểm mạnh**|**Điểm yếu**|
|---|---|---|---|
|**STING**|Nhóm các cửa hàng theo **các ô vuông thẳng hàng**.|Nhanh, dễ hiểu, phù hợp dữ liệu lớn.|Đường biên cụm không mượt, khó phát hiện cụm phức tạp.|
|**CLIQUE**|Nhóm cửa hàng theo các **subspace**: lượt khách cao hoặc doanh thu cao.|Tốt với dữ liệu đa chiều, phát hiện cụm đặc biệt.|Hiệu quả giảm nếu dữ liệu không đồng đều.|
|**WaveCluster**|Nhóm các cửa hàng thành **cụm mượt mà, tự nhiên**, không bị ràng buộc bởi lưới.|Phát hiện cụm phức tạp, hình dạng bất kỳ.|Yêu cầu hiểu biết wavelet, phức tạp hơn STING/CLIQUE.|

---

### **Chọn phương pháp nào?**

- **STING**: Khi bạn cần tốc độ và xử lý dữ liệu lớn (ví dụ: bản đồ mật độ dân cư).
- **CLIQUE**: Khi dữ liệu có nhiều chiều và bạn muốn tìm cụm trong các không gian con (ví dụ: phân tích hành vi khách hàng).
- **WaveCluster**: Khi cụm có hình dạng phức tạp và dữ liệu nhiều nhiễu (ví dụ: phân tích hình ảnh hoặc dữ liệu thiên văn).

Hy vọng ví dụ này giúp bạn phân biệt rõ hơn! Nếu cần minh họa bằng hình, mình sẽ hỗ trợ thêm. 😊


# Evaluation 


### **Đánh Giá Phân Cụm (Clustering Evaluation)**

Việc đánh giá chất lượng của các phân cụm giúp xác định xem các cụm đã được tạo ra có ý nghĩa và phù hợp với dữ liệu hay không. Dưới đây là bảng giải thích các phương pháp và chỉ số đánh giá phân cụm một cách đơn giản và dễ hiểu.

---

#### **1. Xác Định Số Lượng Cụm (Determine the Number of Clusters)**

|**Phương Pháp**|**Mô Tả Đơn Giản**|**Ưu Điểm**|**Nhược Điểm**|
|---|---|---|---|
|**Phương Pháp Kinh Nghiệm (Empirical Method)**|Sử dụng công thức k≈n/2k \approx \sqrt{n}/2 với nn là số điểm dữ liệu. Ví dụ: Với n=200n = 200, k=10k = 10.|Dễ dàng áp dụng khi biết trước số lượng cụm.|Không chính xác cho mọi bộ dữ liệu, chỉ mang tính gợi ý.|
|**Phương Pháp Gập Gối (Elbow Method)**|Vẽ biểu đồ tổng phương sai trong các cụm (Within-Cluster Variance) theo số lượng cụm và tìm "gập gối".|Giúp xác định điểm tối ưu số cụm bằng hình ảnh trực quan.|Đôi khi khó xác định rõ ràng điểm "gập gối".|
|**Phương Pháp Kiểm Định Chéo (Cross Validation Method)**|Chia dữ liệu thành mm phần, dùng m−1m-1 phần để huấn luyện và phần còn lại để kiểm tra chất lượng phân cụm. Lặp lại mm lần và so sánh các chỉ số chất lượng.|Đánh giá chính xác hơn bằng cách kiểm tra trên nhiều tập dữ liệu.|Tốn thời gian và tính toán hơn so với các phương pháp khác.|

---

#### **2. Đo Lường Chất Lượng Phân Cụm (Measuring Clustering Quality)**

|**Loại Đo Lường**|**Mô Tả Đơn Giản**|**Ví Dụ Chỉ Số**|
|---|---|---|
|**Đo Lường Ngoại (External Measures)**|So sánh phân cụm với kiến thức trước đó hoặc "đúng thực" (ground truth). Yêu cầu có nhãn hoặc thông tin bên ngoài.|**Purity**, **F-measure**, **Jaccard Coefficient**|
|**Đo Lường Nội (Internal Measures)**|Đánh giá chất lượng phân cụm dựa trên dữ liệu tự nó, không cần thông tin bên ngoài. Xem xét sự tách biệt và độ gọn của cụm.|**Silhouette Coefficient**, **Within-Cluster Variance**|
|**Đo Lường Tương Quan (Relative Measures)**|So sánh các phân cụm khác nhau với nhau, thường là từ cùng một thuật toán với các tham số khác nhau.|**Davies-Bouldin Index**, **Calinski-Harabasz Index**|

---

#### **3. Các Chỉ Số Đánh Giá Phân Cụm Phổ Biến**

##### **a. Đo Lường Ngoại (External Measures)**

|**Chỉ Số**|**Mô Tả Đơn Giản**|**Ý Nghĩa**|
|---|---|---|
|**Purity**|Tỷ lệ số điểm đúng phân loại trong mỗi cụm so với tổng số điểm trong cụm đó.|Đo lường mức độ "sạch" của các cụm so với nhãn thật.|
|**F-measure**|Trung bình điều hòa giữa độ chính xác (Precision) và độ bao phủ (Recall).|Đánh giá cân bằng giữa chính xác và bao phủ của phân cụm.|
|**Jaccard Coefficient**|Tỷ lệ số điểm chung giữa hai cụm chia cho tổng số điểm trong hai cụm.|Đo lường mức độ tương đồng giữa hai cụm.|
|**Normalized Mutual Information (NMI)**|Đo lường lượng thông tin chung giữa phân cụm và nhãn thật, chuẩn hóa để giá trị từ 0 đến 1.|Đánh giá mức độ tương quan giữa phân cụm và nhãn thật.|

##### **b. Đo Lường Nội (Internal Measures)**

|**Chỉ Số**|**Mô Tả Đơn Giản**|**Ý Nghĩa**|
|---|---|---|
|**Silhouette Coefficient**|Đo lường mức độ tương tự của một điểm với cụm của nó so với các cụm khác. Giá trị từ -1 đến 1, càng cao càng tốt.|Đánh giá sự tách biệt và gọn gàng của cụm.|
|**Within-Cluster Variance**|Tổng phương sai của các điểm trong cụm so với trung tâm của cụm.|Đo lường độ gọn gàng của các cụm, càng nhỏ càng tốt.|

##### **c. Đo Lường Tương Quan (Relative Measures)**

|**Chỉ Số**|**Mô Tả Đơn Giản**|**Ý Nghĩa**|
|---|---|---|
|**Davies-Bouldin Index**|Tỷ lệ giữa độ tương đồng của các cụm và sự khác biệt giữa các cụm. Giá trị càng nhỏ càng tốt.|Đánh giá sự tách biệt và gọn gàng của các cụm.|
|**Calinski-Harabasz Index**|Tỷ lệ giữa sự phân tán giữa các cụm và sự phân tán trong các cụm. Giá trị càng cao càng tốt.|Đánh giá mức độ gọn gàng và tách biệt của cụm.|

---

#### **4. Ví Dụ Minh Họa Các Chỉ Số Đánh Giá**

|**Chỉ Số**|**Ví Dụ Thực Tế**|**Giải Thích**|
|---|---|---|
|**Purity**|Giả sử bạn phân cụm các sinh viên theo nhóm học, và mỗi nhóm có chủ yếu là sinh viên cùng ngành. Purity đo lường tỷ lệ sinh viên cùng ngành trong mỗi nhóm.|Nếu một nhóm có 8 sinh viên cùng ngành và 2 sinh viên khác ngành, purity của nhóm đó là 80%.|
|**Silhouette Coefficient**|Trong phân cụm khách hàng, một khách hàng có silhouette cao nghĩa là họ tương tự nhiều hơn với khách hàng trong cùng nhóm hơn là nhóm khác.|Giá trị silhouette = 0.7 cho thấy khách hàng này được phân loại chính xác.|
|**Jaccard Coefficient**|So sánh hai nhóm marketing khác nhau và đo lường số khách hàng chung giữa hai nhóm so với tổng số khách hàng trong cả hai nhóm.|Nếu hai nhóm có 30 khách hàng chung và tổng khách hàng là 100, Jaccard Coefficient = 0.3.|
|**Davies-Bouldin Index**|Đánh giá hai phân cụm: phân cụm A và B. Nếu phân cụm A và B có độ tương đồng cao nhưng tách biệt rõ ràng, chỉ số sẽ thấp.|Với chỉ số Davies-Bouldin = 0.5, phân cụm A và B có sự tách biệt tốt.|

---

#### **5. Tóm Tắt Lợi Ích và Hạn Chế Của Các Chỉ Số Đánh Giá**

|**Loại Đo Lường**|**Lợi Ích**|**Hạn Chế**|
|---|---|---|
|**Ngoại (External)**|Đánh giá chính xác khi có thông tin nhãn thật.|Cần có thông tin bên ngoài, không áp dụng cho dữ liệu không nhãn.|
|**Nội (Internal)**|Không cần thông tin bên ngoài, dễ áp dụng.|Có thể không phản ánh chính xác chất lượng phân cụm thực tế.|
|**Tương Quan (Relative)**|So sánh trực tiếp các phân cụm khác nhau.|Không cung cấp giá trị tuyệt đối về chất lượng phân cụm.|

---

### **Kết Luận**

Việc chọn lựa phương pháp đánh giá phân cụm phù hợp phụ thuộc vào mục tiêu và loại dữ liệu của bạn:

- **Để xác định số lượng cụm**: Sử dụng Elbow Method để có cái nhìn trực quan hoặc Cross Validation Method để đánh giá chính xác hơn.
- **Để đánh giá chất lượng phân cụm**: Kết hợp các chỉ số nội và ngoại để có cái nhìn toàn diện về sự gọn gàng và tính chính xác của các cụm.
- **Đối với dữ liệu có nhãn**: Sử dụng External Measures như Purity hoặc NMI để so sánh với nhãn thật.
- **Đối với dữ liệu không nhãn**: Sử dụng Internal Measures như Silhouette Coefficient để đánh giá sự tách biệt và gọn gàng của các cụm.

Hy vọng bảng giải thích này giúp bạn hiểu rõ hơn về các phương pháp và chỉ số đánh giá phân cụm! Nếu cần thêm thông tin hoặc ví dụ cụ thể, hãy cho mình biết nhé! 😊



### **Các Chỉ Số Đánh Giá Phân Cụm Ngoại (External Measures)**

Để đánh giá chất lượng của phân cụm, **External Measures** so sánh kết quả phân cụm với các nhãn (labels) thật hoặc kiến thức trước đó. Dưới đây là bảng giải thích các chỉ số phổ biến trong nhóm này một cách đơn giản và dễ hiểu:

---

#### **1. Matching-Based Measures**

|**Chỉ Số**|**Mô Tả Đơn Giản**|**Ý Nghĩa**|
|---|---|---|
|**Purity**|Đo lường tỷ lệ các điểm dữ liệu trong mỗi cụm thuộc về một lớp thực sự nhất định.|Đánh giá mức độ "sạch" của các cụm so với nhãn thật.|
|**Maximum Matching**|Tìm cách ghép các cụm với các lớp thật sao cho số điểm được ghép tối đa.|Đảm bảo ghép cụm với lớp thật sao cho số điểm chính xác nhất.|
|**F-measure**|Trung bình điều hòa giữa độ chính xác (Precision) và độ bao phủ (Recall) của phân cụm so với nhãn thật.|Đánh giá sự cân bằng giữa chính xác và bao phủ của phân cụm.|

---

#### **2. Entropy-Based Measures**

|**Chỉ Số**|**Mô Tả Đơn Giản**|**Ý Nghĩa**|
|---|---|---|
|**Conditional Entropy**|Đo lường lượng thông tin cần thiết để mô tả nhãn thật dựa trên phân cụm hiện tại.|Đánh giá mức độ thông tin mất mát khi phân cụm so với nhãn thật.|
|**Normalized Mutual Information (NMI)**|Đo lường lượng thông tin chung giữa phân cụm và nhãn thật, chuẩn hóa để giá trị từ 0 đến 1.|Đánh giá mức độ tương quan giữa phân cụm và nhãn thật một cách cân bằng.|
|**Variation of Information**|Đo lường sự khác biệt thông tin giữa phân cụm và nhãn thật.|Đánh giá mức độ khác biệt thông tin giữa hai phân hoạch.|

---

#### **3. Pair-Wise Measures**

|**Chỉ Số**|**Mô Tả Đơn Giản**|**Ý Nghĩa**|
|---|---|---|
|**Jaccard Coefficient**|Tỷ lệ số cặp điểm chung giữa hai cụm chia cho tổng số cặp điểm trong hai cụm.|Đo lường mức độ tương đồng giữa hai cụm.|
|**Rand Statistic**|Tỷ lệ số cặp điểm được phân loại giống nhau trong cả hai phân cụm và không giống nhau.|Đánh giá sự tương đồng tổng thể giữa hai phân cụm.|
|**Fowlkes-Mallows Measure**|Trung bình của độ chính xác (Precision) và độ bao phủ (Recall) cho các cặp điểm được phân loại đúng.|Đánh giá sự cân bằng giữa chính xác và bao phủ của phân cụm.|
|**True Positive (TP)**|Số cặp điểm được phân loại đúng vào cùng một cụm.|Phản ánh số lượng cặp điểm được nhóm chính xác.|
|**False Negative (FN)**|Số cặp điểm thuộc cùng một lớp thật nhưng lại bị phân vào các cụm khác nhau.|Phản ánh số lượng cặp điểm bị phân nhầm nhóm.|
|**False Positive (FP)**|Số cặp điểm không thuộc cùng một lớp thật nhưng lại bị phân vào cùng một cụm.|Phản ánh số lượng cặp điểm bị phân nhầm nhóm.|
|**True Negative (TN)**|Số cặp điểm không thuộc cùng một lớp thật và cũng không bị phân vào cùng một cụm.|Phản ánh số lượng cặp điểm được phân loại đúng không nhóm.|

---

#### **4. Correlation Measures**

|**Chỉ Số**|**Mô Tả Đơn Giản**|**Ý Nghĩa**|
|---|---|---|
|**Discretized Huber Statistic**|Đo lường mối tương quan giữa phân cụm và nhãn thật sau khi phân loại dữ liệu thành các khoảng rời rạc.|Đánh giá sự tương quan giữa phân cụm và nhãn thật sau khi xử lý dữ liệu.|
|**Normalized Discretized Huber Statistic**|Chuẩn hóa chỉ số Huber sau khi phân loại dữ liệu thành các khoảng rời rạc để giá trị nằm trong khoảng 0 đến 1.|Cung cấp một thước đo tương quan dễ hiểu và so sánh được giữa các phân cụm.|

---

### **Chi Tiết Các Chỉ Số Đánh Giá Ngoại**

#### **1. Purity**

- **Công thức**: Purity=1N∑kmax⁡j∣Ck∩Lj∣\text{Purity} = \frac{1}{N} \sum_{k} \max_{j} |C_k \cap L_j| Trong đó:
    - NN là tổng số điểm dữ liệu.
    - CkC_k là cụm thứ kk.
    - LjL_j là lớp thật thứ jj.
- **Giải Thích**:
    - Với mỗi cụm, xác định lớp thật có số điểm nhiều nhất trong cụm đó.
    - Tính tỷ lệ số điểm này so với tổng số điểm trong cụm.
- **Ví Dụ**:
    - Giả sử một cụm gồm 8 sinh viên ngành Khoa học Máy tính và 2 sinh viên ngành Toán học.
    - Purity của cụm này là 810=80%\frac{8}{10} = 80\%.

#### **2. F-measure**

- **Công thức**: F-measure=2×Precision×RecallPrecision+RecallF\text{-measure} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}} Trong đó:
    - **Precision**: Tỷ lệ điểm đúng trong phân cụm.
    - **Recall**: Tỷ lệ điểm đúng được phân vào cụm.
- **Giải Thích**:
    - Đánh giá sự cân bằng giữa độ chính xác và độ bao phủ của phân cụm.
- **Ví Dụ**:
    - Nếu Precision = 70% và Recall = 80%, thì F-measure=2×0.7×0.80.7+0.8≈0.746F\text{-measure} = 2 \times \frac{0.7 \times 0.8}{0.7 + 0.8} \approx 0.746 hay 74.6%.

#### **3. Jaccard Coefficient**

- **Công thức**: J(A,B)=∣A∩B∣∣A∪B∣J(A, B) = \frac{|A \cap B|}{|A \cup B|} Trong đó:
    - AA và BB là hai tập hợp cụ thể (ví dụ: hai cụm khác nhau).
- **Giải Thích**:
    - Đo lường tỷ lệ điểm chung giữa hai cụm so với tổng số điểm trong cả hai cụm.
- **Ví Dụ**:
    - Hai cụm có 30 điểm chung và tổng số điểm trong hai cụm là 100.
    - Jaccard Coefficient = 30100=0.3\frac{30}{100} = 0.3.

#### **4. Rand Statistic**

- **Công thức**:
    
    Rand Index=TP+TNTP+TN+FP+FN\text{Rand Index} = \frac{TP + TN}{TP + TN + FP + FN}
- **Giải Thích**:
    
    - Đo lường tỷ lệ cặp điểm được phân loại đúng (cùng cụm hoặc khác cụm giống nhau với nhãn thật).
- **Ví Dụ**:
    
    - Nếu trong tổng số 100 cặp điểm, có 40 TP, 50 TN, 5 FP, và 5 FN.
    - Rand Index = 40+5040+50+5+5=90100=0.9\frac{40 + 50}{40 + 50 + 5 + 5} = \frac{90}{100} = 0.9.

#### **5. Fowlkes-Mallows Measure**

- **Công thức**:
    
    Fowlkes−Mallows=Precision×RecallFowlkes-Mallows = \sqrt{\text{Precision} \times \text{Recall}}
- **Giải Thích**:
    
    - Trung bình điều hòa giữa Precision và Recall cho các cặp điểm được phân loại đúng.
- **Ví Dụ**:
    
    - Nếu Precision = 80% và Recall = 70%, thì Fowlkes−Mallows=0.8×0.7≈0.748Fowlkes-Mallows = \sqrt{0.8 \times 0.7} \approx 0.748 hay 74.8%.

#### **6. Normalized Mutual Information (NMI)**

- **Công thức**: NMI=2×I(C;L)H(C)+H(L)NMI = \frac{2 \times I(C; L)}{H(C) + H(L)} Trong đó:
    - I(C;L)I(C; L) là mutual information giữa phân cụm CC và nhãn thật LL.
    - H(C)H(C) và H(L)H(L) là entropy của phân cụm và nhãn thật.
- **Giải Thích**:
    - Đo lường lượng thông tin chung giữa phân cụm và nhãn thật, chuẩn hóa để giá trị nằm trong khoảng từ 0 đến 1.
- **Ví Dụ**:
    - Nếu NMI = 1, tức là phân cụm hoàn toàn trùng khớp với nhãn thật.
    - Nếu NMI = 0, tức là không có thông tin chung giữa phân cụm và nhãn thật.

#### **7. Davies-Bouldin Index**

- **Công thức**: DB=1K∑i=1Kmax⁡j≠i(Si+Sjd(Ci,Cj))DB = \frac{1}{K} \sum_{i=1}^{K} \max_{j \neq i} \left( \frac{S_i + S_j}{d(C_i, C_j)} \right) Trong đó:
    - SiS_i là độ phân tán của cụm ii.
    - d(Ci,Cj)d(C_i, C_j) là khoảng cách giữa các cụm ii và jj.
- **Giải Thích**:
    - Đo lường tỷ lệ giữa độ tương đồng của các cụm và sự khác biệt giữa các cụm. Giá trị càng nhỏ càng tốt.
- **Ví Dụ**:
    - Với chỉ số DB = 0.5, các cụm có sự tách biệt tốt và độ tương đồng thấp.

#### **8. Calinski-Harabasz Index**

- **Công thức**: CH=Between-Cluster VarianceWithin-Cluster Variance×N−KK−1CH = \frac{\text{Between-Cluster Variance}}{\text{Within-Cluster Variance}} \times \frac{N - K}{K - 1} Trong đó:
    - NN là tổng số điểm dữ liệu.
    - KK là số cụm.
- **Giải Thích**:
    - Đo lường tỷ lệ giữa sự phân tán giữa các cụm và sự phân tán trong các cụm. Giá trị càng cao càng tốt.
- **Ví Dụ**:
    - Với chỉ số CH = 150, phân cụm có sự tách biệt rõ ràng và các cụm đều gọn gàng.

---

### **Tóm Tắt Các Chỉ Số Đánh Giá Ngoại**

|**Loại Đo Lường**|**Chỉ Số**|**Mô Tả Đơn Giản**|**Ý Nghĩa**|
|---|---|---|---|
|**Matching-Based**|Purity, Maximum Matching, F-measure|So sánh các cụm với các lớp thật dựa trên sự trùng khớp của các điểm.|Đánh giá mức độ "sạch" và chính xác của các cụm so với nhãn thật.|
|**Entropy-Based**|Conditional Entropy, NMI, Variation of Information|Đo lường lượng thông tin chung hoặc mất mát giữa phân cụm và nhãn thật.|Đánh giá sự tương quan và khác biệt thông tin giữa phân cụm và nhãn thật.|
|**Pair-Wise**|Jaccard Coefficient, Rand Statistic, Fowlkes-Mallows Measure|So sánh các cặp điểm giữa phân cụm và nhãn thật dựa trên việc phân loại đúng hay sai.|Đánh giá mức độ tương đồng và sự chính xác tổng thể của phân cụm.|
|**Correlation-Based**|Discretized Huber Statistic, Normalized Discretized Huber Statistic|Đo lường mối tương quan giữa phân cụm và nhãn thật sau khi xử lý dữ liệu thành các khoảng rời rạc.|Đánh giá sự tương quan giữa phân cụm và nhãn thật sau khi xử lý dữ liệu.|

---

### **Kết Luận**

Việc lựa chọn chỉ số đánh giá phù hợp phụ thuộc vào mục tiêu và đặc điểm của dữ liệu bạn đang làm việc:

- **Nếu bạn có nhãn thật (ground truth)**:
    - Sử dụng **External Measures** như Purity, NMI, hoặc Rand Statistic để so sánh phân cụm với nhãn thật.
- **Nếu bạn không có nhãn thật**:
    - Sử dụng **Internal Measures** (được giải thích ở phần trước) để đánh giá sự tách biệt và gọn gàng của các cụm.
- **Đối với phân tích chi tiết**:
    - Kết hợp nhiều chỉ số để có cái nhìn toàn diện về chất lượng phân cụm.

Hy vọng bảng giải thích này giúp bạn hiểu rõ hơn về các chỉ số đánh giá phân cụm ngoại! Nếu bạn cần thêm ví dụ hoặc giải thích chi tiết hơn về bất kỳ chỉ số nào, hãy cho mình biết nhé! 😊



### **Các Chỉ Số Đánh Giá Phân Cụm Ngoại (External Measures)**

Để đánh giá chất lượng của phân cụm, **External Measures** so sánh kết quả phân cụm với các nhãn (labels) thật hoặc kiến thức trước đó. Dưới đây là bảng giải thích các chỉ số phổ biến trong nhóm này một cách đơn giản và dễ hiểu:

---

#### **1. Matching-Based Measures**

|**Chỉ Số**|**Mô Tả Đơn Giản**|**Ý Nghĩa**|
|---|---|---|
|**Purity**|Đo lường tỷ lệ các điểm dữ liệu trong mỗi cụm thuộc về một lớp thực sự nhất định.|Đánh giá mức độ "sạch" của các cụm so với nhãn thật.|
|**Maximum Matching**|Tìm cách ghép các cụm với các lớp thật sao cho số điểm được ghép tối đa.|Đảm bảo ghép cụm với lớp thật sao cho số điểm chính xác nhất.|
|**F-measure**|Trung bình điều hòa giữa độ chính xác (Precision) và độ bao phủ (Recall) của phân cụm so với nhãn thật.|Đánh giá sự cân bằng giữa chính xác và bao phủ của phân cụm.|

---

#### **2. Entropy-Based Measures**

|**Chỉ Số**|**Mô Tả Đơn Giản**|**Ý Nghĩa**|
|---|---|---|
|**Conditional Entropy**|Đo lường lượng thông tin cần thiết để mô tả nhãn thật dựa trên phân cụm hiện tại.|Đánh giá mức độ thông tin mất mát khi phân cụm so với nhãn thật.|
|**Normalized Mutual Information (NMI)**|Đo lường lượng thông tin chung giữa phân cụm và nhãn thật, chuẩn hóa để giá trị từ 0 đến 1.|Đánh giá mức độ tương quan giữa phân cụm và nhãn thật một cách cân bằng.|
|**Variation of Information**|Đo lường sự khác biệt thông tin giữa phân cụm và nhãn thật.|Đánh giá mức độ khác biệt thông tin giữa hai phân hoạch.|

---

#### **3. Pair-Wise Measures**

|**Chỉ Số**|**Mô Tả Đơn Giản**|**Ý Nghĩa**|
|---|---|---|
|**Jaccard Coefficient**|Tỷ lệ số cặp điểm chung giữa hai cụm chia cho tổng số cặp điểm trong hai cụm.|Đo lường mức độ tương đồng giữa hai cụm.|
|**Rand Statistic**|Tỷ lệ số cặp điểm được phân loại giống nhau trong cả hai phân cụm và không giống nhau.|Đánh giá sự tương đồng tổng thể giữa hai phân cụm.|
|**Fowlkes-Mallows Measure**|Trung bình của độ chính xác (Precision) và độ bao phủ (Recall) cho các cặp điểm được phân loại đúng.|Đánh giá sự cân bằng giữa chính xác và bao phủ của phân cụm.|
|**True Positive (TP)**|Số cặp điểm được phân loại đúng vào cùng một cụm.|Phản ánh số lượng cặp điểm được nhóm chính xác.|
|**False Negative (FN)**|Số cặp điểm thuộc cùng một lớp thật nhưng lại bị phân vào các cụm khác nhau.|Phản ánh số lượng cặp điểm bị phân nhầm nhóm.|
|**False Positive (FP)**|Số cặp điểm không thuộc cùng một lớp thật nhưng lại bị phân vào cùng một cụm.|Phản ánh số lượng cặp điểm bị phân nhầm nhóm.|
|**True Negative (TN)**|Số cặp điểm không thuộc cùng một lớp thật và cũng không bị phân vào cùng một cụm.|Phản ánh số lượng cặp điểm được phân loại đúng không nhóm.|

---

#### **4. Correlation Measures**

|**Chỉ Số**|**Mô Tả Đơn Giản**|**Ý Nghĩa**|
|---|---|---|
|**Discretized Huber Statistic**|Đo lường mối tương quan giữa phân cụm và nhãn thật sau khi phân loại dữ liệu thành các khoảng rời rạc.|Đánh giá sự tương quan giữa phân cụm và nhãn thật sau khi xử lý dữ liệu.|
|**Normalized Discretized Huber Statistic**|Chuẩn hóa chỉ số Huber sau khi phân loại dữ liệu thành các khoảng rời rạc để giá trị nằm trong khoảng 0 đến 1.|Cung cấp một thước đo tương quan dễ hiểu và so sánh được giữa các phân cụm.|

---

### **Chi Tiết Các Chỉ Số Đánh Giá Ngoại**

#### **1. Purity**

- **Công thức**: Purity=1N∑kmax⁡j∣Ck∩Lj∣\text{Purity} = \frac{1}{N} \sum_{k} \max_{j} |C_k \cap L_j|Purity=N1​k∑​jmax​∣Ck​∩Lj​∣ Trong đó:
    - NNN là tổng số điểm dữ liệu.
    - CkC_kCk​ là cụm thứ kkk.
    - LjL_jLj​ là lớp thật thứ jjj.
- **Giải Thích**:
    - Với mỗi cụm, xác định lớp thật có số điểm nhiều nhất trong cụm đó.
    - Tính tỷ lệ số điểm này so với tổng số điểm trong cụm.
- **Ví Dụ**:
    - Giả sử một cụm gồm 8 sinh viên ngành Khoa học Máy tính và 2 sinh viên ngành Toán học.
    - Purity của cụm này là 810=80%\frac{8}{10} = 80\%108​=80%.

#### **2. F-measure**

- **Công thức**: F-measure=2×Precision×RecallPrecision+RecallF\text{-measure} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}F-measure=2×Precision+RecallPrecision×Recall​ Trong đó:
    - **Precision**: Tỷ lệ điểm đúng trong phân cụm.
    - **Recall**: Tỷ lệ điểm đúng được phân vào cụm.
- **Giải Thích**:
    - Đánh giá sự cân bằng giữa độ chính xác và độ bao phủ của phân cụm.
- **Ví Dụ**:
    - Nếu Precision = 70% và Recall = 80%, thì F-measure=2×0.7×0.80.7+0.8≈0.746F\text{-measure} = 2 \times \frac{0.7 \times 0.8}{0.7 + 0.8} \approx 0.746F-measure=2×0.7+0.80.7×0.8​≈0.746 hay 74.6%.

#### **3. Jaccard Coefficient**

- **Công thức**: J(A,B)=∣A∩B∣∣A∪B∣J(A, B) = \frac{|A \cap B|}{|A \cup B|}J(A,B)=∣A∪B∣∣A∩B∣​ Trong đó:
    - AAA và BBB là hai tập hợp cụ thể (ví dụ: hai cụm khác nhau).
- **Giải Thích**:
    - Đo lường tỷ lệ điểm chung giữa hai cụm so với tổng số điểm trong cả hai cụm.
- **Ví Dụ**:
    - Hai cụm có 30 điểm chung và tổng số điểm trong hai cụm là 100.
    - Jaccard Coefficient = 30100=0.3\frac{30}{100} = 0.310030​=0.3.

#### **4. Rand Statistic**

- **Công thức**:
    
    Rand Index=TP+TNTP+TN+FP+FN\text{Rand Index} = \frac{TP + TN}{TP + TN + FP + FN}Rand Index=TP+TN+FP+FNTP+TN​
- **Giải Thích**:
    
    - Đo lường tỷ lệ cặp điểm được phân loại đúng (cùng cụm hoặc khác cụm giống nhau với nhãn thật).
- **Ví Dụ**:
    
    - Nếu trong tổng số 100 cặp điểm, có 40 TP, 50 TN, 5 FP, và 5 FN.
    - Rand Index = 40+5040+50+5+5=90100=0.9\frac{40 + 50}{40 + 50 + 5 + 5} = \frac{90}{100} = 0.940+50+5+540+50​=10090​=0.9.

#### **5. Fowlkes-Mallows Measure**

- **Công thức**:
    
    Fowlkes−Mallows=Precision×RecallFowlkes-Mallows = \sqrt{\text{Precision} \times \text{Recall}}Fowlkes−Mallows=Precision×Recall​
- **Giải Thích**:
    
    - Trung bình điều hòa giữa Precision và Recall cho các cặp điểm được phân loại đúng.
- **Ví Dụ**:
    
    - Nếu Precision = 80% và Recall = 70%, thì Fowlkes−Mallows=0.8×0.7≈0.748Fowlkes-Mallows = \sqrt{0.8 \times 0.7} \approx 0.748Fowlkes−Mallows=0.8×0.7​≈0.748 hay 74.8%.

#### **6. Normalized Mutual Information (NMI)**

- **Công thức**: NMI=2×I(C;L)H(C)+H(L)NMI = \frac{2 \times I(C; L)}{H(C) + H(L)}NMI=H(C)+H(L)2×I(C;L)​ Trong đó:
    - I(C;L)I(C; L)I(C;L) là mutual information giữa phân cụm CCC và nhãn thật LLL.
    - H(C)H(C)H(C) và H(L)H(L)H(L) là entropy của phân cụm và nhãn thật.
- **Giải Thích**:
    - Đo lường lượng thông tin chung giữa phân cụm và nhãn thật, chuẩn hóa để giá trị nằm trong khoảng từ 0 đến 1.
- **Ví Dụ**:
    - Nếu NMI = 1, tức là phân cụm hoàn toàn trùng khớp với nhãn thật.
    - Nếu NMI = 0, tức là không có thông tin chung giữa phân cụm và nhãn thật.

#### **7. Davies-Bouldin Index**

- **Công thức**: DB=1K∑i=1Kmax⁡j≠i(Si+Sjd(Ci,Cj))DB = \frac{1}{K} \sum_{i=1}^{K} \max_{j \neq i} \left( \frac{S_i + S_j}{d(C_i, C_j)} \right)DB=K1​i=1∑K​j=imax​(d(Ci​,Cj​)Si​+Sj​​) Trong đó:
    - SiS_iSi​ là độ phân tán của cụm iii.
    - d(Ci,Cj)d(C_i, C_j)d(Ci​,Cj​) là khoảng cách giữa các cụm iii và jjj.
- **Giải Thích**:
    - Đo lường tỷ lệ giữa độ tương đồng của các cụm và sự khác biệt giữa các cụm. Giá trị càng nhỏ càng tốt.
- **Ví Dụ**:
    - Với chỉ số DB = 0.5, các cụm có sự tách biệt tốt và độ tương đồng thấp.

#### **8. Calinski-Harabasz Index**

- **Công thức**: CH=Between-Cluster VarianceWithin-Cluster Variance×N−KK−1CH = \frac{\text{Between-Cluster Variance}}{\text{Within-Cluster Variance}} \times \frac{N - K}{K - 1}CH=Within-Cluster VarianceBetween-Cluster Variance​×K−1N−K​ Trong đó:
    - NNN là tổng số điểm dữ liệu.
    - KKK là số cụm.
- **Giải Thích**:
    - Đo lường tỷ lệ giữa sự phân tán giữa các cụm và sự phân tán trong các cụm. Giá trị càng cao càng tốt.
- **Ví Dụ**:
    - Với chỉ số CH = 150, phân cụm có sự tách biệt rõ ràng và các cụm đều gọn gàng.

---

### **Tóm Tắt Các Chỉ Số Đánh Giá Ngoại**

|**Loại Đo Lường**|**Chỉ Số**|**Mô Tả Đơn Giản**|**Ý Nghĩa**|
|---|---|---|---|
|**Matching-Based**|Purity, Maximum Matching, F-measure|So sánh các cụm với các lớp thật dựa trên sự trùng khớp của các điểm.|Đánh giá mức độ "sạch" và chính xác của các cụm so với nhãn thật.|
|**Entropy-Based**|Conditional Entropy, NMI, Variation of Information|Đo lường lượng thông tin chung hoặc mất mát giữa phân cụm và nhãn thật.|Đánh giá sự tương quan và khác biệt thông tin giữa phân cụm và nhãn thật.|
|**Pair-Wise**|Jaccard Coefficient, Rand Statistic, Fowlkes-Mallows Measure|So sánh các cặp điểm giữa phân cụm và nhãn thật dựa trên việc phân loại đúng hay sai.|Đánh giá mức độ tương đồng và sự chính xác tổng thể của phân cụm.|
|**Correlation-Based**|Discretized Huber Statistic, Normalized Discretized Huber Statistic|Đo lường mối tương quan giữa phân cụm và nhãn thật sau khi xử lý dữ liệu thành các khoảng rời rạc.|Đánh giá sự tương quan giữa phân cụm và nhãn thật sau khi xử lý dữ liệu.|

---

### **Kết Luận**

Việc lựa chọn chỉ số đánh giá phù hợp phụ thuộc vào mục tiêu và đặc điểm của dữ liệu bạn đang làm việc:

- **Nếu bạn có nhãn thật (ground truth)**:
    - Sử dụng **External Measures** như Purity, NMI, hoặc Rand Statistic để so sánh phân cụm với nhãn thật.
- **Nếu bạn không có nhãn thật**:
    - Sử dụng **Internal Measures** (được giải thích ở phần trước) để đánh giá sự tách biệt và gọn gàng của các cụm.
- **Đối với phân tích chi tiết**:
    - Kết hợp nhiều chỉ số để có cái nhìn toàn diện về chất lượng phân cụm.

Hy vọng bảng giải thích này giúp bạn hiểu rõ hơn về các chỉ số đánh giá phân cụm ngoại! Nếu bạn cần thêm ví dụ hoặc giải thích chi tiết hơn về bất kỳ chỉ số nào, hãy cho mình biết nhé! 😊

o1-mini