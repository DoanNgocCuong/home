[Chain of Draft: Thinking Faster by Writing Less](https://arxiv.org/html/2502.18600v1)
### **Summary of "Chain of Draft: Thinking Faster by Writing Less"**

#### **1. Background & Motivation**

Large Language Models (LLMs) like GPT-4 and Claude 3.5 have demonstrated strong reasoning abilities using **Chain-of-Thought (CoT) prompting**, which involves breaking down problems into detailed, step-by-step explanations. However, this method is computationally expensive, slow, and often produces unnecessarily verbose responses.

Humans, on the other hand, tend to **draft concise intermediate steps** while solving problems instead of writing everything out. Inspired by this, the authors propose **Chain of Draft (CoD)**—a new prompting strategy that encourages LLMs to generate **concise but informative** reasoning steps.

#### **2. Key Contributions**

- Introduces **Chain of Draft (CoD)** as a more efficient alternative to CoT.
- Empirically shows that CoD reduces **token usage and latency** while maintaining or improving accuracy.
- Explores implications of CoD for **LLM efficiency, cost reduction, and real-world usability**.

#### **3. Method: Chain-of-Draft (CoD) Prompting**

- Unlike CoT, which produces **detailed step-by-step reasoning**, CoD forces the model to **write minimal drafts** (≤5 words per reasoning step).
- This method captures **only the essential information** needed to progress toward the final answer.
- Example:
    - **CoT:** Writes a long explanation before giving the answer.
    - **CoD:** Writes only a short mathematical equation or key reasoning points.

#### **4. Experiments & Results**

The authors evaluate CoD on three reasoning benchmarks:

1. **Arithmetic Reasoning (GSM8k)**
    
    - **CoD achieves 91% accuracy with 80% fewer tokens compared to CoT.**
    - Significantly reduces inference latency (up to **76.2%** on GPT-4o and **48.4%** on Claude 3.5).
2. **Commonsense Reasoning (BIG-bench)**
    
    - **CoD outperforms CoT in some tasks while using fewer tokens.**
    - In **sports understanding tasks**, CoD reduces **92.4% of the token count** compared to CoT.
3. **Symbolic Reasoning (Coin Flip Task)**
    
    - **Both CoD and CoT achieve 100% accuracy, but CoD uses up to 86% fewer tokens.**

#### **5. Discussion & Impact**

- **Latency & Cost Reduction:** CoD enables **faster** and **cheaper** LLM inference, making it suitable for real-time applications.
- **Trade-offs & Flexibility:** CoD provides a balance between efficiency and reasoning depth.
- **Future Work:** Potential extensions include integrating CoD with **parallel decoding** or **multi-pass validation** to further optimize LLM performance.

### **Conclusion**

**Chain-of-Draft (CoD)** is a **new reasoning strategy** for LLMs that focuses on **concise and efficient** intermediate reasoning steps. It **reduces verbosity, improves speed, and lowers inference costs** while maintaining or even improving accuracy. This approach makes LLMs more practical for real-world applications that require both **fast** and **accurate** reasoning.