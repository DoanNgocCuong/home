### **📄 Đồ án nghiên cứu: LONG TERM MEMORY, MEMORY-AUGMENTED AI AGENTS**

📝 **Tác giả:** (Tên của bạn)  
🏫 **Đơn vị nghiên cứu:** (Tên trường đại học / viện nghiên cứu)  
📅 **Ngày thực hiện:** (Ngày bắt đầu nghiên cứu)

---

## **📌 1. Giới thiệu (Introduction)**

### **1.1. Bối cảnh nghiên cứu**

- **Vấn đề**: Các mô hình ngôn ngữ lớn (LLMs) khi triển khai trong các “chatbot” hay “AI agent” thường gặp hạn chế về dung lượng ngữ cảnh (context window) và khả năng cập nhật thông tin động. Khi độ dài hội thoại hoặc dữ liệu doanh nghiệp trở nên lớn, việc đưa trực tiếp tất cả vào “prompt” là không khả thi.
- **Giải pháp truyền thống**: Nhiều hệ thống áp dụng RAG (Retrieval-Augmented Generation) – tức là tìm kiếm (retrieval) các mẩu thông tin quan trọng trong “corpus” hoặc “document store” rồi chèn vào ngữ cảnh (prompt). Tuy nhiên, hầu hết chỉ tập trung vào kho dữ liệu “tĩnh” (static) hay các văn bản không thay đổi thường xuyên.
-**Điểm mới**: Trong thực tế doanh nghiệp, dữ liệu liên tục thay đổi (thông tin khách hàng, các sự kiện, luồng hội thoại dài, v.v.). Để chatbot hay AI agent “nhớ” và lập luận được với lượng thông tin “động” này, ta cần một lớp “bộ nhớ dài hạn” hiệu quả.

### **1.2. Vấn đề nghiên cứu**

- **Làm thế nào để tích hợp trí nhớ dài hạn vào AI Agents mà không làm giảm hiệu suất?**
- **Làm thế nào để AI chỉ nhớ thông tin quan trọng thay vì lưu trữ toàn bộ hội thoại?**
- **Làm sao để AI có thể quên thông tin không cần thiết và cập nhật kiến thức liên tục?**

### **1.3. Mục tiêu nghiên cứu**

📌 **Nghiên cứu này nhằm:**

1. **Phát triển một kiến trúc Memory-Augmented AI Agent** giúp AI có **trí nhớ dài hạn**, duy trì bối cảnh hội thoại.
2. **Xây dựng thuật toán quản lý bộ nhớ AI** giúp AI biết **cái gì nên nhớ, cái gì nên quên**.
3. **So sánh hiệu suất của Memory-Augmented AI với LLM thông thường** trong các bài toán thực tế.

---

## **📌 2. Tổng quan nghiên cứu (Related Work)**

### **2.1. Hạn chế của LLMs về trí nhớ**

- LLMs hiện nay **chỉ có trí nhớ ngắn hạn**, bị giới hạn bởi context window (128K tokens với GPT-4-turbo, 1M tokens với Claude 3). - 2M rất to
- Các mô hình không thể duy trì bối cảnh hội thoại **qua nhiều phiên làm việc**.

### **2.2. Các phương pháp hiện tại**

#### **(1) Memory-Augmented Neural Networks (MANNs)**

- **Ưu điểm**: Tăng cường trí nhớ bằng cách lưu trữ thông tin trong **Vector Databases** như FAISS, Pinecone.
- **Nhược điểm**: Dữ liệu có thể quá tải nếu không có cơ chế lọc.

#### **(2) Retrieval-Augmented Generation (RAG)**

- **Ưu điểm**: LLM có thể truy xuất dữ liệu từ nguồn ngoài khi cần.
- **Nhược điểm**: Không nhớ thông tin theo thời gian, chỉ hoạt động khi có truy vấn tìm kiếm.

#### **(3) Các nghiên cứu trước đây**

- OpenAI đang phát triển **tác nhân có trí nhớ** nhưng chưa công bố chi tiết.
- Meta AI thử nghiệm chatbot có khả năng **nhớ sở thích người dùng** nhưng gặp thách thức về quyền riêng tư.

📌 **Điểm khác biệt của nghiên cứu này:**  
✅ Đề xuất mô hình **Memory-Augmented AI** tối ưu hơn, có thể **học hỏi theo thời gian mà không bị quá tải dữ liệu**.  
✅ Kết hợp giữa **Memory-Augmented Learning & RAG** để tối ưu hóa bộ nhớ.

---

## **📌 3. Phương pháp nghiên cứu (Methodology)**

### **3.1. Kiến trúc đề xuất**

Mô hình **Memory-Augmented AI Agent** gồm các thành phần chính:  
1️⃣ **Short-Term Memory (STM)**: Lưu trữ thông tin trong phạm vi cửa sổ ngữ cảnh hiện tại.  
2️⃣ **Long-Term Memory (LTM)**: Lưu trữ thông tin quan trọng vào **Vector Database**.  
3️⃣ **Memory Management Algorithm**: Quyết định **nên nhớ gì, quên gì**.  (lưu tất thì bị phìng bộ nhớ? )
-bỏ:  Trí nhớ về sở thích 
- bỏ: Trí nhớ về các sự kiện đã qua 
- Trí nhớ về các lịch sắp tới
- 
4️⃣ **Knowledge Update Mechanism**: Cập nhật và quên thông tin cũ khi cần.
- Cập nhật dựa trên thời gian (User ngày xưa thích chơi đá bóng.Gẫy chân => Hiện tại thì không). 

- 
📌 **Mô hình sử dụng các công nghệ:**

- **LLM (GPT-4, Claude 3, Llama 2)**.
- **Vector Database (FAISS, Pinecone, Weaviate)** để lưu trí nhớ dài hạn.
- **LangChain / LlamaIndex** để quản lý truy xuất thông tin.

---

## **📌 4. Thực nghiệm & Kết quả (Experiments & Results)**

### **4.1. Thiết lập thử nghiệm**

**Bài toán:** So sánh hiệu suất giữa **Memory-Augmented AI Agent** và **LLM thông thường** trong hội thoại dài hạn.

🔹 **Dữ liệu thử nghiệm:**

- **Tập hội thoại thực tế** (chăm sóc khách hàng, trợ lý ảo).
- **Tập hội thoại tổng hợp** (hội thoại kéo dài > 10,000 tokens).
## 4. Thực nghiệm và đánh giá

### 4.1 Deep Memory Retrieval (DMR)

- **DMR** (giới thiệu trong MemGPT) có 500 cuộc hội thoại nhiều phiên (multi-session).
- Zep đạt **94.8%** độ chính xác khi dùng GPT-4-turbo (và 98.2% khi dùng một biến thể GPT-4o-mini), nhỉnh hơn so với MemGPT (93.4%).
- Tuy nhiên, bộ DMR chỉ có hội thoại khá ngắn (khoảng 60 tin nhắn mỗi cuộc), chưa thực sự kiểm tra khả năng “siêu dài hạn”.

### 4.2 LongMemEval (LME)

- **LongMemEval** có các đoạn hội thoại dài hơn nhiều (trung bình 115.000 tokens), mô phỏng tình huống doanh nghiệp thực tế phức tạp.

Các hệ thống trợ lý trò chuyện ngôn ngữ lớn gần đây (LLM) có các thành phần bộ nhớ tích hợp để theo dõi lịch sử trò chuyện có sự hỗ trợ của người dùng, cho phép các phản hồi chính xác và cá nhân hóa hơn. Tuy nhiên, khả năng bộ nhớ dài hạn của họ trong các tương tác bền vững vẫn chưa được khai thác. Bài viết này giới thiệu Longmemeval, một điểm chuẩn toàn diện được thiết kế để đánh giá năm khả năng bộ nhớ dài hạn cốt lõi của các trợ lý trò chuyện: trích xuất thông tin, lý luận đa phiên, lý luận thời gian, cập nhật kiến ​​thức và kiêng khem. Với 500 câu hỏi được quản lý tỉ mỉ được nhúng trong lịch sử trò chuyện hỗ trợ người dùng có thể mở rộng, Longmemeval đưa ra một thách thức đáng kể đối với các hệ thống bộ nhớ dài hạn hiện có, với các trợ lý trò chuyện thương mại và LLM bối cảnh dài cho thấy độ chính xác giảm 30% khi ghi nhớ thông tin qua các tương tác được duy trì. Sau đó, chúng tôi trình bày một khung thống nhất phân chia thiết kế bộ nhớ dài hạn thành bốn lựa chọn thiết kế trên các giai đoạn lập chỉ mục, truy xuất và đọc. Được xây dựng dựa trên những hiểu biết thử nghiệm quan trọng, chúng tôi đề xuất một số thiết kế bộ nhớ bao gồm phân tách phiên để tối ưu hóa mức độ chi tiết giá trị, mở rộng chính được thực hiện để tăng cường cấu trúc chỉ số và mở rộng truy vấn thời gian để tinh chỉnh phạm vi tìm kiếm. Kết quả thử nghiệm cho thấy các tối ưu hóa này cải thiện đáng kể cả việc thu hồi bộ nhớ và trả lời câu hỏi hạ nguồn trên longmemeval. Nhìn chung, nghiên cứu của chúng tôi cung cấp các nguồn lực và hướng dẫn có giá trị để thúc đẩy khả năng bộ nhớ dài hạn của các trợ lý trò chuyện dựa trên LLM, mở đường cho AI trò chuyện cá nhân hóa và đáng tin cậy hơn.

- Zep cải thiện kết quả so với baseline (dùng toàn bộ hội thoại) ở hầu hết các loại câu hỏi, đặc biệt:
    - Loại câu “multi-session,” “preference,” “temporal reasoning” tăng đáng kể.
    - Độ trễ (latency) giảm đến 90% so với việc nhét toàn bộ hội thoại vào prompt (vì prompt của Zep ngắn gọn hơn).
🔹 **Tiêu chí đánh giá:**

| **Tiêu chí**                  | **Memory-Augmented AI**          | **LLM thông thường**     |
| ----------------------------- | -------------------------------- | ------------------------ |
| **Khả năng duy trì bối cảnh** | ✅ Tốt                            | ❌ Kém                    |
| **Độ chính xác phản hồi**     | ✅ Cao hơn                        | ❌ Giảm khi hội thoại dài |
| **Tốc độ phản hồi**           | ❌ Chậm hơn                       | ✅ Nhanh hơn              |
| **Khả năng cá nhân hóa**      | ✅ Có thể nhớ sở thích người dùng | ❌ Không nhớ thông tin cũ |

Chi tiết các tiêu chí đánh giá: 

- **Trích xuất thông tin (Information Extraction)**: Khả năng nhớ lại thông tin cụ thể từ lịch sử tương tác dài, bao gồm cả chi tiết được đề cập bởi người dùng hoặc trợ lý.​[Di Wu](https://xiaowu0162.github.io/long-mem-eval/?utm_source=chatgpt.com)
    
- **Suy luận đa phiên (Multi-Session Reasoning)**: Khả năng tổng hợp thông tin từ nhiều phiên lịch sử để trả lời các câu hỏi phức tạp liên quan đến việc tổng hợp và so sánh.​
    
- **Suy luận thời gian (Temporal Reasoning)**: Nhận thức về các khía cạnh thời gian của thông tin người dùng, bao gồm cả các đề cập thời gian rõ ràng và siêu dữ liệu dấu thời gian trong các tương tác.​
    
- **Cập nhật kiến thức (Knowledge Updates)**: Khả năng nhận biết các thay đổi trong thông tin cá nhân của người dùng và cập nhật kiến thức về người dùng một cách động theo thời gian.​
    
- **Từ chối trả lời (Abstention)**: Khả năng từ chối trả lời các câu hỏi liên quan đến thông tin không được đề cập trong lịch sử tương tác, tức là thông tin không được nhắc đến trong lịch sử tương tác.
### **4.2. Kết quả thực nghiệm**

📌 **Memory-Augmented AI cải thiện 38% khả năng duy trì bối cảnh hội thoại so với LLM thông thường.**  
📌 **Tốc độ phản hồi chậm hơn ~10% nhưng độ chính xác tăng 25%.**

---

## **📌 5. Kết luận & Hướng phát triển (Conclusion & Future Work)**

### **5.1. Kết luận**

- **Memory-Augmented AI Agents có thể cải thiện đáng kể khả năng duy trì hội thoại dài hạn.**
- **Hạn chế của mô hình là tốc độ phản hồi, nhưng có thể tối ưu hóa.**

### **5.2. Hướng phát triển**

✅ **Tối ưu thuật toán quản lý bộ nhớ** để cải thiện tốc độ.  
✅ **Kết hợp với RAG** để AI có thể truy xuất thông tin từ dữ liệu ngoài.  
✅ **Mở rộng thử nghiệm trên nhiều lĩnh vực** như giáo dục, chăm sóc sức khỏe.

---

## **📌 6. Tài liệu tham khảo (References)**

- [KARMA: Memory-Augmented AI Research](https://arxiv.org/abs/2409.14908)
- [AriGraph: Knowledge Memory for LLMs](https://arxiv.org/abs/2407.04363)
- [Meta AI’s Memory-Augmented Chatbot](https://www.theverge.com/2025/1/27/24352992/meta-ai-memory-personalization)
