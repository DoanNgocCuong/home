### **📄 Đồ án nghiên cứu: LONG TERM MEMORY, MEMORY-AUGMENTED AI AGENTS**

📝 **Tác giả:** (Tên của bạn)  
🏫 **Đơn vị nghiên cứu:** (Tên trường đại học / viện nghiên cứu)  
📅 **Ngày thực hiện:** (Ngày bắt đầu nghiên cứu)

---

## **📌 1. Giới thiệu (Introduction)**

### **1.1. Đặt vấn đề: 

Các mô hình ngôn ngữ lớn (LLMs) như GPT, BERT, LLaMA hay PaLM đã chứng tỏ năng lực nổi bật trong việc hiểu và tạo ra ngôn ngữ tự nhiên, đặc biệt khi được triển khai dưới dạng hệ thống hội thoại hoặc trợ lý AI. Tuy nhiên, trong môi trường ứng dụng thực tế, nhất là tại các doanh nghiệp, những mô hình này phải đối mặt với một bài toán đáng kể liên quan đến việc duy trì ngữ cảnh, cập nhật dữ liệu động và tương tác lâu dài cùng người dùng. Mỗi khi lượng thông tin của các cuộc hội thoại trở nên đồ sộ, việc đưa tất cả nội dung vào phần ngữ cảnh (prompt) trở nên bất khả thi do giới hạn về mặt kỹ thuật cũng như chi phí tính toán. Bên cạnh đó, dữ liệu tại các doanh nghiệp không tĩnh mà luôn được điều chỉnh và bổ sung, đòi hỏi một cơ chế thường xuyên cập nhật để tránh tình trạng mô hình sử dụng thông tin cũ hoặc lạc hậu.

Vấn đề của những mô hình ngôn ngữ này càng trở nên phức tạp hơn khi người dùng mong đợi khả năng “nhớ” các luồng hội thoại kéo dài nhiều phiên, thậm chí nhiều tháng. Trong các tình huống thực tế, như khi tương tác với khách hàng, việc chatbot quên mất những trao đổi trước đó khiến người dùng phải lặp lại thông tin và gây nên sự khó chịu không nhỏ. Nếu như trước đây, các giải pháp RAG (Retrieval-Augmented Generation) chủ yếu tập trung vào các tập dữ liệu tĩnh để giảm thiểu sai sót và tránh tình trạng mô hình “bịa” thông tin, thì nay, nhu cầu quản lý luồng hội thoại động và dữ liệu doanh nghiệp liên tục thay đổi lại đòi hỏi một cơ chế linh hoạt hơn. RAG truyền thống không được thiết kế để xử lý thường xuyên các cập nhật, thêm bớt hay xóa bỏ nội dung trong cơ sở dữ liệu, vì đa số tập trung vào văn bản “tĩnh” như cẩm nang, FAQ hoặc hướng dẫn.

Khó khăn khác nảy sinh khi những mô hình ngôn ngữ này trở nên quá tải do phải nạp toàn bộ lịch sử của nhiều phiên hội thoại, dẫn đến chi phí tính toán tăng vọt và độ trễ xử lý cũng không còn đáp ứng được yêu cầu thực tế. Từ góc độ người dùng, việc có một chatbot thông minh và nhanh nhạy là ưu tiên hàng đầu, nhưng nếu hệ thống mất quá nhiều thời gian để suy xét hoặc trả lời không chính xác do rối loạn thông tin, trải nghiệm tương tác sẽ bị ảnh hưởng nặng nề. Đối với doanh nghiệp, lượng hội thoại có thể lên đến hàng triệu dòng, kết hợp với nhiều loại dữ liệu khác như hồ sơ khách hàng, thống kê kinh doanh hay các báo cáo nội bộ. Sự hiện diện của một kiến trúc có thể trích xuất phần thông tin cần thiết để đưa vào ngữ cảnh và bỏ qua những yếu tố không còn hữu ích là điều bắt buộc, nhằm tối ưu cả chi phí và khả năng vận hành.

Bài toán “lãng quên” hay “ưu tiên thông tin” đặt ra yêu cầu đặc biệt về cách tổ chức và gán nhãn dữ liệu. Nếu giữ lại tất cả thì hệ thống bị quá tải, còn nếu xóa bớt một cách tùy tiện, mô hình có thể bỏ lỡ những chi tiết quan trọng vốn dĩ cần thiết để suy luận chính xác. Hơn nữa, mỗi khi có xung đột thông tin hoặc thay đổi về dữ liệu, quá trình cập nhật sao cho mô hình không trả lời dựa trên những gì đã lỗi thời lại trở thành một thách thức. Từ đó, câu hỏi trung tâm được đặt ra là làm thế nào để thiết kế một cơ chế “bộ nhớ ngoài” cho mô hình ngôn ngữ, có khả năng quản lý luồng hội thoại dài hạn, tiếp nhận và loại bỏ thông tin linh hoạt, đồng thời bảo đảm tốc độ và chất lượng trả lời không suy giảm.

Tất cả các yếu tố vừa đề cập nhấn mạnh nhu cầu nghiên cứu và phát triển một lớp “bộ nhớ dài hạn” (long-term memory layer) có thể bổ sung cho LLM, giúp lưu trữ, truy xuất và cập nhật thông tin hiệu quả trong môi trường hội thoại nhiều phiên và dữ liệu doanh nghiệp liên tục phát sinh. Giải pháp lý tưởng cần cho phép tách biệt quá trình lưu trữ và trích xuất khỏi mô hình ngôn ngữ, đồng thời duy trì tính chính xác trong việc truy vấn những đoạn thông tin quan trọng mỗi khi cần dùng đến. Mục tiêu là nâng cao chất lượng hội thoại, giảm thiểu tình trạng lặp lại câu hỏi, hạn chế chi phí về token và thời gian, qua đó đáp ứng tốt hơn yêu cầu triển khai thực tế trong doanh nghiệp.

### **1.2. Các giải pháp hiện tại và hạn chế
- .... Phân đoạn dựa trên ...

**Trợ lý hội thoại cá nhân hóa có trí nhớ (Memory-based Personalized Dialogue Agents)**

Sự phát triển của các trợ lý hội thoại cá nhân hóa có trí nhớ đã nâng cao đáng kể khả năng tương tác dài hạn, bằng cách cho phép hệ thống **lưu giữ và sử dụng lại thông tin từ các cuộc trò chuyện trước đó** (Bae et al., 2022).

Những phương pháp ban đầu, chẳng hạn như **CoMemNN** (Pei et al., 2021), giới thiệu các cơ chế để **từng bước xây dựng hồ sơ người dùng** trong quá trình đối thoại.

Tuy nhiên, việc thu thập dữ liệu được gán nhãn đủ lớn để huấn luyện một hệ thống cá nhân hóa lâu dài là **rất khó** (Tseng et al., 2024).

Gần đây, các nghiên cứu tập trung vào việc **kết hợp LLM với module bộ nhớ**. Ví dụ:

| Bae et al., "Keep Me Updated!"                     | 2022 | [https://aclanthology.org/2022.findings-emnlp.276](https://aclanthology.org/2022.findings-emnlp.276) |
| -------------------------------------------------- | ---- | ---------------------------------------------------------------------------------------------------- |
| Pei et al., "Cooperative Memory Network (CoMemNN)" | 2021 | [https://doi.org/10.1145/3442381.3449843](https://doi.org/10.1145/3442381.3449843)                   |

## 🔗 **Link các bài báo được trích dẫn:**

| Paper                                              | Năm  | Link                                                                                                 |
| -------------------------------------------------- | ---- | ---------------------------------------------------------------------------------------------------- |
| Bae et al., "Keep Me Updated!"                     | 2022 | [https://aclanthology.org/2022.findings-emnlp.276](https://aclanthology.org/2022.findings-emnlp.276) |
| Pei et al., "Cooperative Memory Network (CoMemNN)" | 2021 | [https://doi.org/10.1145/3442381.3449843](https://doi.org/10.1145/3442381.3449843)                   |
| Tseng et al., "Two Tales of Persona in LLMs"       | 2024 | [https://aclanthology.org/2024.findings-emnlp.969](https://aclanthology.org/2024.findings-emnlp.969) |
| Li et al., "LD-Agent"                              | 2024 | [https://arxiv.org/abs/2406.05925](https://arxiv.org/abs/2406.05925)                                 |
| Zhong et al., "MemoryBank"                         | 2024 | [https://doi.org/10.1609/aaai.v38i17.29946](https://doi.org/10.1609/aaai.v38i17.29946)               |
| Kim et al., "Theanine"                             | 2024 | [https://arxiv.org/abs/2406.10996](https://arxiv.org/abs/2406.10996)                                 |

---

Nếu Quốc muốn, mình có thể tổng hợp đoạn này thành **một phần “Related Work” hoàn chỉnh cho research paper** hoặc vẽ sơ đồ so sánh các phương pháp. Quốc muốn chọn hướng nào?
### **1.3. Mục tiêu và định hướng giải pháp

Đồ án hướng đến mục tiêu sau:
1. Tìm hiểu và nghiên cứu các phương pháp, kỹ thuật phân đoạn khác nhau,
từ đó đưa ra đánh giá và các phương pháp kết hợp để tận dụng ưu điểm của các
phương pháp cũng như hạn chế, nhược điểm phù hợp với tình huống đặt ra về tài
nguyên sử dụng.
2. Đưa ra đề xuất cải tiến và hiệu quả có khả năng làm nâng cao hiệu quả trong
mô đun truy xuất.
3. Cài đặt hệ thống và thử nghiệm với các kịch bản khác nhau. Nêu và phân tích
được những kết quả thực nghiệm, so sánh đánh giá giữa các phương pháp và đưa
ra các ưu điểm và nhược điểm của các kỹ thuật thử nghiệm.
Trên cơ sở các phân tích và đánh giá ở phần 0.2 và để đạt được những mục tiêu
đã nêu phía trên, đồ án này sẽ tập trung vào các khía cạnh:
4. Thực hiện kết hợp phương pháp phân đoạn cổ điển với phương pháp phân
đoạn sử dụng mô hình ngôn ngữ lớn để cải thiện chất lượng phân đoạn.
4
5. Thiết kế luồng truy xuất hiệu quả bằng cách kết hợp các phương pháp truy
xuất và sử dụng thêm mô-đun xếp hạng để cải thiện thêm chất lượng truy xuất.

Vấn đề với phương pháp cũ (LongMemEval gốc)

1. **Granularity chưa tối ưu**:
    
    - Việc trích xuất `summary`, `fact`, `keyphrase` từ **toàn bộ session** hoặc **round riêng lẻ** có thể gặp tình trạng:
        - Đoạn quá **ngắn** (không đủ ngữ cảnh để LLM trích xuất meaningful facts).
        - Đoạn quá **dài** (gây nhiễu thông tin, LLM không thể tóm tắt chính xác, dễ mất detail).
    - Không có cách kiểm soát mức độ coherence hoặc topic shift trong session dài.
2. **Chỉ dùng 1 loại key duy nhất cho indexing**:
    
    - `K = V + fact` hoặc `K = V + summary` là tốt, nhưng mỗi loại key có điểm mạnh khác nhau:
        - `summary`: tốt cho match semantic tổng thể.
        - `keyphrase`: bắt cụ thể keyword.
        - `fact`: truy xuất chính xác các entity, số liệu, mốc thời gian.
    - Không tận dụng được hiệu ứng **ensemble giữa các loại key**.
3. **Lacking structure in indexing**:
    
    - Indexing hiện tại là **flat** → không tận dụng tính chất "tầng" của văn bản hội thoại: đoạn – session – timeline.
    - Thiếu khả năng điều hướng mượt mà giữa các mức khái quát (coarse) và chi tiết (fine).

---

## ✅ Giải pháp đề xuất: Kết hợp **LLMs + Raptor + Multi-Key Embedding + Hierarchical Indexing**

### **1. Conversation-Aware Chunking trước khi Extract**

#### ✂️ 1.1. LLM-based Chunking

- Dùng LLM để phân chia session thành các đoạn nhỏ (chunk) theo chuyển chủ đề, mục đích câu hỏi, hoặc hành vi người dùng.
- Lợi ích:
    - Tách được các segment theo topic.
    - Giữ được coherence bên trong mỗi chunk.

#### 🧱 1.2. Raptor Chunking

- Dùng **RAPTOR (recursive abstractive chunking)** để tạo cây phân cấp cho từng session.
- Mỗi node là một chunk hoặc summary của chunk con → có thể phục vụ **hierarchical retrieval**.


=> **Sau đó ta thu được: thay vì K = Session + fact thì của ta là: K = Session1.i + Fact (Với i là Session 1.i được Chunking nhỏ ra từ Session to ban đầu).** 

![[Pasted image 20250322071142.png]]
---

### **2. Embedding: Flatten & Index**

#### 🧾 2.1 Raptor Flat Embedding

- Đưa từng chunk (ban đầu + LLM-chunked + summary chunk) vào embedding encoder.
- Tạo index **dạng phẳng (flat)**, có thể dùng Reranker để chọn top-K chunk có khả năng cao nhất.

#### 🧠 2.2 Hierarchical Indexing (2-phase Retrieval)

**Pha 1: Coarse Retrieval**

- Embed summary / keyphrase của chunk.
- Dùng query để so sánh, chọn Top-K chunk liên quan.

**Pha 2: Fine Retrieval**

- Với mỗi chunk đã chọn ở coarse stage → đi sâu vào level fine:
    - Embed lại các câu gốc / facts / sub-chunks.
    - Lấy top-K’ fine-grained memory units.

=> **Cuối cùng đưa vào LLM để đọc và trả lời (Reading stage).**

---

### **3. Multi-Key Embedding cho Indexing**

- Với mỗi chunk → tạo và embed song song:
    - `K1 = V + summary`
    - `K2 = V + fact`
    - `K3 = V + keyphrase`
- Kết hợp kết quả truy hồi từ các luồng (voting / weighted fusion / union-rerank).
- Lý do:
    - Summary bắt ngữ nghĩa chung.
    - Fact giúp reasoning logic.
    - Keyphrase giúp match keyword trong truy vấn cụ thể.

---

## 🔁 Tổng pipeline cải tiến

```
Session
  ↓
Conversation-aware Chunking (LLMs Chunk + Raptor Chunk)
  ↓
Chunk-level Value → Extract (summary, fact, keyphrase)
  ↓
Embed:
   - K1 = V + summary
   - K2 = V + fact
   - K3 = V + keyphrase
  ↓
Phase 1: Coarse Retrieval từ summary/keyphrase
  ↓
Phase 2: Fine Retrieval từ facts
  ↓
Reading Strategy: CoN + JSON (Chain-of-Note)
  ↓
Answer
```

---

## 📈 Lợi ích chính

- ✅ Giảm nhiễu, tối ưu granularity nhờ LLM chunking.
- ✅ Tận dụng tốt semantic, factual và keyword-level cues qua multi-key.
- ✅ Tăng khả năng truy hồi đúng với hierarchical search.
- ✅ Phù hợp để scale cho 500+ sessions như LongMemEvalM.

---

Nếu bạn cần mình mô phỏng pipeline này bằng sơ đồ (sequence hoặc flowchart), hoặc viết phần giải thích thành văn academic để ghép vào một paper / research blog, mình cũng làm được ngay nhé!

---
Dưới đây là toàn bộ **kịch bản thử nghiệm** (experimental settings) tương ứng với từng ý tưởng cải tiến mà Quốc đề xuất — được tổ chức theo dạng **ma trận thí nghiệm** để có thể dễ dàng triển khai thực nghiệm, đánh giá từng thành phần và kết hợp của pipeline.

---

## 🎯 **MỤC TIÊU THỬ NGHIỆM**

> Kiểm chứng các cải tiến về chunking, indexing, embedding, retrieval và reading strategy nhằm cải thiện hiệu quả của hệ thống long-term memory QA (ví dụ trên benchmark như LONGMEMEVAL).

---

## 🧪 **KỊCH BẢN THỬ NGHIỆM CHÍNH**

### 🔹 **I. Chunking Strategy**

|Mã|Tên phương pháp|Mô tả|
|---|---|---|
|C1|No Chunking (baseline)|Dùng cả session hoặc round làm value trực tiếp|
|C2|LLM-based Chunking|Phân chia đoạn theo chủ đề/ngữ nghĩa bằng LLM|
|C3|RAPTOR Chunking|Chunking dạng cây phân cấp theo RAPTOR|
|C4|LLM + RAPTOR Hybrid|Chunk theo LLM → dùng RAPTOR để tóm tắt từng chunk|

---

### 🔹 **II. Value Representation**

|Mã|Dạng value đầu vào|Mô tả|
|---|---|---|
|V1|Full Session|Không chia nhỏ, để nguyên session|
|V2|Round-based|Mỗi round là một value|
|V3|Chunked|Chunk theo chiến lược C2, C3, C4|
|V4|Summary|Tóm tắt của chunk hoặc session|
|V5|Fact|Fact trích từ chunk/session|

---

### 🔹 **III. Key Design (Indexing)**

|Mã|Tên thiết kế key|Mô tả|
|---|---|---|
|K1|K = V|Dùng raw value làm key|
|K2|K = fact|Key là facts đã trích|
|K3|K = summary|Key là summary|
|K4|K = V + fact|Nối fact vào value để tạo key|
|K5|K = V + summary|Nối summary vào value|
|K6|K = V + fact + summary + keyphrase|Multi-key (concat tất cả)|
|K7|Multi-path index|Tạo nhiều loại key riêng biệt, embed độc lập|

---

### 🔹 **IV. Retrieval Strategy**

|Mã|Phương pháp truy hồi|Mô tả|
|---|---|---|
|R1|Flat Retrieval|Retrieval đơn lớp, cosine / FAISS|
|R2|Coarse → Fine Retrieval (2-phase)|Truy xuất 2 pha: summary → fact|
|R3|Flat + Reranker|Retrieval sơ cấp rồi rerank bằng LLM|
|R4|Multi-path Fusion|Truy hồi theo từng key, rồi hợp kết quả (voting / union)|

---

### 🔹 **V. Reading Strategy**

|Mã|Kỹ thuật đọc kết quả|Mô tả|
|---|---|---|
|RS1|Direct Answer|Đưa chunk vào, yêu cầu LLM trả lời thẳng|
|RS2|Chain-of-Note (CoN)|Trích info trước rồi reasoning sau|
|RS3|JSON + CoN|Đưa input dạng JSON có cấu trúc, dùng CoN|
|RS4|CoT + CoN|Kết hợp chain-of-thought reasoning với CoN|

---

## ✅ **KẾT HỢP THỬ NGHIỆM GỢI Ý (FULL COMBO)**

|#|Chunking|Value|Key|Retrieval|Reading|
|---|---|---|---|---|---|
|1|C1|V1|K1|R1|RS1|
|2|C2|V3|K4|R2|RS3|
|3|C3|V3|K6|R2|RS2|
|4|C4|V3|K7|R4|RS3|
|5|C3|V5|K2|R3|RS1|
|6|C2|V3|K5|R1|RS2|
|7|C4|V3|K6|R3|RS4|

> 💡 _Bạn có thể chọn 3-5 combo để thử nghiệm A/B, đo các metric như:_
> 
> - **QA Accuracy (top-K)**
> - **Recall@K, NDCG@K**
> - **Inference time / latency**
> - **Token count (input to reader)**

---

## 📦 **Dữ liệu sử dụng**

- Dataset chính: `LONGMEMEVAL-S` và `LONGMEMEVAL-M`
- Có thể mở rộng thử nghiệm với `MemoryBank`, `PerLTQA` để kiểm tra độ generalize.

---

Nếu bạn cần mình giúp viết script pipeline chạy thử nghiệm hoặc dựng YAML config cho từng scenario để quản lý chạy bằng `Hydra`/`WandB` hoặc hệ thống ML pipeline khác thì cứ nói nhé. Cũng có thể dựng lại bảng này dưới dạng Notion template hoặc Google Sheet để dễ quản lý.


---
# SAU KHI HIỂU GỐC, BÀI BÁO GỐC, QUAY LẠI LANGGRAPH THÌ THẤY Ồ. RA LANGGRAPH NÓ ĐỀ XUẤT KIẾN TRÚC THÔI, CÒN CƠ BẢN THÌ LÀ BÀI BÁO ĐANG SEARCH NÀY 

**LangGraph** là một **framework** được giới thiệu trong khóa học "Long-Term Agentic Memory with LangGraph" do Harrison Chase, Co-Founder và CEO của LangChain, giảng dạy. Khóa học này hướng dẫn cách xây dựng một **agent** với khả năng **ghi nhớ dài hạn**, cụ thể là trong việc quản lý email cá nhân.

**Điểm mới mà LangGraph đề cập đến**:

1. **Tích hợp ba loại memory trong agent**:
    
    - **Semantic Memory**: Lưu trữ các **facts** về người dùng, như sở thích, thói quen, để sử dụng trong các tương tác sau này.
    - **Episodic Memory**: Ghi nhớ các **tình huống cụ thể** đã xảy ra trong quá khứ, giúp agent hiểu ngữ cảnh và cải thiện phản hồi.
    - **Procedural Memory**: Lưu trữ các **hướng dẫn và quy trình** mà agent cần tuân theo, giúp tối ưu hóa hành vi dựa trên phản hồi.


---
https://github.com/DoanNgocCuong/MiniProj_RAG3_RAG6_LegalChatbot_16032025

---
# Hiểu sâu hơn về Datase: 


LongMemEval là một bộ dữ liệu toàn diện, được thiết kế để đánh giá khả năng ghi nhớ dài hạn của các trợ lý trò chuyện. Bộ dữ liệu này bao gồm 500 câu hỏi chất lượng cao, tập trung vào năm khả năng cốt lõi:

1. **Trích xuất thông tin (Information Extraction):** Khả năng nhớ lại thông tin cụ thể từ lịch sử tương tác dài, bao gồm cả chi tiết do người dùng hoặc trợ lý cung cấp.
    
2. **Lý luận đa phiên (Multi-Session Reasoning):** Khả năng tổng hợp thông tin từ nhiều phiên trò chuyện để trả lời các câu hỏi phức tạp yêu cầu sự tổng hợp và so sánh.
    
3. **Cập nhật kiến thức (Knowledge Updates):** Khả năng nhận biết và cập nhật thông tin cá nhân của người dùng theo thời gian.
    
4. **Lý luận thời gian (Temporal Reasoning):** Nhận thức về các khía cạnh thời gian của thông tin người dùng, bao gồm cả thời gian được đề cập rõ ràng và siêu dữ liệu thời gian trong các tương tác.
    
5. **Từ chối trả lời (Abstention):** Khả năng từ chối trả lời các câu hỏi liên quan đến thông tin không được đề cập trong lịch sử tương tác.
    

Lấy cảm hứng từ bài kiểm tra "tìm kim trong đống cỏ khô", LongMemEval sử dụng một quy trình kiểm soát thuộc tính để tạo ra lịch sử trò chuyện mạch lạc, có thể mở rộng và được đánh dấu thời gian cho mỗi câu hỏi. Hệ thống trò chuyện cần phân tích các tương tác động để ghi nhớ và trả lời câu hỏi sau khi tất cả các phiên tương tác đã diễn ra.

**Cấu trúc Bộ Dữ Liệu:**

Bộ dữ liệu bao gồm ba tệp chính:

1. **longmemeval_s.json:** Mỗi lịch sử trò chuyện tiêu thụ khoảng 115.000 token (~40 phiên lịch sử).
    
2. **longmemeval_m.json:** Mỗi lịch sử trò chuyện chứa khoảng 500 phiên.
    
3. **longmemeval_oracle.json:** Chỉ bao gồm các phiên chứa bằng chứng cần thiết.
    

Mỗi tệp chứa 500 trường hợp đánh giá, mỗi trường hợp bao gồm các trường:

- **question_id:** ID duy nhất cho mỗi câu hỏi.
    
- **question_type:** Loại câu hỏi, như single-session-user, single-session-assistant, single-session-preference, temporal-reasoning, knowledge-update, và multi-session. Nếu question_id kết thúc bằng _abs, đó là câu hỏi từ chối trả lời.
    
- **question:** Nội dung câu hỏi.
    
- **answer:** Câu trả lời mong đợi từ mô hình.
    
- **question_date:** Ngày của câu hỏi.
    
- **haystack_session_ids:** Danh sách ID của các phiên lịch sử (sắp xếp theo thời gian).
    
- **haystack_dates:** Danh sách các mốc thời gian của các phiên lịch sử.
    
- **haystack_sessions:** Danh sách nội dung thực tế của các phiên trò chuyện giữa người dùng và trợ lý. Mỗi phiên là một danh sách các lượt trao đổi, mỗi lượt có định dạng {"role": user/assistant, "content": nội dung tin nhắn}. Đối với các lượt chứa bằng chứng cần thiết, có thêm trường has_answer: true.
    
- **answer_session_ids:** Danh sách ID của các phiên chứa bằng chứng, dùng để đánh giá độ chính xác của việc nhớ lại ở cấp độ phiên.
    

**Thiết lập Môi Trường:**

Để sử dụng bộ dữ liệu, bạn có thể tải xuống từ [Hugging Face](https://huggingface.co/datasets/xiaowu0162/longmemeval) và giải nén vào thư mục `data/`. Khuyến nghị sử dụng môi trường conda để cài đặt các yêu cầu cần thiết:

```bash
conda create -n longmemeval python=3.9
conda activate longmemeval
pip install -r requirements-full.txt
```



**Đánh Giá Hệ Thống:**

Để kiểm tra hệ thống của bạn trên LongMemEval, bạn có thể sử dụng các tập lệnh đánh giá được cung cấp. Lưu đầu ra của hệ thống vào tệp JSONL với mỗi dòng chứa hai trường: `question_id` và `hypothesis`. Sau đó, chạy tập lệnh đánh giá:

```bash
export OPENAI_API_KEY=YOUR_API_KEY
cd src/evaluation
python3 evaluate_qa.py gpt-4o your_hypothesis_file ../../data/longmemeval_oracle.json
```



Tập lệnh này sẽ lưu nhật ký đánh giá vào tệp `[your_hypothesis_file].log`. Bạn có thể tổng hợp các điểm số từ nhật ký bằng lệnh:

```bash
python3 print_qa_metrics.py gpt-4o your_hypothesis_file.log ../../data/longmemeval_oracle.json
```



**Tạo Lịch Sử Trò Chuyện Tùy Chỉnh:**

LongMemEval hỗ trợ biên soạn lịch sử trò chuyện với độ dài tùy ý cho mỗi trường hợp câu hỏi, cho phép bạn dễ dàng tăng độ khó. Để tạo lịch sử tùy chỉnh, bạn có thể làm theo định dạng trong `2_questions` và `6_session_cache` để tạo câu hỏi và các phiên bằng chứng, sau đó chạy tập lệnh `sample_haystack_and_timestamp.py` với các tham số phù hợp.

**Chạy Thử Nghiệm Hệ Thống Ghi Nhớ:**

Chúng tôi cung cấp mã thử nghiệm cho việc truy xuất bộ nhớ và tạo câu trả lời có hỗ trợ truy xuất dưới các thư mục `src/retrieval


---
Long-TermMemoryMethods Toequipchatassistantswithlong-termmemorycapabilities, three major techniques are commonly explored. The first approach involves directly adapting LLMs to process extensive history information as long-context inputs (Beltagy et al., 2020; Kitaev et al., 2020; Fu et al., 2024; An et al., 2024). While this method avoids the need for complex architectures, it is inefficient and susceptible to the “lost-in-the-middle” phenomenon, where the ability of LLMs to utilize contextual information weakens as the input length grows (Shi et al., 2023; Liu et al., 2024). A second line of research integrates differentiable memory modules into language models, proposing specialized architectural designs and training strategies to enhance memory capabilities (Weston et al., 2014; Wu et al., 2022; Zhong et al., 2022; Wang et al., 2023). Lastly, several studies approach long-term memory from the perspective of context compression, developing techniques 3 Published as a conference paper at ICLR 2025 to condense lengthy histories into compact representations, whether in the form of LLM internal representations (Mu et al., 2023; Chevalier et al., 2023), discrete tokens (Jiang et al., 2023; Xu et al., 2024), or retrievable text segments via retrieval-augmented generation (RAG, Shi et al. (2024); Wang et al. (2023); Sarthi et al. (2024); Chen et al. (2023a); Guti´ errez et al. (2024)). Although LONGMEMEVAL can evaluate any memory system, we will take an online context compression perspective, where each history interaction session is sequentially processed, stored, and accessed on-demand through indexing and retrieval mechanisms (§4). This formulation aligns with current literature (Zhong et al., 2024; Guti´ errez et al., 2024) and commercial systems (OpenAI, 2024; Coze, 2024). Its plug-and-play nature also facilitates the integration into existing chat assistant systems


Dưới đây là bản dịch tiếng Việt đoạn văn bạn cung cấp:

---

### **Các phương pháp trí nhớ dài hạn (Long-Term Memory Methods)**

Để trang bị khả năng ghi nhớ dài hạn cho các trợ lý hội thoại, hiện có ba kỹ thuật chính thường được nghiên cứu:

1. **Phương pháp thứ nhất** là điều chỉnh trực tiếp các mô hình ngôn ngữ lớn (LLMs) để xử lý lượng lớn thông tin lịch sử dưới dạng đầu vào dài (long-context input)  
    _(Beltagy et al., 2020; Kitaev et al., 2020; Fu et al., 2024; An et al., 2024)_.  
    Phương pháp này giúp tránh việc phải thiết kế kiến trúc phức tạp,  
    tuy nhiên lại **kém hiệu quả** và dễ gặp hiện tượng **"mất thông tin ở giữa" (lost-in-the-middle)** –  
    khi mà khả năng của LLM trong việc tận dụng thông tin ngữ cảnh suy giảm theo độ dài đầu vào tăng lên _(Shi et al., 2023; Liu et al., 2024)_.
    
2. **Hướng nghiên cứu thứ hai** là tích hợp các **module bộ nhớ phân biệt được (differentiable memory modules)** vào trong mô hình ngôn ngữ.  
    Các nghiên cứu này đề xuất các thiết kế kiến trúc chuyên biệt và chiến lược huấn luyện nhằm tăng cường khả năng ghi nhớ của mô hình  
    _(Weston et al., 2014; Wu et al., 2022; Zhong et al., 2022; Wang et al., 2023)_.
    
3. **Cuối cùng**, nhiều nghiên cứu tiếp cận trí nhớ dài hạn từ góc độ **nén ngữ cảnh (context compression)**, phát triển các kỹ thuật nhằm **tinh gọn lịch sử hội thoại dài** thành các biểu diễn nhỏ gọn hơn –  
    có thể dưới dạng biểu diễn nội tại trong LLM _(Mu et al., 2023; Chevalier et al., 2023)_,  
    các token rời rạc _(Jiang et al., 2023; Xu et al., 2024)_,  
    hoặc các đoạn văn bản có thể truy xuất được thông qua kỹ thuật sinh có hỗ trợ truy hồi (Retrieval-Augmented Generation - RAG)  
    _(Shi et al., 2024; Wang et al., 2023; Sarthi et al., 2024; Chen et al., 2023a; Gutiérrez et al., 2024)_.
    

Mặc dù **LONGMEMEVAL** có thể được dùng để đánh giá bất kỳ hệ thống trí nhớ nào,  
trong bài này chúng tôi chọn cách tiếp cận theo hướng **nén ngữ cảnh trực tuyến (online context compression)**,  
nơi mà mỗi phiên tương tác trong lịch sử sẽ được **xử lý tuần tự, lưu trữ và truy xuất theo yêu cầu** thông qua các cơ chế đánh chỉ mục (indexing) và truy hồi (retrieval) (§4).

Cách tiếp cận này phù hợp với các công trình hiện tại _(Zhong et al., 2024; Gutiérrez et al., 2024)_  
cũng như các hệ thống thương mại như **OpenAI (2024)** và **Coze (2024)**.  
Đặc biệt, nhờ vào tính **"plug-and-play"** (cắm vào là chạy), phương pháp này có thể dễ dàng tích hợp vào các hệ thống trợ lý hội thoại hiện có.

---

Nếu bạn muốn mình tóm lại thành bảng so sánh 3 hướng tiếp cận hoặc biểu đồ sơ đồ hóa thì mình có thể vẽ liền nhé!

## 1.4 Đóng góp của đồ án
Đồ án này có 2 đóng góp chính như sau:
1. Đồ án đề xuất giải pháp kết hợp các kỹ thuật phân đoạn khác nhau nhằm tăng
hiệu suất của hệ thống truy xuất thông tin.
2. Thực hiện thử nghiệm kết hợp các kỹ thuật truy xuất nhằm cải thiện kết quả
đầu ra.
## 1.5 Bố cục đồ án
Toàn bộ báo cáo đồ án tốt nghiệp được triển khai trong 5 chương. Các chương
còn lại của báo cáo có nội dung như sau.
Chương 2 đề cập đến các nội dung lý thuyết nhằm phục vụ việc nghiên cứu, xây
dựng thử nghiệm và đánh giá giải pháp đề xuất. Trong chương này, tôi sẽ trình bày
tổng quan về mô hình ngôn ngữ lớn, các ứng dụng, hạn chế và một số dòng mô
hình ngôn ngữ lớn phổ biến. Kỹ thuật RAG với các thành phần và các giải pháp
hiện có cũng sẽ được phân tích chi tiết ở chương này.
Chương 3 trình bày chi tiết về giải pháp đề xuất. Trước hết, tôi mô tả tổng quan
về luồng xử lý, sau đó là đi sâu vào từng mô-đun. Trong mô-đun phân đoạn, tôi
trình bày hai kỹ thuật phân đoạn tôi lấy làm ý tưởng đó là phân đoạn sử dụng mô
hình ngôn ngữ lớn và RAPTOR. Sau đó, tôi đề xuất việc kết hợp hai kỹ thuật này
để bổ trợ cho nhau. Trong mô-đun truy xuất, tôi trình bày việc kết hợp hai kỹ thuật
đó là: i) tìm kiếm mức ngữ nghĩa và ii) tìm kiếm mức từ vựng nhằm cải thiện mức
độ phù hợp của các tài liệu tìm kiếm được.
Chương 4 trình bày cụ thể về các kịch bản thử nghiệm, thông số cấu hình thử
nghiệm, kết quả thực nghiệm và các đánh giá, nhận xét về các phương pháp thử
nghiệm. Trong chương này, tôi sử dụng một số độ đo tự động thường được sử dụng
cho hỏi đáp và đánh giá bằng mô hình ngôn ngữ lớn. Những nhận xét và đánh giá
hiệu năng của phương pháp đề xuất so với các phương pháp tham chiếu cũng được
trình bày tại chương này.
Chương 5 là chương cuối cùng. Trong chương này, tôi nêu ra kết luận về phương
pháp đề xuất, những ưu điểm cũng như những hạn chế còn tồn tại cũng như đề ra
các hướng phát triển trong tương lai.

---

## **📌 2. Tổng quan nghiên cứu (Related Work)**

### **2.1. Hạn chế của LLMs về trí nhớ**

- LLMs hiện nay **chỉ có trí nhớ ngắn hạn**, bị giới hạn bởi context window (128K tokens với GPT-4-turbo, 1M tokens với Claude 3). - 2M rất to
- Các mô hình không thể duy trì bối cảnh hội thoại **qua nhiều phiên làm việc**.

### **2.2. Các phương pháp hiện tại**

#### **(1) LLMs lưu trữ ngắn hạn



#### **(2) Retrieval-Augmented Generation (RAG)**

- **Ưu điểm**: LLM có thể truy xuất dữ liệu từ nguồn ngoài khi cần.
- **Nhược điểm**: Không nhớ thông tin theo thời gian, chỉ hoạt động khi có truy vấn tìm kiếm.

#### **(3) Các nghiên cứu trước đây**

- OpenAI đang phát triển **tác nhân có trí nhớ** nhưng chưa công bố chi tiết.
- Meta AI thử nghiệm chatbot có khả năng **nhớ sở thích người dùng** nhưng gặp thách thức về quyền riêng tư.
![[Pasted image 20250322054143.png]]

📌 **Điểm khác biệt của nghiên cứu này:**  
✅ Đề xuất mô hình **Memory-Augmented AI** tối ưu hơn, có thể **học hỏi theo thời gian mà không bị quá tải dữ liệu**.  
✅ Kết hợp giữa **Memory-Augmented Learning & RAG** để tối ưu hóa bộ nhớ.

---

## **📌 3. Phương pháp nghiên cứu (Methodology)**

### **3.1. Kiến trúc đề xuất**

Mô hình **Memory-Augmented AI Agent** gồm các thành phần chính:  
1️⃣ **Short-Term Memory (STM)**: Lưu trữ thông tin trong phạm vi cửa sổ ngữ cảnh hiện tại.  
2️⃣ **Long-Term Memory (LTM)**: Lưu trữ thông tin quan trọng vào **Vector Database**.  
3️⃣ **Memory Management Algorithm**: Quyết định **nên nhớ gì, quên gì**.  (lưu tất thì bị phìng bộ nhớ? )
-bỏ:  Trí nhớ về sở thích 
- bỏ: Trí nhớ về các sự kiện đã qua 
- Trí nhớ về các lịch sắp tới
- 
4️⃣ **Knowledge Update Mechanism**: Cập nhật và quên thông tin cũ khi cần.
- Cập nhật dựa trên thời gian (User ngày xưa thích chơi đá bóng.Gẫy chân => Hiện tại thì không). 

- 
📌 **Mô hình sử dụng các công nghệ:**

- **LLM (GPT-4, Claude 3, Llama 2)**.
- **Vector Database (FAISS, Pinecone, Weaviate)** để lưu trí nhớ dài hạn.
- **LangChain / LlamaIndex** để quản lý truy xuất thông tin.

---

## **📌 4. Thực nghiệm & Kết quả (Experiments & Results)**

### **4.1. Thiết lập thử nghiệm**

**Bài toán:** So sánh hiệu suất giữa **Memory-Augmented AI Agent** và **LLM thông thường** trong hội thoại dài hạn.

🔹 **Dữ liệu thử nghiệm:**

- **Tập hội thoại thực tế** (chăm sóc khách hàng, trợ lý ảo).
- **Tập hội thoại tổng hợp** (hội thoại kéo dài > 10,000 tokens).
## 4. Thực nghiệm và đánh giá

### 4.1 Deep Memory Retrieval (DMR)

- **DMR** (giới thiệu trong MemGPT) có 500 cuộc hội thoại nhiều phiên (multi-session).
- Zep đạt **94.8%** độ chính xác khi dùng GPT-4-turbo (và 98.2% khi dùng một biến thể GPT-4o-mini), nhỉnh hơn so với MemGPT (93.4%).
- Tuy nhiên, bộ DMR chỉ có hội thoại khá ngắn (khoảng 60 tin nhắn mỗi cuộc), chưa thực sự kiểm tra khả năng “siêu dài hạn”.

### 4.2 LongMemEval (LME)

- **LongMemEval** có các đoạn hội thoại dài hơn nhiều (trung bình 115.000 tokens), mô phỏng tình huống doanh nghiệp thực tế phức tạp.

Các hệ thống trợ lý trò chuyện ngôn ngữ lớn gần đây (LLM) có các thành phần bộ nhớ tích hợp để theo dõi lịch sử trò chuyện có sự hỗ trợ của người dùng, cho phép các phản hồi chính xác và cá nhân hóa hơn. Tuy nhiên, khả năng bộ nhớ dài hạn của họ trong các tương tác bền vững vẫn chưa được khai thác. Bài viết này giới thiệu Longmemeval, một điểm chuẩn toàn diện được thiết kế để đánh giá năm khả năng bộ nhớ dài hạn cốt lõi của các trợ lý trò chuyện: trích xuất thông tin, lý luận đa phiên, lý luận thời gian, cập nhật kiến ​​thức và kiêng khem. Với 500 câu hỏi được quản lý tỉ mỉ được nhúng trong lịch sử trò chuyện hỗ trợ người dùng có thể mở rộng, Longmemeval đưa ra một thách thức đáng kể đối với các hệ thống bộ nhớ dài hạn hiện có, với các trợ lý trò chuyện thương mại và LLM bối cảnh dài cho thấy độ chính xác giảm 30% khi ghi nhớ thông tin qua các tương tác được duy trì. Sau đó, chúng tôi trình bày một khung thống nhất phân chia thiết kế bộ nhớ dài hạn thành bốn lựa chọn thiết kế trên các giai đoạn lập chỉ mục, truy xuất và đọc. Được xây dựng dựa trên những hiểu biết thử nghiệm quan trọng, chúng tôi đề xuất một số thiết kế bộ nhớ bao gồm phân tách phiên để tối ưu hóa mức độ chi tiết giá trị, mở rộng chính được thực hiện để tăng cường cấu trúc chỉ số và mở rộng truy vấn thời gian để tinh chỉnh phạm vi tìm kiếm. Kết quả thử nghiệm cho thấy các tối ưu hóa này cải thiện đáng kể cả việc thu hồi bộ nhớ và trả lời câu hỏi hạ nguồn trên longmemeval. Nhìn chung, nghiên cứu của chúng tôi cung cấp các nguồn lực và hướng dẫn có giá trị để thúc đẩy khả năng bộ nhớ dài hạn của các trợ lý trò chuyện dựa trên LLM, mở đường cho AI trò chuyện cá nhân hóa và đáng tin cậy hơn.

- Zep cải thiện kết quả so với baseline (dùng toàn bộ hội thoại) ở hầu hết các loại câu hỏi, đặc biệt:
    - Loại câu “multi-session,” “preference,” “temporal reasoning” tăng đáng kể.
    - Độ trễ (latency) giảm đến 90% so với việc nhét toàn bộ hội thoại vào prompt (vì prompt của Zep ngắn gọn hơn).
🔹 **Tiêu chí đánh giá:**

| **Tiêu chí**                  | **Memory-Augmented AI**          | **LLM thông thường**     |
| ----------------------------- | -------------------------------- | ------------------------ |
| **Khả năng duy trì bối cảnh** | ✅ Tốt                            | ❌ Kém                    |
| **Độ chính xác phản hồi**     | ✅ Cao hơn                        | ❌ Giảm khi hội thoại dài |
| **Tốc độ phản hồi**           | ❌ Chậm hơn                       | ✅ Nhanh hơn              |
| **Khả năng cá nhân hóa**      | ✅ Có thể nhớ sở thích người dùng | ❌ Không nhớ thông tin cũ |

Chi tiết các tiêu chí đánh giá: 

- **Trích xuất thông tin (Information Extraction)**: Khả năng nhớ lại thông tin cụ thể từ lịch sử tương tác dài, bao gồm cả chi tiết được đề cập bởi người dùng hoặc trợ lý.​[Di Wu](https://xiaowu0162.github.io/long-mem-eval/?utm_source=chatgpt.com)
    
- **Suy luận đa phiên (Multi-Session Reasoning)**: Khả năng tổng hợp thông tin từ nhiều phiên lịch sử để trả lời các câu hỏi phức tạp liên quan đến việc tổng hợp và so sánh.​
    
- **Suy luận thời gian (Temporal Reasoning)**: Nhận thức về các khía cạnh thời gian của thông tin người dùng, bao gồm cả các đề cập thời gian rõ ràng và siêu dữ liệu dấu thời gian trong các tương tác.​
    
- **Cập nhật kiến thức (Knowledge Updates)**: Khả năng nhận biết các thay đổi trong thông tin cá nhân của người dùng và cập nhật kiến thức về người dùng một cách động theo thời gian.​
    
- **Từ chối trả lời (Abstention)**: Khả năng từ chối trả lời các câu hỏi liên quan đến thông tin không được đề cập trong lịch sử tương tác, tức là thông tin không được nhắc đến trong lịch sử tương tác.
### **4.2. Kết quả thực nghiệm**

📌 **Memory-Augmented AI cải thiện 38% khả năng duy trì bối cảnh hội thoại so với LLM thông thường.**  
📌 **Tốc độ phản hồi chậm hơn ~10% nhưng độ chính xác tăng 25%.**

---

## **📌 5. Kết luận & Hướng phát triển (Conclusion & Future Work)**

### **5.1. Kết luận**

- **Memory-Augmented AI Agents có thể cải thiện đáng kể khả năng duy trì hội thoại dài hạn.**
- **Hạn chế của mô hình là tốc độ phản hồi, nhưng có thể tối ưu hóa.**

### **5.2. Hướng phát triển**

✅ **Tối ưu thuật toán quản lý bộ nhớ** để cải thiện tốc độ.  
✅ **Kết hợp với RAG** để AI có thể truy xuất thông tin từ dữ liệu ngoài.  
✅ **Mở rộng thử nghiệm trên nhiều lĩnh vực** như giáo dục, chăm sóc sức khỏe.

---

## **📌 6. Tài liệu tham khảo (References)**

- [KARMA: Memory-Augmented AI Research](https://arxiv.org/abs/2409.14908)
- [AriGraph: Knowledge Memory for LLMs](https://arxiv.org/abs/2407.04363)
- [Meta AI’s Memory-Augmented Chatbot](https://www.theverge.com/2025/1/27/24352992/meta-ai-memory-personalization)
