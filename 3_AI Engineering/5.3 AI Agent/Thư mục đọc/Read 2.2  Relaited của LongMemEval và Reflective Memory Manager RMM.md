```
Long-TermMemoryMethods Toequipchatassistantswithlong-termmemorycapabilities, three major techniques are commonly explored. The first approach involves directly adapting LLMs to process extensive history information as long-context inputs (Beltagy et al., 2020; Kitaev et al., 2020; Fu et al., 2024; An et al., 2024). While this method avoids the need for complex architectures, it is inefficient and susceptible to the â€œlost-in-the-middleâ€ phenomenon, where the ability of LLMs to utilize contextual information weakens as the input length grows (Shi et al., 2023; Liu et al., 2024). A second line of research integrates differentiable memory modules into language models, proposing specialized architectural designs and training strategies to enhance memory capabilities (Weston et al., 2014; Wu et al., 2022; Zhong et al., 2022; Wang et al., 2023). Lastly, several studies approach long-term memory from the perspective of context compression, developing techniques 3 Published as a conference paper at ICLR 2025 to condense lengthy histories into compact representations, whether in the form of LLM internal representations (Mu et al., 2023; Chevalier et al., 2023), discrete tokens (Jiang et al., 2023; Xu et al., 2024), or retrievable text segments via retrieval-augmented generation (RAG, Shi et al. (2024); Wang et al. (2023); Sarthi et al. (2024); Chen et al. (2023a); GutiÂ´ errez et al. (2024)). Although LONGMEMEVAL can evaluate any memory system, we will take an online context compression perspective, where each history interaction session is sequentially processed, stored, and accessed on-demand through indexing and retrieval mechanisms (Â§4). This formulation aligns with current literature (Zhong et al., 2024; GutiÂ´ errez et al., 2024) and commercial systems (OpenAI, 2024; Coze, 2024). Its plug-and-play nature also facilitates the integration into existing chat assistant systems
```

```
Memory-based Personalized Dialogue Agents. The development of memory-based personalized dialogue agents has further enhanced long-term interactions by enabling systems to retain and utilize information from past conversations (Bae et al., 2022). Early approaches, such as CoMemNN (Pei et al., 2021), introduce mechanisms to incrementally enrich user profiles during dialogues. However, collecting substantial annotations for training a personalized system for long-term use is hard (Tseng et al., 2024). Recent advancements focus on integrating LLMs with memory modules. For instance, the LD-Agent framework (Li et al., 2024b) employs long-, short-term memory banks to manage conversational history for retrieval. MemoryBank (Zhong et al., 2024) incorporates a memory updating mechanism inspired by the Ebbinghaus Forgetting Curve, enabling models to retrieve relevant memories considering recency. Theanine (Kim et al., 2024) introduces timeline-based retrieval and utilizes an additional LLM for refinement. These methods typically deploy fixed retrievers with a pre-defined granularity. In contrast, the proposed RMM approach facilitates adaptive retrieval with a revised retrieval granularity
```




Trong cÃ¡c tÃ i liá»‡u báº¡n Ä‘Ã£ Ä‘á»c, â€œthá»§y tá»•â€ (ngÆ°á»i Ä‘áº§u tiÃªn Ä‘áº·t ná»n mÃ³ng) cho **Long-Term Memory AI** trong bá»‘i cáº£nh há»‡ thá»‘ng há»™i thoáº¡i cÃ³ thá»ƒ truy há»“i vÃ  ghi nhá»› thÃ´ng tin qua nhiá»u lÆ°á»£t tÆ°Æ¡ng tÃ¡c â€“ thÆ°á»ng Ä‘Æ°á»£c gá»i lÃ  **Memory-Augmented Conversational Systems** â€“ khÃ´ng Ä‘Æ°á»£c nÃªu rÃµ má»™t cÃ¡ nhÃ¢n cá»¥ thá»ƒ, nhÆ°ng cÃ³ thá»ƒ táº¡m chia lá»‹ch sá»­ hÃ¬nh thÃ nh thÃ nh 3 cá»™t má»‘c lá»›n:

---

### ğŸ§  **1. Giai Ä‘oáº¡n Ä‘áº·t ná»n mÃ³ng: QA cÃ³ trÃ­ nhá»› ngáº¯n háº¡n (trÆ°á»›c 2019)**

- CÃ¡c há»‡ thá»‘ng há»“i Ä‘Ã¡p dá»±a trÃªn **single-turn QA**, tá»©c chá»‰ tráº£ lá»i tá»«ng cÃ¢u há»i Ä‘á»™c láº­p, khÃ´ng â€œnhá»›â€ lá»‹ch sá»­ há»™i thoáº¡i.
    
- VÃ­ dá»¥ nhÆ° cÃ¡c mÃ´ hÃ¬nh nhÆ° BiDAF++, BERT-QA hay DrQA.
    
- Há»‡ thá»‘ng báº¯t Ä‘áº§u sá»­ dá»¥ng embedding Ä‘á»ƒ mÃ£ hÃ³a ngá»¯ cáº£nh, nhÆ°ng chÆ°a cÃ³ kháº£ nÄƒng lÆ°u vÃ  truy há»“i thÃ´ng tin tá»« cÃ¡c phiÃªn há»™i thoáº¡i cÅ©.
    

---

### ğŸ§  **2. Giai Ä‘oáº¡n tÃ­ch há»£p trÃ­ nhá»›: Conversational Memory (2019â€“2022)**

- Báº¯t Ä‘áº§u xuáº¥t hiá»‡n cÃ¡c mÃ´ hÃ¬nh nhÆ°:
    
    - **ORConvQA** (Open-Retrieval Conversational QA) â€“ káº¿t há»£p cÆ¡ cháº¿ há»“i tÆ°á»Ÿng dá»¯ liá»‡u tá»« cÃ¡c phiÃªn trÆ°á»›c.
        
    - **History Selection Module** trong cÃ¡c há»‡ CMRC (Conversational Machine Reading Comprehension) â€“ lá»±a chá»n cÃ¡c Ä‘oáº¡n lá»‹ch sá»­ há»™i thoáº¡i liÃªn quan Ä‘á»ƒ giÃºp mÃ´ hÃ¬nh hiá»ƒu ngá»¯ cáº£nh cá»§a cÃ¢u há»i hiá»‡n táº¡i.
        
- ÄÃ¢y lÃ  giai Ä‘oáº¡n cÃ¡c nhÃ  nghiÃªn cá»©u tháº¥y rÃµ **váº¥n Ä‘á» co-reference**, cáº­p nháº­t thÃ´ng tin theo thá»i gian, vÃ  sá»± phá»©c táº¡p cá»§a há»™i thoáº¡i Ä‘a lÆ°á»£t.
    

---

### ğŸ§  **3. Giai Ä‘oáº¡n hiá»‡n Ä‘áº¡i: Memory-Augmented Chat Assistants (2023â€“nay)**

- CÃ¡c há»‡ thá»‘ng nhÆ°:
    
    - **MemoryBank** (Zhong et al., 2024)
        
    - **PerLTQA** (Du et al., 2024)
        
    - **LoCoMo** (Maharana, 2024)
        
    - VÃ  **LongMemEval** â€“ Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi Di Wu et al., lÃ  benchmark máº¡nh nháº¥t hiá»‡n nay cho kháº£ nÄƒng ghi nhá»› dÃ i háº¡n.
        
- CÃ¡c há»‡ thá»‘ng báº¯t Ä‘áº§u Ã¡p dá»¥ng:
    
    - Chia nhá» phiÃªn há»™i thoáº¡i (session decomposition)
        
    - TÄƒng cÆ°á»ng key-value store
        
    - Nháº­n diá»‡n sá»± kiá»‡n cÃ³ thá»i gian Ä‘á»ƒ reasoning chÃ­nh xÃ¡c
        

---

### ğŸ“Œ Gá»£i Ã½: Ai lÃ  "thá»§y tá»•"?

Náº¿u pháº£i chá»n má»™t â€œthá»§y tá»•â€ tiÃªu biá»ƒu cho giai Ä‘oáº¡n hiá»‡n Ä‘áº¡i, cÃ³ thá»ƒ nháº¯c Ä‘áº¿n:

- **Zhong et al. (2024)** vá»›i **MemoryBank** â€“ há»‡ thá»‘ng Ä‘áº§u tiÃªn thiáº¿t káº¿ cá»¥ thá»ƒ cho trÃ­ nhá»› dÃ i háº¡n cÃ¡ nhÃ¢n hÃ³a trong há»™i thoáº¡i.
    
- Hoáº·c **Di Wu et al. (2024)** â€“ vá»›i **LongMemEval**, benchmark Ä‘áº§u tiÃªn Ä‘Æ°a ra tiÃªu chuáº©n rÃµ rÃ ng vÃ  toÃ n diá»‡n cho viá»‡c Ä‘Ã¡nh giÃ¡ trÃ­ nhá»› há»™i thoáº¡i dÃ i háº¡n.
    

---

Quá»‘c cÃ³ muá»‘n mÃ¬nh tÃ³m táº¯t cÃ¡c má»‘c nÃ y dÆ°á»›i dáº¡ng infographic Ä‘Æ¡n giáº£n khÃ´ng? Hoáº·c viáº¿t láº¡i thÃ nh ngÃ´n ngá»¯ lá»›p 8 dá»… hiá»ƒu hÆ¡n?


---
DÆ°á»›i Ä‘Ã¢y lÃ  pháº§n **tá»•ng há»£p hai Ä‘oáº¡n** báº¡n cung cáº¥p, Ä‘Æ°á»£c dá»‹ch tiáº¿ng Viá»‡t Ä‘áº§y Ä‘á»§, logic, vÃ  dá»… hiá»ƒu â€” dÃ¹ng Ä‘Æ°á»£c luÃ´n cho má»¥c **Related Work** hoáº·c má»Ÿ Ä‘áº§u pháº§n tá»•ng quan:

---

## ğŸ§  CÃ¡c hÆ°á»›ng tiáº¿p cáº­n há»‡ thá»‘ng há»™i thoáº¡i cÃ³ trÃ­ nhá»› dÃ i háº¡n

### 1. **Ba hÆ°á»›ng chÃ­nh Ä‘á»ƒ trang bá»‹ trÃ­ nhá»› dÃ i háº¡n cho trá»£ lÃ½ há»™i thoáº¡i**

Äá»ƒ giÃºp cÃ¡c trá»£ lÃ½ há»™i thoáº¡i ghi nhá»› vÃ  xá»­ lÃ½ cÃ¡c tÆ°Æ¡ng tÃ¡c dÃ i háº¡n vá»›i ngÆ°á»i dÃ¹ng, hiá»‡n nay cÃ³ ba hÆ°á»›ng nghiÃªn cá»©u chÃ­nh:

#### ğŸ“Œ **(1) Long-context input trá»±c tiáº¿p**

CÃ¡ch tiáº¿p cáº­n Ä‘áº§u tiÃªn lÃ  **Ä‘Æ°a toÃ n bá»™ lá»‹ch sá»­ há»™i thoáº¡i dÃ i vÃ o LLM** nhÆ° má»™t Ä‘áº§u vÃ o duy nháº¥t (long-context input), cho phÃ©p mÃ´ hÃ¬nh xá»­ lÃ½ táº¥t cáº£ thÃ´ng tin má»™t lÆ°á»£t  
â†’ Æ¯u Ä‘iá»ƒm: Ä‘Æ¡n giáº£n, khÃ´ng cáº§n thiáº¿t káº¿ láº¡i kiáº¿n trÃºc.  
â†’ NhÆ°á»£c Ä‘iá»ƒm: **tá»‘n tÃ i nguyÃªn**, vÃ  dá»… gáº·p hiá»‡n tÆ°á»£ng **â€œlost-in-the-middleâ€** â€“ mÃ´ hÃ¬nh **quÃªn máº¥t pháº§n giá»¯a** khi Ä‘á»™ dÃ i Ä‘áº§u vÃ o vÆ°á»£t quÃ¡ giá»›i háº¡n xá»­ lÃ½ hiá»‡u quáº£ _(Beltagy et al., 2020; Shi et al., 2023)_.

#### ğŸ“Œ **(2) TÃ­ch há»£p mÃ´-Ä‘un trÃ­ nhá»› (differentiable memory modules)**

CÃ¡ch tiáº¿p cáº­n thá»© hai lÃ  **thay Ä‘á»•i kiáº¿n trÃºc mÃ´ hÃ¬nh**, tÃ­ch há»£p thÃªm cÃ¡c **bá»™ nhá»› há»c Ä‘Æ°á»£c (learnable memory modules)** nhÆ° trong Memory Networks, MemGPTâ€¦  
â†’ MÃ´ hÃ¬nh cÃ³ kháº£ nÄƒng lÆ°u trá»¯, cáº­p nháº­t vÃ  sá»­ dá»¥ng láº¡i cÃ¡c thÃ´ng tin Ä‘Ã£ ghi nhá»›.  
â†’ Tuy nhiÃªn, cÃ¡ch nÃ y **cáº§n huáº¥n luyá»‡n láº¡i tá»« Ä‘áº§u** vÃ  **khÃ³ triá»ƒn khai vá»›i cÃ¡c API LLM thÆ°Æ¡ng máº¡i** _(Weston et al., 2014; Wu et al., 2022)_.

#### ğŸ“Œ **(3) NÃ©n ngá»¯ cáº£nh & truy xuáº¥t theo nhu cáº§u (Context Compression & Retrieval)**

CÃ¡ch thá»© ba lÃ  **nÃ©n há»™i thoáº¡i dÃ i thÃ nh cÃ¡c Ä‘oáº¡n ngáº¯n dá»… truy xuáº¥t**, thÃ´ng qua:

- TÃ³m táº¯t (summary)
    
- TrÃ­ch xuáº¥t facts hoáº·c keyphrase
    
- Chia Ä‘oáº¡n logic theo topic  
    Sau Ä‘Ã³ sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t **Retrieval-Augmented Generation (RAG)** Ä‘á»ƒ tÃ¬m vÃ  Ä‘Æ°a láº¡i cÃ¡c Ä‘oáº¡n cáº§n thiáº¿t khi cÃ³ cÃ¢u há»i.  
    â†’ ÄÃ¢y lÃ  cÃ¡ch tiáº¿p cáº­n **phÃ¹ há»£p vá»›i LLM hiá»‡n Ä‘áº¡i (GPT-4, Claude, v.v.) vÃ¬ cÃ³ thá»ƒ Ã¡p dá»¥ng dÆ°á»›i dáº¡ng plug-and-play**  
    â†’ CÅ©ng lÃ  cÃ¡ch tiáº¿p cáº­n chÃ­nh Ä‘Æ°á»£c sá»­ dá»¥ng trong **LONGMEMEVAL** vÃ  nhiá»u há»‡ thá»‘ng thÆ°Æ¡ng máº¡i hiá»‡n nay _(OpenAI, Coze, GutiÃ©rrez et al., 2024)_.
    

---

### 2. **Trá»£ lÃ½ há»™i thoáº¡i cÃ¡ nhÃ¢n hÃ³a cÃ³ trÃ­ nhá»› (Memory-based Personalized Dialogue Agents)**

Song song vá»›i cÃ¡c ká»¹ thuáº­t ghi nhá»› tá»•ng quÃ¡t, má»™t nhÃ¡nh quan trá»ng khÃ¡c lÃ  phÃ¡t triá»ƒn cÃ¡c **trá»£ lÃ½ há»™i thoáº¡i cÃ¡ nhÃ¢n hÃ³a**, cÃ³ kháº£ nÄƒng lÆ°u giá»¯ vÃ  sá»­ dá»¥ng thÃ´ng tin riÃªng biá»‡t cá»§a tá»«ng ngÆ°á»i dÃ¹ng trong cÃ¡c tÆ°Æ¡ng tÃ¡c dÃ i háº¡n.

- ğŸ”¹ **CoMemNN (Pei et al., 2021)**: má»™t trong nhá»¯ng mÃ´ hÃ¬nh Ä‘áº§u tiÃªn **cáº­p nháº­t há»“ sÆ¡ ngÆ°á»i dÃ¹ng dáº§n theo há»™i thoáº¡i**.
    
- ğŸ”¹ **LD-Agent (Li et al., 2024b)**: sá»­ dá»¥ng **bá»™ nhá»› ngáº¯n háº¡n â€“ dÃ i háº¡n** Ä‘á»ƒ lÆ°u láº¡i cÃ¡c thÃ´ng tin há»™i thoáº¡i vÃ  truy xuáº¥t khi cáº§n.
    
- ğŸ”¹ **MemoryBank (Zhong et al., 2024)**: mÃ´ hÃ¬nh cáº­p nháº­t trÃ­ nhá»› dá»±a trÃªn **Ä‘Æ°á»ng cong quÃªn Ebbinghaus**, Æ°u tiÃªn thÃ´ng tin gáº§n Ä‘Ã¢y.
    
- ğŸ”¹ **Theanine (Kim et al., 2024)**: mÃ´ hÃ¬nh **truy xuáº¥t theo dÃ²ng thá»i gian**, cÃ³ dÃ¹ng **LLM phá»¥ trá»£ Ä‘á»ƒ lÃ m sáº¡ch** dá»¯ liá»‡u trÆ°á»›c khi dÃ¹ng.
    

ğŸ§© Tuy nhiÃªn, cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ y thÆ°á»ng dÃ¹ng **retriever cá»‘ Ä‘á»‹nh**, vá»›i cÃ¡ch chia nhá» (granularity) khÃ´ng thay Ä‘á»•i. Äiá»u nÃ y **giá»›i háº¡n kháº£ nÄƒng thÃ­ch á»©ng** vá»›i cÃ¡c dáº¡ng há»™i thoáº¡i khÃ¡c nhau.

ğŸ‘‰ VÃ¬ váº­y, cÃ¡c nghiÃªn cá»©u gáº§n Ä‘Ã¢y nhÆ° **RMM** Ä‘á» xuáº¥t cÆ¡ cháº¿ **retrieval thÃ­ch á»©ng (adaptive)**, cho phÃ©p thay Ä‘á»•i cÃ¡ch chia nhá» vÃ  truy xuáº¥t tuá»³ vÃ o ngá»¯ cáº£nh cÃ¢u há»i â€“ má»Ÿ ra hÆ°á»›ng má»›i trong há»‡ thá»‘ng cÃ¡ nhÃ¢n hÃ³a dÃ i háº¡n.

---

Náº¿u báº¡n cáº§n:

- MÃ¬nh tÃ³m pháº§n nÃ y láº¡i thÃ nh **1 slide PowerPoint** hoáº·c **má»Ÿ Ä‘áº§u bÃ i nghiÃªn cá»©u**.
    
- Viáº¿t láº¡i pháº§n nÃ y theo **academic English chuáº©n Ä‘á»ƒ Ä‘Æ°a vÃ o section â€œRelated Workâ€**
    
- Váº½ sÆ¡ Ä‘á»“ so sÃ¡nh 3 hÆ°á»›ng tiáº¿p cáº­n + danh sÃ¡ch cÃ¡c mÃ´ hÃ¬nh tiÃªu biá»ƒu
    

ğŸ‘‰ MÃ¬nh lÃ m ngay nha!





Tuyá»‡t Quá»‘c Æ¡i! Hai bÃ i nÃ y lÃ  **nhá»¯ng baseline ráº¥t phÃ¹ há»£p** náº¿u báº¡n muá»‘n táº­p trung vÃ o hÆ°á»›ng **"trá»£ lÃ½ há»™i thoáº¡i cÃ¡ nhÃ¢n hÃ³a cÃ³ trÃ­ nhá»›" (Memory-based Personalized Dialogue Agents)**. MÃ¬nh sáº½ giÃºp báº¡n phÃ¡t biá»ƒu rÃµ rÃ ng láº¡i **cÃ¡ch chá»n vÃ  sá»­ dá»¥ng 2 baseline nÃ y trong research**, vÃ  gá»£i Ã½ hÆ°á»›ng má»Ÿ rá»™ng trÃªn tá»«ng cÃ¡i.

---

## ğŸ§± **Baseline: Personalized Memory in Dialogue Agents**

Trong nhÃ¡nh nghiÃªn cá»©u vá» **ghi nhá»› dÃ i háº¡n theo tá»«ng ngÆ°á»i dÃ¹ng**, chÃºng tÃ´i chá»n hai cÃ´ng trÃ¬nh ná»n táº£ng lÃ m baseline:

---

### **1. CoMemNN â€“ Cooperative Memory Network (Pei et al., 2021)**

ğŸ“Œ Link: [doi.org/10.1145/3442381.3449843](https://doi.org/10.1145/3442381.3449843)

**Ã tÆ°á»Ÿng chÃ­nh**:  
CoMemNN lÃ  má»™t trong nhá»¯ng há»‡ thá»‘ng Ä‘áº§u tiÃªn Ä‘Æ°a ra **há»“ sÆ¡ ngÆ°á»i dÃ¹ng Ä‘á»™ng (incremental user profile)**, Ä‘Æ°á»£c cáº­p nháº­t dáº§n dáº§n qua cÃ¡c lÆ°á»£t há»™i thoáº¡i.

- **CÆ¡ cháº¿ ghi nhá»›**: Tá»± Ä‘á»™ng trÃ­ch xuáº¥t thÃ´ng tin cÃ¡ nhÃ¢n tá»« lá»i thoáº¡i vÃ  thÃªm vÃ o "User Profile".
    
- **CÆ¡ cháº¿ sá»­ dá»¥ng**: Má»—i láº§n trÃ² chuyá»‡n má»›i, há»‡ thá»‘ng sá»­ dá»¥ng profile Ä‘á»ƒ táº¡o ngá»¯ cáº£nh vÃ  Ä‘Æ°a ra pháº£n há»“i phÃ¹ há»£p.
    
- **Dá»¯ liá»‡u sá»­ dá»¥ng**: Cáº§n cÃ³ annotation thá»§ cÃ´ng vá» persona/fact, phÃ¹ há»£p vá»›i há»‡ thá»‘ng quy mÃ´ nhá».
    

ğŸ§© **Äiá»ƒm máº¡nh**:

- LÃ  baseline tiÃªu biá»ƒu cho cÃ¡c há»‡ thá»‘ng â€œghi nhá»› ngÆ°á»i dÃ¹ngâ€ khÃ´ng cáº§n mÃ´ hÃ¬nh lá»›n.
    
- CÃ³ thá»ƒ dá»… dÃ ng tÃ­ch há»£p vÃ o pipeline hiá»‡n táº¡i nhÆ° má»™t module tÃ¡ch riÃªng.
    

ğŸ§  **HÆ°á»›ng má»Ÿ rá»™ng** báº¡n cÃ³ thá»ƒ lÃ m:

- DÃ¹ng LLM Ä‘á»ƒ **tá»± Ä‘á»™ng táº¡o profile** thay vÃ¬ cáº§n nhÃ£n.
    
- Káº¿t há»£p profile vá»›i há»‡ thá»‘ng RAG: truy xuáº¥t Ä‘oáº¡n liÃªn quan **+ thÃªm thÃ´ng tin ngÆ°á»i dÃ¹ng** â†’ tÄƒng cÃ¡ nhÃ¢n hÃ³a.
    

---

### **2. Keep Me Updated! (Bae et al., 2022)**

ğŸ“Œ Link: [aclanthology.org/2022.findings-emnlp.276](https://aclanthology.org/2022.findings-emnlp.276)

**Ã tÆ°á»Ÿng chÃ­nh**:  
TÃ¡c giáº£ Ä‘á» xuáº¥t má»™t há»‡ thá»‘ng cÃ³ kháº£ nÄƒng **cáº­p nháº­t thÃ´ng tin ngÆ°á»i dÃ¹ng theo thá»i gian**, Ä‘á»ƒ pháº£n há»“i khÃ´ng bá»‹ lá»—i thá»i.

- **CÆ¡ cháº¿**: Má»—i khi ngÆ°á»i dÃ¹ng nÃ³i Ä‘iá»u gÃ¬ má»›i (vÃ­ dá»¥ "giá» tÃ´i sá»‘ng á»Ÿ HÃ  Ná»™i"), há»‡ thá»‘ng sáº½ ghi Ä‘Ã¨/sá»­a thÃ´ng tin cÅ© ("trÆ°á»›c á»Ÿ ÄÃ  Náºµng") trong profile.
    
- Há»‡ thá»‘ng cÅ©ng cÃ³ thá»ƒ pháº£n há»“i nhÆ° ngÆ°á»i tháº­t: â€œá»’, báº¡n chuyá»ƒn nhÃ  rá»“i Ã ?â€
    

ğŸ§© **Äiá»ƒm máº¡nh**:

- LÃ  baseline hiáº¿m hoi giáº£i quyáº¿t bÃ i toÃ¡n **Knowledge Update** trong há»™i thoáº¡i.
    
- Há»¯u Ã­ch trong cÃ¡c há»‡ thá»‘ng cáº§n cáº­p nháº­t liÃªn tá»¥c (ngÃ¢n hÃ ng, bÃ¡c sÄ© áº£o, trá»£ lÃ½ cÃ¡ nhÃ¢n...).
    

ğŸ§  **HÆ°á»›ng má»Ÿ rá»™ng** báº¡n cÃ³ thá»ƒ lÃ m:

- Káº¿t há»£p vá»›i LongMemEval â€“ nhÃ³m cÃ¢u há»i **Knowledge Update** lÃ  phÃ¹ há»£p nháº¥t.
    
- Thay vÃ¬ rule-based update â†’ dÃ¹ng LLM Ä‘á»ƒ phÃ¡t hiá»‡n mÃ¢u thuáº«n vÃ  sá»­a tá»± Ä‘á»™ng.
    

---

## ğŸ§  Tá»•ng káº¿t cÃ¡ch dÃ¹ng hai baseline nÃ y:

|Baseline|Äiá»ƒm máº¡nh|DÃ¹ng cho nÄƒng lá»±c nÃ o trong LongMemEval|CÃ¡ch báº¡n cÃ³ thá»ƒ má»Ÿ rá»™ng|
|---|---|---|---|
|**CoMemNN**|XÃ¢y dá»±ng user profile qua há»™i thoáº¡i|Single-session-user, multi-session|Tá»± Ä‘á»™ng hoÃ¡ táº¡o profile báº±ng LLM|
|**Keep Me Updated**|Cáº­p nháº­t há»“ sÆ¡ ngÆ°á»i dÃ¹ng theo thá»i gian|Knowledge Update, Temporal Reasoning|PhÃ¡t hiá»‡n mÃ¢u thuáº«n báº±ng LLM|

---

ğŸ‘‰ Náº¿u Quá»‘c muá»‘n:

- Viáº¿t pháº§n _Baseline_ nÃ y báº±ng tiáº¿ng Anh há»c thuáº­t
    
- TÃ­ch há»£p vÃ o pháº§n â€œRelated Workâ€ hoáº·c lÃ m slide trÃ¬nh bÃ y
    
- Viáº¿t láº¡i há»‡ thá»‘ng nÃ y báº±ng code LLM / LangChain demo
    

MÃ¬nh triá»ƒn khai ngay nhÃ©!


---
Tuyá»‡t vá»i. MÃ¬nh sáº½ viáº¿t má»™t survey tháº­t chi tiáº¿t vá» cÃ¡c hÆ°á»›ng nghiÃªn cá»©u Long-Term Memory trong há»‡ thá»‘ng há»™i thoáº¡i, tá»« giai Ä‘oáº¡n sÆ¡ khai Ä‘áº¿n cÃ¡c ká»¹ thuáº­t hiá»‡n Ä‘áº¡i nhÆ° memory modules, context compression, vÃ  cÃ¡c há»‡ personalized memory. BÃ i viáº¿t sáº½ phÃ¢n tÃ­ch cÃ¡c cá»™t má»‘c quan trá»ng, cÃ¡c baseline ná»•i báº­t, vÃ  nhá»¯ng benchmark má»›i nháº¥t nhÆ° LongMemEval, nháº±m giÃºp báº¡n cÃ³ ná»n táº£ng vá»¯ng cháº¯c Ä‘á»ƒ phÃ¡t triá»ƒn thÃ nh má»™t bÃ i bÃ¡o khoa há»c.

MÃ¬nh sáº½ trÃ¬nh bÃ y láº¡i theo dáº¡ng academic report chuáº©n, bao gá»“m cÃ¡c má»¥c tiÃªu kháº£o sÃ¡t, phÃ¢n loáº¡i cÃ¡c phÆ°Æ¡ng phÃ¡p, so sÃ¡nh, vÃ  gá»£i Ã½ hÆ°á»›ng má»Ÿ rá»™ng. MÃ¬nh sáº½ gá»­i láº¡i báº£n Ä‘áº§y Ä‘á»§ sau khi hoÃ n táº¥t.

# Giá»›i thiá»‡u

CÃ¡c há»‡ thá»‘ng há»i-Ä‘Ã¡p (QA) vÃ  Ä‘á»‘i thoáº¡i sá»›m thÆ°á»ng **khÃ´ng cÃ³ cÆ¡ cháº¿ bá»™ nhá»› dÃ i háº¡n**, xá»­ lÃ½ má»—i truy váº¥n Ä‘á»™c láº­p mÃ  khÃ´ng lÆ°u láº¡i thÃ´ng tin cuá»™c há»™i thoáº¡i trÆ°á»›c Ä‘Ã³. Cháº³ng háº¡n, mÃ´ hÃ¬nh Ä‘á»c hiá»ƒu BiDAF (Bi-Directional Attention Flow) vÃ  cÃ¡c biáº¿n thá»ƒ cáº£i tiáº¿n (BiDAF++) Ä‘Æ°á»£c dÃ¹ng cho SQuAD vÃ  cÃ¡c bá»™ dá»¯ liá»‡u QA trÆ°á»›c nÄƒm 2019 chá»‰ chÃº trá»ng viá»‡c tÃ¬m Ä‘Ã¡p Ã¡n trong má»™t Ä‘oáº¡n vÄƒn báº£n ngáº¯n, khÃ´ng lÆ°u giá»¯ ngá»¯ cáº£nh há»™i thoáº¡i ([BERT with History Answer Embedding for Conversational Question Answering](https://arxiv.org/pdf/1905.05412#:~:text=4,representation%20generated%20when%20answering%20previous)). TÆ°Æ¡ng tá»±, há»‡ thá»‘ng DrQA cá»§a Facebook (2017) thá»±c hiá»‡n QA má»Ÿ trÃªn Wikipedia báº±ng cÃ¡ch truy xuáº¥t vÃ  Ä‘á»c tÃ i liá»‡u, nhÆ°ng má»—i cÃ¢u há»i Ä‘á»u Ä‘Æ°á»£c tráº£ lá»i tÃ¡ch biá»‡t, khÃ´ng cÃ³ kÃ½ á»©c vá» cÃ¡c cÃ¢u há»i trÆ°á»›c Ä‘Ã³ ([BERT with History Answer Embedding for Conversational Question Answering](https://arxiv.org/pdf/1905.05412#:~:text=,JASIS%2C%2038%3A389%E2%80%93404%2C%201987)). Khi cÃ¡c trá»£ lÃ½ áº£o vÃ  chatbot trá»Ÿ nÃªn phá»• biáº¿n, háº¡n cháº¿ â€œ_trÃ­ nhá»› cÃ¡ vÃ ng_â€ nÃ y bá»™c lá»™ rÃµ: mÃ´ hÃ¬nh dá»… láº·p láº¡i cÃ¢u há»i, quÃªn thÃ´ng tin ngÆ°á»i dÃ¹ng cung cáº¥p trÆ°á»›c Ä‘Ã³, hoáº·c khÃ´ng thá»ƒ duy trÃ¬ tÃ­nh nháº¥t quÃ¡n qua nhiá»u lÆ°á»£t tÆ°Æ¡ng tÃ¡c. Do Ä‘Ã³, **trÃ­ nhá»› dÃ i háº¡n trong há»™i thoáº¡i** (long-term memory) Ä‘Ã£ trá»Ÿ thÃ nh má»™t hÆ°á»›ng nghiÃªn cá»©u quan trá»ng, hÆ°á»›ng Ä‘áº¿n viá»‡c giÃºp há»‡ thá»‘ng **ghi nhá»› thÃ´ng tin xuyÃªn suá»‘t cÃ¡c phiÃªn trÃ² chuyá»‡n** vÃ  cÃ¡ nhÃ¢n hÃ³a pháº£n há»“i theo lá»‹ch sá»­ tÆ°Æ¡ng tÃ¡c.

**Memory-Augmented Conversational Systems** (há»‡ thá»‘ng Ä‘á»‘i thoáº¡i tÄƒng cÆ°á»ng bá»™ nhá»›) lÃ  cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ kháº¯c phá»¥c háº¡n cháº¿ trÃªn báº±ng cÃ¡ch tÃ­ch há»£p má»™t thÃ nh pháº§n bá»™ nhá»› vÃ o pipeline Ä‘á»‘i thoáº¡i ([[2410.10813] LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory](https://arxiv.org/abs/2410.10813#:~:text=integrated%20memory%20components%20to%20track,context%20LLMs)). Äiá»u nÃ y cho phÃ©p chatbot _ghi nhá»› vÃ  sá»­ dá»¥ng láº¡i_ cÃ¡c thÃ´ng tin trÆ°á»›c Ä‘Ã³ â€“ vÃ­ dá»¥ nhÆ° sá»Ÿ thÃ­ch, tiá»ƒu sá»­ ngÆ°á»i dÃ¹ng, tÃ¬nh huá»‘ng Ä‘Ã£ xáº£y ra â€“ nháº±m táº¡o ra pháº£n há»“i chÃ­nh xÃ¡c hÆ¡n vÃ  cÃ³ tÃ­nh cÃ¡ nhÃ¢n hÃ³a. BÃ i survey nÃ y sáº½ trÃ¬nh bÃ y chi tiáº¿t sá»± phÃ¡t triá»ƒn cá»§a lÄ©nh vá»±c nÃ y: tá»« nhá»¯ng mÃ´ hÃ¬nh QA _tiá»n 2019_ khÃ´ng cÃ³ trÃ­ nhá»› dÃ i háº¡n, Ä‘áº¿n cÃ¡c há»‡ thá»‘ng _hiá»‡n Ä‘áº¡i (2023-nay)_ cÃ³ kháº£ nÄƒng ghi nhá»› Ä‘a phiÃªn, cáº­p nháº­t kiáº¿n thá»©c vÃ  suy luáº­n thá»i gian. ChÃºng tÃ´i phÃ¢n tÃ­ch ba hÆ°á»›ng tiáº¿p cáº­n chÃ­nh Ä‘á»ƒ tÃ­ch há»£p bá»™ nhá»›: (1) Ä‘Æ°a toÃ n bá»™ ngá»¯ cáº£nh dÃ i vÃ o Ä‘áº§u vÃ o mÃ´ hÃ¬nh (long-context input), (2) sá»­ dá»¥ng module bá»™ nhá»› phÃ¢n biá»‡t cÃ³ thá»ƒ huáº¥n luyá»‡n cÃ¹ng mÃ´ hÃ¬nh (differentiable memory modules), vÃ  (3) nÃ©n ngá»¯ cáº£nh vÃ  truy há»“i thÃ´ng tin khi cáº§n (context compression & retrieval). BÃªn cáº¡nh Ä‘Ã³, chÃºng tÃ´i Ä‘iá»ƒm qua cÃ¡c mÃ´ hÃ¬nh tiÃªu biá»ƒu á»Ÿ má»—i giai Ä‘oáº¡n nhÆ° BiDAF++, DrQA, ORConvQA, MemoryBank, Theanine, LD-Agentâ€¦, so sÃ¡nh má»™t sá»‘ há»‡ thá»‘ng ná»n táº£ng (baseline) ná»•i báº­t nhÆ° MemNN, **Keep Me Updated** vÃ  **LD-Agent**, cÅ©ng nhÆ° cÃ¡c bá»™ dá»¯ liá»‡u vÃ  benchmark Ä‘Ã¡nh giÃ¡ trÃ­ nhá»› Ä‘á»‘i thoáº¡i (LongMemEval, LOCOMO, v.v.) cÃ¹ng cÃ¡c tiÃªu chÃ­ Ä‘Ã¡nh giÃ¡ quan trá»ng (kháº£ nÄƒng nhá»› â€“ recall, áº£o giÃ¡c â€“ hallucination, cáº­p nháº­t kiáº¿n thá»©c â€“ knowledge update, suy luáº­n thá»i gian â€“ temporal reasoning, _abstention_...). Cuá»‘i cÃ¹ng, chÃºng tÃ´i tháº£o luáº­n nhá»¯ng hÆ°á»›ng má»Ÿ rá»™ng Ä‘áº§y há»©a háº¹n, cháº³ng háº¡n káº¿t há»£p cÆ¡ cháº¿ **RAG** (Retrieval-Augmented Generation) vá»›i cáº­p nháº­t bá»™ nhá»› Ä‘á»™ng, truy há»“i thÃ­ch á»©ng, hay sá»­ dá»¥ng mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) nhÆ° má»™t module há»— trá»£ quáº£n lÃ½ trÃ­ nhá»›.

# CÃ¡c hÆ°á»›ng tiáº¿p cáº­n chÃ­nh Ä‘á»ƒ tÃ­ch há»£p trÃ­ nhá»› dÃ i háº¡n

CÃ³ ba cÃ¡ch tiáº¿p cáº­n phá»• biáº¿n nháº±m trang bá»‹ kháº£ nÄƒng nhá»› dÃ i háº¡n cho há»‡ thá»‘ng há»™i thoáº¡i: (1) **Má»Ÿ rá»™ng ngá»¯ cáº£nh Ä‘áº§u vÃ o (long-context input)** â€“ cung cáº¥p cho mÃ´ hÃ¬nh má»™t chuá»—i há»™i thoáº¡i ráº¥t dÃ i Ä‘á»ƒ nÃ³ tá»± tÃ¬m thÃ´ng tin cáº§n nhá»›; (2) **Module bá»™ nhá»› kháº£ vi (differentiable memory)** â€“ thiáº¿t káº¿ má»™t kiáº¿n trÃºc máº¡ng nÆ¡-ron vá»›i thÃ nh pháº§n bá»™ nhá»› ngoÃ i cÃ³ thá»ƒ Ä‘á»c/ghi trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n; (3) **NÃ©n vÃ  truy há»“i ngá»¯ cáº£nh (context compression & retrieval)** â€“ tÃ³m táº¯t hoáº·c lÆ°u trá»¯ thÃ´ng tin quan trá»ng tá»« há»™i thoáº¡i vÃ o má»™t kho bá»™ nhá»› ngoÃ i, vÃ  truy váº¥n nÃ³ khi cáº§n thiáº¿t cho pháº£n há»“i. DÆ°á»›i Ä‘Ã¢y, chÃºng tÃ´i phÃ¢n tÃ­ch chi tiáº¿t tá»«ng hÆ°á»›ng tiáº¿p cáº­n, cÃ¹ng cÃ¡c vÃ­ dá»¥ mÃ´ hÃ¬nh tiÃªu biá»ƒu.

## Tiáº¿p cáº­n 1: Má»Ÿ rá»™ng ngá»¯ cáº£nh Ä‘áº§u vÃ o

CÃ¡ch Ä‘Æ¡n giáº£n nháº¥t Ä‘á»ƒ mÃ´ hÃ¬nh â€œnhá»›â€ lÃ  **cung cáº¥p toÃ n bá»™ lá»‹ch sá»­ há»™i thoáº¡i trong pháº§n input** cá»§a nÃ³, nháº±m cho phÃ©p mÃ´ hÃ¬nh tá»± truy xuáº¥t nhá»¯ng chi tiáº¿t cáº§n thiáº¿t. Trong cÃ¡c há»‡ QA/há»™i thoáº¡i truyá»n thá»‘ng, Ä‘iá»u nÃ y thÆ°á»ng tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i viá»‡c ná»‘i chuá»—i cÃ¡c lÆ°á»£t há»i-Ä‘Ã¡p trÆ°á»›c vÃ o cÃ¢u há»i hiá»‡n táº¡i. VÃ­ dá»¥, trÃªn bá»™ dá»¯ liá»‡u há»™i thoáº¡i ngá»¯ cáº£nh CoQA/QuAC, mÃ´ hÃ¬nh BiDAF++ Ä‘Ã£ Ä‘Æ°á»£c cáº£i tiáº¿n Ä‘á»ƒ cháº¥p nháº­n thÃªm 2 lÆ°á»£t há»i-Ä‘Ã¡p trÆ°á»›c Ä‘Ã³ lÃ m ngá»¯ cáº£nh, bÃªn cáº¡nh Ä‘oáº¡n vÄƒn cáº§n Ä‘á»c ([BERT with History Answer Embedding for Conversational Question Answering](https://arxiv.org/pdf/1905.05412#:~:text=4,representation%20generated%20when%20answering%20previous)). Viá»‡c Ä‘Æ¡n giáº£n ná»‘i thÃªm lá»‹ch sá»­ nhÆ° váº­y giÃºp mÃ´ hÃ¬nh tráº£ lá»i tá»‘t hÆ¡n cÃ¡c cÃ¢u há»i phá»¥ thuá»™c bá»‘i cáº£nh (vÃ­ dá»¥ Ä‘áº¡i tá»«, tham chiáº¿u Ä‘áº¿n thÃ´ng tin nháº¯c á»Ÿ cÃ¢u há»i trÆ°á»›c). TÆ°Æ¡ng tá»±, trong Ä‘á»‘i thoáº¡i má»Ÿ, má»™t sá»‘ mÃ´ hÃ¬nh dá»±a trÃªn BERT/GPT ban Ä‘áº§u cÅ©ng thá»±c hiá»‡n báº±ng cÃ¡ch **prepend** toÃ n bá»™ ná»™i dung cuá»™c trÃ² chuyá»‡n trÆ°á»›c Ä‘Ã³ vÃ o prompt Ä‘áº§u vÃ o á»Ÿ má»—i lÆ°á»£t Ä‘Ã¡p.

CÃ¹ng vá»›i sá»± phÃ¡t triá»ƒn cá»§a cÃ¡c Transformer cÃ³ cá»­a sá»• ngá»¯ cáº£nh lá»›n, hÆ°á»›ng tiáº¿p cáº­n nÃ y ngÃ y cÃ ng tá» ra há»¯u dá»¥ng hÆ¡n. CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) hiá»‡n nay nhÆ° GPT-4 hay Claude cÃ³ thá»ƒ cháº¥p nháº­n ngá»¯ cáº£nh dÃ i hÃ ng chá»¥c nghÃ¬n token, cho phÃ©p lÆ°u giá»¯ nguyÃªn váº¹n ná»™i dung nhiá»u phiÃªn trÃ² chuyá»‡n trÆ°á»›c Ä‘Ã³. Tuy nhiÃªn, cÃ¡ch lÃ m nÃ y **Ä‘á»‘i máº·t vá»›i nhá»¯ng háº¡n cháº¿**: (i) Chi phÃ­ tÃ­nh toÃ¡n tÄƒng lÃªn Ä‘Ã¡ng ká»ƒ khi Ä‘á»™ dÃ i input lá»›n, gÃ¢y cháº­m trá»… vÃ  tá»‘n tÃ i nguyÃªn; (ii) Máº·c dÃ¹ input ráº¥t dÃ i, mÃ´ hÃ¬nh váº«n cÃ³ thá»ƒ **â€œquÃªnâ€** cÃ¡c chi tiáº¿t quan trá»ng hoáº·c **giáº£m Ä‘á»™ chÃ­nh xÃ¡c** khi pháº£i xá»­ lÃ½ quÃ¡ nhiá»u thÃ´ng tin khÃ´ng liÃªn quan. NghiÃªn cá»©u gáº§n Ä‘Ã¢y cho tháº¥y ngay cáº£ cÃ¡c chat GPT cÃ³ ngá»¯ cáº£nh má»Ÿ rá»™ng váº«n sá»¥t giáº£m ~30% Ä‘á»™ chÃ­nh xÃ¡c khi pháº£i ghi nhá»› thÃ´ng tin tráº£i dÃ i qua má»™t cuá»™c trÃ² chuyá»‡n kÃ©o dÃ i ([[2410.10813] LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory](https://arxiv.org/abs/2410.10813#:~:text=meticulously%20curated%20questions%20embedded%20within,augmented%20key)). NguyÃªn nhÃ¢n lÃ  cÆ¡ cháº¿ tá»± chÃº Ã½ cÃ³ khuynh hÆ°á»›ng táº­p trung vÃ o ná»™i dung gáº§n thá»i Ä‘iá»ƒm hiá»‡n táº¡i, cÃ²n cÃ¡c chi tiáº¿t tá»« ráº¥t lÃ¢u vá» trÆ°á»›c dÃ¹ náº±m trong input cÅ©ng cÃ³ thá»ƒ bá»‹ lu má». Do Ä‘Ã³, má»Ÿ rá»™ng ngá»¯ cáº£nh Ä‘áº§u vÃ o _chÆ°a pháº£i giáº£i phÃ¡p tá»‘i Æ°u_ cho trÃ­ nhá»› dÃ i háº¡n, Ä‘áº·c biá»‡t khi há»™i thoáº¡i kÃ©o dÃ i hÃ ng trÄƒm lÆ°á»£t.

Má»™t sá»‘ cáº£i tiáº¿n Ä‘Ã£ Ä‘Æ°á»£c Ä‘á» xuáº¥t trong hÆ°á»›ng nÃ y nháº±m giÃºp mÃ´ hÃ¬nh táº­n dá»¥ng ngá»¯ cáº£nh dÃ i hiá»‡u quáº£ hÆ¡n. Cháº³ng háº¡n, **Transformer-XL** (Dai et al., 2019) giá»›i thiá»‡u cÆ¡ cháº¿ ghi nhá»› cÃ¡c tráº¡ng thÃ¡i áº©n vÃ  tÃ¡i sá»­ dá»¥ng chÃºng á»Ÿ cÃ¡c phÃ¢n Ä‘oáº¡n sau, táº¡o má»™t dáº¡ng _bá»™ nhá»› ngáº¯n háº¡n trÆ°á»£t_ há»— trá»£ káº¿t ná»‘i ngá»¯ cáº£nh dÃ i. **Compressive Transformer** (Rae et al., 2019) tiáº¿n thÃªm bÆ°á»›c ná»¯a khi nÃ©n cÃ¡c tráº¡ng thÃ¡i cÅ© láº¡i (vÃ­ dá»¥ láº¥y máº«u hoáº·c trung bÃ¬nh) thay vÃ¬ bá» háº³n, giÃºp mÃ´ hÃ¬nh cÃ³ â€œkÃ½ á»©c tÃ³m lÆ°á»£câ€ vá» nhá»¯ng Ä‘oáº¡n ráº¥t xa. Máº·c dÃ¹ váº­y, cÃ¡c ká»¹ thuáº­t nÃ y váº«n hoáº¡t Ä‘á»™ng trong khuÃ´n khá»• trá»ng sá»‘ mÃ´ hÃ¬nh vÃ  Ä‘á»™ dÃ i ngá»¯ cáº£nh cá»‘ Ä‘á»‹nh, chá»© chÆ°a cung cáº¥p má»™t kho nhá»› linh hoáº¡t cÃ³ thá»ƒ tÃ¹y Ã½ Ä‘á»c ghi.

TÃ³m láº¡i, cung cáº¥p ngá»¯ cáº£nh há»™i thoáº¡i dÃ i vÃ o trá»±c tiáº¿p mÃ´ hÃ¬nh lÃ  cÃ¡ch dá»… dÃ ng triá»ƒn khai (khÃ´ng cáº§n thay Ä‘á»•i kiáº¿n trÃºc), vÃ  cÃ³ hiá»‡u quáº£ nháº¥t Ä‘á»‹nh trong cÃ¡c tÃ¬nh huá»‘ng há»™i thoáº¡i ngáº¯n hoáº·c trung bÃ¬nh. NhÆ°ng vá»›i cÃ¡c tÆ°Æ¡ng tÃ¡c lÃ¢u dÃ i, Ä‘a phiÃªn, phÆ°Æ¡ng phÃ¡p nÃ y bá»™c lá»™ háº¡n cháº¿ vá» cáº£ hiá»‡u nÄƒng láº«n Ä‘á»™ tin cáº­y. Äiá»u Ä‘Ã³ dáº«n tá»›i nhu cáº§u vá» nhá»¯ng kiáº¿n trÃºc cÃ³ **bá»™ nhá»› ngoÃ i** rÃµ rá»‡t hÆ¡n, náº±m ngoÃ i chuá»—i input Ä‘Æ¡n thuáº§n â€“ vá»‘n lÃ  ná»™i dung cá»§a hai hÆ°á»›ng tiáº¿p cáº­n sau.

## Tiáº¿p cáº­n 2: Module bá»™ nhá»› kháº£ vi (Differentiable Memory)

HÆ°á»›ng tiáº¿p cáº­n thá»© hai tÃ­ch há»£p trÃ­ nhá»› dÃ i háº¡n ngay trong **kiáº¿n trÃºc cá»§a mÃ´ hÃ¬nh** dÆ°á»›i dáº¡ng má»™t module bá»™ nhá»› Ä‘áº·c biá»‡t cÃ³ thá»ƒ Ä‘á»c/ghi thÃ´ng tin. KhÃ¡c vá»›i viá»‡c nhá»“i nhÃ©t má»i thá»© vÃ o input, á»Ÿ Ä‘Ã¢y mÃ´ hÃ¬nh cÃ³ má»™t **bá»™ nhá»› rá»i** (external memory) â€“ vÃ­ dá»¥ má»™t ma tráº­n hoáº·c dáº£i Ã´ nhá»› â€“ cho phÃ©p lÆ°u tráº¡ng thÃ¡i cuá»™c thoáº¡i vÃ  truy xuáº¥t láº¡i khi cáº§n thÃ´ng qua cÆ¡ cháº¿ attention hoáº·c Ä‘á»c-ghi kháº£ vi (differentiable read/write). Ã tÆ°á»Ÿng nÃ y Ä‘Æ°á»£c tiÃªn phong bá»Ÿi Weston et al. (2014) vá»›i mÃ´ hÃ¬nh **Memory Networks**, káº¿t há»£p giá»¯a má»™t thÃ nh pháº§n suy luáº­n (inference) vÃ  má»™t thÃ nh pháº§n bá»™ nhá»› dÃ i háº¡n ([[1410.3916] Memory Networks](https://arxiv.org/abs/1410.3916#:~:text=,chaining%20multiple%20supporting%20sentences%20to)). Bá»™ nhá»› nÃ y cÃ³ thá»ƒ coi nhÆ° má»™t **cÆ¡ sá»Ÿ tri thá»©c Ä‘á»™ng**: táº¡i má»—i bÆ°á»›c, mÃ´ hÃ¬nh cÃ³ thá»ƒ ghi cÃ¡c thÃ´ng tin má»›i vÃ o cÃ¡c Ã´ nhá»›, vÃ  khi tráº£ lá»i thÃ¬ thá»±c hiá»‡n chu trÃ¬nh chÃº Ã½ lÃªn bá»™ nhá»› Ä‘á»ƒ _chá»n lá»c cÃ¡c Ä‘oáº¡n liÃªn quan_ phá»¥c vá»¥ suy luáº­n. TrÃªn cÃ¡c tÃ¡c vá»¥ QA Ä‘Æ¡n giáº£n, Memory Network Ä‘Ã£ chá»©ng tá» kháº£ nÄƒng **xÃ¢u chuá»—i láº­p luáº­n nhiá»u bÆ°á»›c** nhá» Ä‘á»c tá»« nhiá»u Ã´ nhá»› (cháº³ng háº¡n tráº£ lá»i cÃ¢u há»i cáº§n 2-3 cÃ¢u há»— trá»£) ([[1410.3916] Memory Networks](https://arxiv.org/abs/1410.3916#:~:text=these%20models%20in%20the%20context,understanding%20the%20intension%20of%20verbs)).

Tiáº¿p ná»‘i hÆ°á»›ng nÃ y, nhiá»u kiáº¿n trÃºc bá»™ nhá»› kháº£ vi khÃ¡c ra Ä‘á»i: **End-to-End Memory Network** (Sukhbaatar et al., 2015) tá»‘i Æ°u hÃ³a Memory Network báº±ng cÆ¡ cháº¿ attention Ä‘a lÆ°á»£t; **Dynamic Memory Network** (Kumar et al., 2016) Ã¡p dá»¥ng thÃ nh cÃ´ng cho hiá»ƒu ngÃ´n ngá»¯ vÃ  phÃ¢n tÃ­ch cáº£m xÃºc; Ä‘áº·c biá»‡t lÃ  mÃ´ hÃ¬nh **Differentiable Neural Computer (DNC)** cá»§a DeepMind, má»™t bá»™ nhá»› ngoÃ i cÃ³ mÃ´ Ä‘un Ä‘á»c/ghi Ä‘Æ°á»£c Ä‘iá»u khiá»ƒn bá»Ÿi má»™t máº¡ng LSTM ([Differentiable neural computer - Wikipedia](https://en.wikipedia.org/wiki/Differentiable_neural_computer#:~:text=In%20artificial%20intelligence%20%2C%20a,1)) ([Differentiable neural computer - Wikipedia](https://en.wikipedia.org/wiki/Differentiable_neural_computer#:~:text=DNC%20indirectly%20takes%20inspiration%20from,by%20finding%20a%20%2052)). DNC Ä‘Æ°á»£c vÃ­ nhÆ° _mÃ¡y Turing tháº§n kinh_, cÃ³ thanh ghi nhá»› vÃ  bá»™ Ä‘iá»u khiá»ƒn há»c cÃ¡ch ghi nhá»› chuá»—i dá»¯ liá»‡u vÃ  truy váº¥n khi cáº§n. Graves et al. (2016) cho tháº¥y DNC cÃ³ thá»ƒ há»c cÃ¡ch **lÆ°u trá»¯ vÃ  truy há»“i thÃ´ng tin dáº¡ng Ä‘á»“ thá»‹ tuáº§n tá»±**, vÃ­ dá»¥ ghi láº¡i má»™t tuyáº¿n Ä‘Æ°á»ng vÃ  sau Ä‘Ã³ xuáº¥t ra Ä‘Æ°á»ng Ä‘i ngáº¯n nháº¥t, hay táº¡o ra lá»i giáº£i cho bÃ i toÃ¡n dÆ°á»ng nhÆ° cáº§n kháº£ nÄƒng â€œláº­p trÃ¬nhâ€ ([Differentiable neural computer - Wikipedia](https://en.wikipedia.org/wiki/Differentiable_neural_computer#:~:text=So%20far%2C%20DNCs%20have%20been,video%20commentaries%20or%20semantic%20text)). Nhá»¯ng mÃ´ hÃ¬nh nÃ y **giÃ¡n tiáº¿p chá»©ng minh** máº¡ng nÆ¡-ron cÃ³ kháº£ nÄƒng mÃ´ phá»ng hÃ nh vi nhá»› vÃ  suy luáº­n phi tuyáº¿n tÃ­nh náº¿u Ä‘Æ°á»£c trang bá»‹ bá»™ nhá»› ngoÃ i Ä‘á»§ máº¡nh.

Trong bá»‘i cáº£nh há»™i thoáº¡i, module bá»™ nhá»› kháº£ vi há»©a háº¹n giÃºp chatbot **nhá»› cÃ¡c thÃ´ng tin tá»« cÃ¡c lÆ°á»£t trÆ°á»›c** mÃ  khÃ´ng cáº§n mang toÃ n bá»™ ná»™i dung Ä‘Ã³ trong ngá»¯ cáº£nh má»—i láº§n. Thay vÃ o Ä‘Ã³, thÃ´ng tin sáº½ Ä‘Æ°á»£c viáº¿t vÃ o bá»™ nhá»› (vÃ­ dá»¥ vector áº©n Ä‘áº¡i diá»‡n cho cÃ¢u thoáº¡i quan trá»ng) vÃ  sau Ä‘Ã³ Ä‘á»c ra khi pháº£i pháº£n há»“i. Má»™t vÃ­ dá»¥ Ä‘Æ¡n giáº£n: má»™t **Memory Network** cÃ³ thá»ƒ lÆ°u trá»¯ cÃ¡c phÃ¡t ngÃ´n cá»§a ngÆ°á»i dÃ¹ng dÆ°á»›i dáº¡ng vector trong Ã´ nhá»›, vÃ  má»—i láº§n tráº£ lá»i, mÃ´ hÃ¬nh truy tÃ¬m vector nÃ o cÃ³ liÃªn quan nháº¥t Ä‘áº¿n cÃ¢u há»i hiá»‡n táº¡i Ä‘á»ƒ sá»­ dá»¥ng ([[1410.3916] Memory Networks](https://arxiv.org/abs/1410.3916#:~:text=memory%20component%3B%20they%20learn%20how,chaining%20multiple%20supporting%20sentences%20to)). Vá» nguyÃªn táº¯c, phÆ°Æ¡ng phÃ¡p nÃ y cÃ³ thá»ƒ má»Ÿ rá»™ng trÃ­ nhá»› tÃ¹y Ã½ (chá»‰ cáº§n tÄƒng sá»‘ Ã´ nhá»›) vÃ  mÃ´ hÃ¬nh cÃ³ thá»ƒ há»c cÃ¡ch ghi Ä‘Ã¨ hoáº·c lÃ m má» dáº§n cÃ¡c Ã´ Ã­t quan trá»ng â€“ tÆ°Æ¡ng tá»± cÆ¡ cháº¿ quÃªn cÃ³ chá»§ Ä‘Ã­ch.

Tuy nhiÃªn, **thÃ¡ch thá»©c lá»›n** cá»§a hÆ°á»›ng tiáº¿p cáº­n nÃ y náº±m á»Ÿ viá»‡c _huáº¥n luyá»‡n_ vÃ  _quy mÃ´_. Viá»‡c huáº¥n luyá»‡n end-to-end Ä‘á»ƒ mÃ´ hÃ¬nh vá»«a lÃ m tá»‘t nhiá»‡m vá»¥ Ä‘á»‘i thoáº¡i, vá»«a tá»‘i Æ°u cÃ¡ch Ä‘á»c/ghi bá»™ nhá»› khÃ´ng há» dá»… dÃ ng, Ä‘áº·c biá»‡t trÃªn dá»¯ liá»‡u há»™i thoáº¡i tá»± nhiÃªn phá»©c táº¡p. Káº¿t quáº£ lÃ  cÃ¡c kiáº¿n trÃºc bá»™ nhá»› kháº£ vi tá»«ng thÃ nh cÃ´ng trÃªn nhiá»‡m vá»¥ giáº£ láº­p (nhÆ° bÃ i toÃ¡n bAbI cá»§a Facebook) láº¡i Ã­t Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c há»‡ thá»‘ng há»™i thoáº¡i má»Ÿ rá»™ng thá»±c táº¿. Thay vÃ o Ä‘Ã³, cá»™ng Ä‘á»“ng chuyá»ƒn sang cÃ¡c phÆ°Æ¡ng phÃ¡p dÃ¹ng bá»™ nhá»› ngoÃ i nhÆ°ng _khÃ´ng train chung vá»›i mÃ´ hÃ¬nh_, tá»©c lÃ  hÆ°á»›ng (3) dÆ°á»›i Ä‘Ã¢y. Gáº§n Ä‘Ã¢y, má»™t sá»‘ nghiÃªn cá»©u cá»‘ gáº¯ng káº¿t há»£p LLM vá»›i module nhá»› kháº£ vi â€“ vÃ­ dá»¥ **PlugLM** (Cheng et al., 2022) chÃ¨n má»™t bá»™ nhá»› key-value cÃ³ thá»ƒ cáº­p nháº­t vÃ o mÃ´ hÃ¬nh pretrained Ä‘á»ƒ tÃ¡ch rá»i pháº§n lÆ°u trá»¯ kiáº¿n thá»©c khá»i tham sá»‘ mÃ´ hÃ¬nh ([Language model with Plug-in Knowldge Memory | OpenReview](https://openreview.net/forum?id=Plr5l7r0jY6#:~:text=of%20knowledge%20PLM%20needs%20to,also%20keep%20absorbing%20new%20knowledge)). DÃ¹ cÃ³ káº¿t quáº£ kháº£ quan trong cáº­p nháº­t kiáº¿n thá»©c má»›i mÃ  khÃ´ng tÃ¡i huáº¥n luyá»‡n toÃ n bá»™ mÃ´ hÃ¬nh ([Language model with Plug-in Knowldge Memory | OpenReview](https://openreview.net/forum?id=Plr5l7r0jY6#:~:text=adaptation%20setting%2C%20PlugLM%20could%20be,task%20knowledge)), cÃ¡ch lÃ m nÃ y váº«n hiáº¿m khi Ã¡p dá»¥ng trá»±c tiáº¿p trong Ä‘á»‘i thoáº¡i má»Ÿ. NÃ³i tÃ³m láº¡i, module bá»™ nhá»› kháº£ vi lÃ  má»™t hÆ°á»›ng mang nhiá»u tiá»m nÄƒng vá» máº·t lÃ½ thuyáº¿t, nhÆ°ng Ä‘á»™ phá»©c táº¡p khi huáº¥n luyá»‡n vÃ  tÃ­ch há»£p khiáº¿n nÃ³ chÆ°a phá»• biáº¿n báº±ng cÃ¡ch tiáº¿p cáº­n dá»±a trÃªn truy há»“i thÃ´ng tin.

## Tiáº¿p cáº­n 3: NÃ©n ngá»¯ cáº£nh vÃ  truy há»“i thÃ´ng tin

Hiá»‡n nay, **phá»• biáº¿n nháº¥t** trong cÃ¡c há»‡ thá»‘ng Ä‘á»‘i thoáº¡i cÃ³ trÃ­ nhá»› dÃ i háº¡n lÃ  hÆ°á»›ng tiáº¿p cáº­n dá»±a trÃªn **bá»™ nhá»› ngoÃ i káº¿t há»£p truy há»“i (retrieval)**. Thay vÃ¬ giá»¯ toÃ n bá»™ lá»‹ch sá»­ trong input hay thiáº¿t káº¿ má»™t module nhá»› phá»©c táº¡p bÃªn trong, phÆ°Æ¡ng phÃ¡p nÃ y tÃ¡ch biá»‡t háº³n má»™t **kho lÆ°u trá»¯ thÃ´ng tin há»™i thoáº¡i** (conversation memory repository) dÆ°á»›i dáº¡ng vÄƒn báº£n hoáº·c vector, vÃ  sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n truy há»“i (thÆ°á»ng qua embedding vÃ  so khá»›p ngá»¯ nghÄ©a) Ä‘á»ƒ láº¥y ra nhá»¯ng máº©u thÃ´ng tin cáº§n thiáº¿t cho má»—i lÆ°á»£t Ä‘á»‘i thoáº¡i. CÃ¡ch tiáº¿p cáº­n nÃ y chá»‹u áº£nh hÆ°á»Ÿng tá»« thÃ nh cÃ´ng cá»§a mÃ´ hÃ¬nh **open-domain QA** vÃ  **retrieval-augmented generation (RAG)**, nÆ¡i mÃ´ hÃ¬nh language model Ä‘Æ°á»£c bá»• trá»£ bá»Ÿi má»™t cÆ¡ cháº¿ tÃ¬m kiáº¿m tri thá»©c bÃªn ngoÃ i. Äiá»ƒm khÃ¡c biá»‡t lÃ  á»Ÿ Ä‘Ã¢y, kho lÆ°u trá»¯ khÃ´ng pháº£i tri thá»©c chung cá»‘ Ä‘á»‹nh (nhÆ° Wikipedia) mÃ  chÃ­nh lÃ  _nhá»¯ng gÃ¬ Ä‘Ã£ diá»…n ra trong cuá»™c há»™i thoáº¡i trÆ°á»›c Ä‘Ã³_.

Quy trÃ¬nh chung thÆ°á»ng gá»“m cÃ¡c bÆ°á»›c: (i) **LÆ°u trá»¯**: má»—i khi káº¿t thÃºc má»™t phiÃªn hoáº·c má»™t sá»‘ lÆ°á»£t thoáº¡i, há»‡ thá»‘ng sáº½ trÃ­ch xuáº¥t cÃ¡c thÃ´ng tin cá»‘t lÃµi (vÃ­ dá»¥: sá»± kiá»‡n vá»«a xáº£y ra, tÃ­nh cÃ¡ch hoáº·c sá»Ÿ thÃ­ch ngÆ°á»i dÃ¹ng Ä‘Æ°á»£c Ä‘á» cáº­p, cÃ¢u há»i chÆ°a Ä‘Æ°á»£c tráº£ lá»i,...) vÃ  lÆ°u vÃ o bá»™ nhá»› dÃ i háº¡n. Viá»‡c lÆ°u trá»¯ nÃ y cÃ³ thá»ƒ á»Ÿ dáº¡ng vÄƒn báº£n thÃ´ (nhÆ° táº­p cÃ¡c cÃ¢u tÃ³m táº¯t) hoáº·c vector embedding (nhÆ° trung bÃ¬nh biá»ƒu diá»…n cá»§a cÃ¢u nÃ³i). (ii) **Truy váº¥n**: khi Ä‘á»‘i thoáº¡i tiáº¿p tá»¥c, trÆ°á»›c khi táº¡o cÃ¢u tráº£ lá»i, mÃ´ hÃ¬nh sáº½ truy váº¥n bá»™ nhá»› Ä‘á»ƒ láº¥y ra nhá»¯ng máº©u thÃ´ng tin liÃªn quan Ä‘áº¿n ngá»¯ cáº£nh hiá»‡n táº¡i. Cháº³ng háº¡n, náº¿u ngÆ°á»i dÃ¹ng há»i láº¡i â€œ_HÃ´m trÆ°á»›c báº¡n há»©a gÃ¬ vá»›i tÃ´i?_â€, há»‡ thá»‘ng sáº½ tÃ¬m trong bá»™ nhá»› má»¥c nÃ o chá»©a ná»™i dung lá»i há»©a. (iii) **Sá»­ dá»¥ng**: cÃ¡c káº¿t quáº£ truy há»“i Ä‘Æ°á»£c Ä‘Æ°a vÃ o mÃ´ hÃ¬nh (nhÆ° má»™t Ä‘oáº¡n context thÃªm vÃ o prompt cá»§a LLM) Ä‘á»ƒ sinh ra pháº£n há»“i cuá»‘i cÃ¹ng. CÆ¡ cháº¿ nÃ y tÆ°Æ¡ng tá»± pipeline _retrieve-then-read_ Ä‘Ã£ thÃ nh cÃ´ng trong QA má»Ÿ ([[2005.11364] Open-Retrieval Conversational Question Answering](https://arxiv.org/abs/2005.11364#:~:text=retrieval%20conversational%20question%20answering%20,the%20reranker%20component%20contributes%20to)), chá»‰ khÃ¡c lÃ  â€œcorpusâ€ á»Ÿ Ä‘Ã¢y chÃ­nh lÃ  lá»‹ch sá»­ há»™i thoáº¡i quÃ¡ khá»©.

**Æ¯u Ä‘iá»ƒm chÃ­nh** cá»§a hÆ°á»›ng nÃ y lÃ  kháº£ nÄƒng má»Ÿ rá»™ng vÃ  kiá»ƒm soÃ¡t: Ta cÃ³ thá»ƒ duy trÃ¬ má»™t bá»™ nhá»› ráº¥t lá»›n (hÃ ng nghÃ¬n sá»± kiá»‡n) mÃ  khÃ´ng lÃ m â€œquÃ¡ táº£iâ€ mÃ´ hÃ¬nh táº¡i thá»i Ä‘iá»ƒm sinh Ä‘áº§u ra, bá»Ÿi vÃ¬ luÃ´n chá»‰ má»™t pháº§n nhá» (vÃ­ dá»¥ 5-10 Ä‘oáº¡n) Ä‘Æ°á»£c truy há»“i lÃ m ngá»¯ cáº£nh má»—i lÆ°á»£t. Äá»“ng thá»i, ta cÃ³ thá»ƒ **cáº­p nháº­t** hoáº·c **Ä‘iá»u chá»‰nh** ná»™i dung bá»™ nhá»› Ä‘á»™c láº­p vá»›i mÃ´ hÃ¬nh (vÃ¬ nÃ³ náº±m ngoÃ i), giÃºp dá»… dÃ ng thÃªm thÃ´ng tin má»›i, xÃ³a thÃ´ng tin lá»—i thá»i, hay sá»­a sai náº¿u chatbot ghi nhá»› nháº§m. Nhá»¯ng há»‡ thá»‘ng há»™i thoáº¡i dÃ i háº¡n máº¡nh gáº§n Ä‘Ã¢y háº§u háº¿t Ä‘á»u theo kiáº¿n trÃºc nÃ y, káº¿t há»£p vá»›i nhiá»u ká»¹ thuáº­t tinh vi Ä‘á»ƒ tÄƒng cháº¥t lÆ°á»£ng tÃ³m táº¯t vÃ  truy há»“i.

Má»™t vÃ­ dá»¥ tiÃªu biá»ƒu lÃ  **ORConvQA** (Open-Retrieval Conversational QA) cá»§a Qu et al. (2020). Thay vÃ¬ giáº£ Ä‘á»‹nh cÃ¢u tráº£ lá»i luÃ´n náº±m trong má»™t Ä‘oáº¡n vÄƒn cho trÆ°á»›c nhÆ° CoQA, ORConvQA cho phÃ©p mÃ´ hÃ¬nh **truy tÃ¬m báº±ng chá»©ng** tá»« má»™t táº­p tÃ i liá»‡u lá»›n trÆ°á»›c khi tráº£ lá»i ([[2005.11364] Open-Retrieval Conversational Question Answering](https://arxiv.org/abs/2005.11364#:~:text=passage,We%20further%20show%20that%20our)). Há»‡ thá»‘ng cá»§a há» gá»“m ba thÃ nh pháº§n Transformer: truy há»“i (retriever), tÃ¡i xáº¿p háº¡ng, vÃ  Ä‘á»c hiá»ƒu, cho phÃ©p tÃ¬m kiáº¿m thÃ´ng tin qua nhiá»u lÆ°á»£t há»i Ä‘Ã¡p. Káº¿t quáº£ chá»‰ ra ráº±ng viá»‡c tÃ­ch há»£p _history modeling_ (mÃ´ hÃ¬nh hÃ³a lá»‹ch sá»­ há»™i thoáº¡i) vÃ o cáº£ truy há»“i láº«n Ä‘á»c hiá»ƒu giÃºp cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ Ä‘á»™ chÃ­nh xÃ¡c ([[2005.11364] Open-Retrieval Conversational Question Answering](https://arxiv.org/abs/2005.11364#:~:text=to,the%20reranker%20component%20contributes%20to)) â€“ minh chá»©ng cho lá»£i Ã­ch cá»§a viá»‡c lÆ°u vÃ  sá»­ dá»¥ng ngá»¯ cáº£nh tá»« cÃ¡c lÆ°á»£t trÆ°á»›c. ORConvQA lÃ  cáº§u ná»‘i tá»« QA thuáº§n tÃºy sang Ä‘á»‘i thoáº¡i cÃ³ trÃ­ nhá»›, cho tháº¥y **káº¿t há»£p retrieval vá»›i context há»™i thoáº¡i** lÃ  hÆ°á»›ng Ä‘i há»¯u Ã­ch.

Trong Ä‘á»‘i thoáº¡i má»Ÿ, dá»± Ã¡n **BlenderBot 2.0** cá»§a Facebook (Roller et al., 2021) láº§n Ä‘áº§u tiÃªn giá»›i thiá»‡u má»™t chatbot cÃ³ kháº£ nÄƒng **â€œnhá»›â€ cÃ¡c cuá»™c trÃ² chuyá»‡n trÆ°á»›c Ä‘Ã³**. Cá»¥ thá»ƒ, BlenderBot 2.0 lÆ°u láº¡i _tÃ³m táº¯t_ cá»§a má»—i phiÃªn tÆ°Æ¡ng tÃ¡c vá»›i ngÆ°á»i dÃ¹ng trong má»™t cÆ¡ sá»Ÿ dá»¯ liá»‡u bá»™ nhá»› lÃ¢u dÃ i. Khi gáº·p láº¡i ngÆ°á»i dÃ¹ng Ä‘Ã³ hoáº·c trong phiÃªn káº¿ tiáº¿p, bot sáº½ truy váº¥n cÆ¡ sá»Ÿ nÃ y Ä‘á»ƒ tÃ¬m cÃ¡c thÃ´ng tin liÃªn quan (vÃ­ dá»¥: tÃªn ngÆ°á»i dÃ¹ng, sá»Ÿ thÃ­ch Ä‘Ã£ Ä‘á» cáº­p) vÃ  Ä‘iá»u chá»‰nh pháº£n há»“i cho phÃ¹ há»£p. Song song, BlenderBot 2.0 cÃ²n tÃ­ch há»£p tÃ¬m kiáº¿m Internet, nhÆ°ng Ä‘iá»ƒm máº¥u chá»‘t lÃ  nÃ³ chá»©ng minh Ä‘Æ°á»£c viá»‡c **ghi nhá»› vÃ  truy xuáº¥t dá»¯ kiá»‡n tá»« cÃ¡c phiÃªn trÆ°á»›c** giÃºp bot trá»Ÿ nÃªn tá»± nhiÃªn vÃ  nháº¥t quÃ¡n hÆ¡n háº³n so vá»›i phiÃªn báº£n trÆ°á»›c Ä‘Ã³ (BlenderBot 1) vá»‘n chá»‰ nhá»› trong pháº¡m vi phiÃªn hiá»‡n táº¡i. ÄÃ¢y lÃ  má»™t minh há»a sá»›m cho hiá»‡u quáº£ cá»§a memory augmentation trong Ä‘á»‘i thoáº¡i.

Äá»ƒ quáº£n lÃ½ bá»™ nhá»› hiá»‡u quáº£, cÃ¡c nghiÃªn cá»©u gáº§n Ä‘Ã¢y táº­p trung vÃ o **ká»¹ thuáº­t tÃ³m táº¯t vÃ  cáº­p nháº­t bá»™ nhá»›**. Thay vÃ¬ lÆ°u táº¥t cáº£ má»i cÃ¢u, há»‡ thá»‘ng sáº½ **tÃ³m táº¯t ngáº¯n gá»n** nhá»¯ng thÃ´ng tin quan trá»ng sau má»—i phiÃªn. Bae et al. (2022) â€“ trong há»‡ thá»‘ng **â€œKeep Me Updated!â€** â€“ sá»­ dá»¥ng má»™t mÃ´-Ä‘un tÃ³m táº¯t Ä‘á»ƒ trÃ­ch xuáº¥t cÃ¡c cÃ¢u **tiá»ƒu sá»­ ngÆ°á»i dÃ¹ng** sau má»—i phiÃªn trÃ² chuyá»‡n vÃ  lÆ°u chÃºng vÃ o bá»™ nhá»› ([](https://aclanthology.org/2022.findings-emnlp.276.pdf#:~:text=interlocutors%20revealed%20in%20the%20previous,in%02coming%20summary%20is%20%E2%80%9CJust%20got)) ([](https://aclanthology.org/2022.findings-emnlp.276.pdf#:~:text=For%20example%2C%20if%20the%20previous,additional%20condi%02tion%20for%20generating%20chatbot)). Quan trá»ng hÆ¡n, há» thiáº¿t káº¿ cÆ¡ cháº¿ **quáº£n lÃ½ bá»™ nhá»› Ä‘á»™ng**: má»—i khi cÃ³ thÃ´ng tin má»›i, há»‡ thá»‘ng so sÃ¡nh vá»›i cÃ¡c cÃ¢u nhá»› cÅ© vÃ  thá»±c hiá»‡n bá»‘n thao tÃ¡c cÃ³ thá»ƒ â€“ _giá»¯ nguyÃªn (PASS), thay tháº¿ (REPLACE), thÃªm má»›i (APPEND), hoáº·c xÃ³a bá» (DELETE)_ â€“ nháº±m loáº¡i bá» mÃ¢u thuáº«n hoáº·c trÃ¹ng láº·p ([](https://aclanthology.org/2022.findings-emnlp.276.pdf#:~:text=Specifically%2C%20the%20memory%20management%20mechanism,%E2%80%9CJust%20got%20positive%20results%20from)). Cháº³ng háº¡n, náº¿u bá»™ nhá»› cÃ³ cÃ¢u â€œChÆ°a xÃ©t nghiá»‡m COVIDâ€ vÃ  phiÃªn má»›i phÃ¡t hiá»‡n â€œVá»«a nháº­n káº¿t quáº£ dÆ°Æ¡ng tÃ­nh COVIDâ€, mÃ´-Ä‘un sáº½ _thay tháº¿_ cÃ¢u cÅ© báº±ng cÃ¢u má»›i trong bá»™ nhá»› ([](https://aclanthology.org/2022.findings-emnlp.276.pdf#:~:text=find%20and%20eliminate%20the%20information,in%20sub%02sequent%20sessions%2C%20a%20relevant)). Nhá» Ä‘Ã³, bá»™ nhá»› luÃ´n Ä‘Æ°á»£c duy trÃ¬ _cáº­p nháº­t_ vÃ  _nháº¥t quÃ¡n_ vá»›i tÃ¬nh tráº¡ng hiá»‡n táº¡i cá»§a ngÆ°á»i dÃ¹ng. ThÃ­ nghiá»‡m cho tháº¥y cÃ¡ch tiáº¿p cáº­n nÃ y giÃºp chatbot duy trÃ¬ Ä‘Æ°á»£c **tÃ­nh chÃ­nh xÃ¡c cá»§a trÃ­ nhá»›** qua nhiá»u phiÃªn, cáº£i thiá»‡n tÃ­nh gáº¯n káº¿t vÃ  tá»± nhiÃªn trong Ä‘á»‘i thoáº¡i dÃ i ([](https://aclanthology.org/2022.findings-emnlp.276.pdf#:~:text=With%20extensive%20experiments%20and%20ablations%2C,date)).

Má»™t hÆ°á»›ng khÃ¡c Ä‘á»ƒ nÃ©n thÃ´ng tin lÃ  sá»­ dá»¥ng LLM tá»± Ä‘á»™ng táº¡o **báº£n tÃ³m táº¯t Ä‘á»‡ quy**. Wang et al. (2023) Ä‘á» xuáº¥t phÆ°Æ¡ng phÃ¡p _Recursively Summarizing_ vá»›i GPT-4: chia há»™i thoáº¡i ráº¥t dÃ i thÃ nh cÃ¡c Ä‘oáº¡n nhá», láº§n lÆ°á»£t dÃ¹ng LLM tÃ³m táº¯t tá»«ng Ä‘oáº¡n, rá»“i láº¡i tÃ³m táº¯t tiáº¿p cÃ¡c báº£n tÃ³m táº¯t Ä‘á»ƒ táº¡o nÃªn má»™t _â€œsiÃªu tÃ³m táº¯tâ€_ cuá»‘i cÃ¹ng lÃ m bá»™ nhá»› ([[2308.15022] Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models](https://arxiv.org/abs/2308.15022#:~:text=long%20conversation%2C%20these%20chatbots%20fail,consistent%20responses%20in%20a%20long)). MÃ´ hÃ¬nh Ä‘á»‘i thoáº¡i sáº½ tham kháº£o cÃ¡c tÃ³m táº¯t nÃ y thay vÃ¬ toÃ n bá»™ chi tiáº¿t cuá»™c trÃ² chuyá»‡n. Ká»¹ thuáº­t Ä‘á»‡ quy nÃ y giÃºp lÆ°u giá»¯ Ä‘Æ°á»£c Ã½ chÃ­nh cá»§a nhá»¯ng há»™i thoáº¡i hÃ ng trÄƒm lÆ°á»£t dÆ°á»›i dáº¡ng vÃ i Ä‘oáº¡n vÄƒn sÃºc tÃ­ch. ThÃº vá»‹ lÃ  nhÃ³m tÃ¡c giáº£ nháº­n tháº¥y phÆ°Æ¡ng phÃ¡p cá»§a há» cÃ³ thá»ƒ **káº¿t há»£p cá»™ng hÆ°á»Ÿng** vá»›i cáº£ LLM cÃ³ ngá»¯ cáº£nh dÃ i (8K-16K) láº«n mÃ´ hÃ¬nh tÃ­ch há»£p retrieval, giÃºp nÃ¢ng cao hiá»‡u quáº£ trÃªn cÃ¡c há»™i thoáº¡i cá»±c dÃ i ([[2308.15022] Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models](https://arxiv.org/abs/2308.15022#:~:text=consistent%20response%20with%20the%20help,scripts%20will%20be%20released%20later)). Äiá»u nÃ y gá»£i Ã½ hÆ°á»›ng tÆ°Æ¡ng lai: káº¿t há»£p giá»¯a tÃ³m táº¯t vÃ  truy há»“i má»™t cÃ¡ch thÃ­ch á»©ng.

Äá»‘i vá»›i pha **truy há»“i**, háº§u háº¿t cÃ¡c há»‡ thá»‘ng dÃ¹ng **embedding khÃ´ng gian**: lÆ°u cÃ¡c memory dÆ°á»›i dáº¡ng vector nhÃºng vÃ  sá»­ dá»¥ng _khoáº£ng cÃ¡ch ngá»¯ nghÄ©a_ Ä‘á»ƒ tÃ¬m kiáº¿m. Äá»™ chÃ­nh xÃ¡c truy há»“i phá»¥ thuá»™c nhiá»u vÃ o cÃ¡ch biá»ƒu diá»…n vÃ  tá»• chá»©c bá»™ nhá»›. Pan et al. (2024) trong cÃ´ng trÃ¬nh **SeCom** nháº¥n máº¡nh táº§m quan trá»ng cá»§a **â€œÄ‘Æ¡n vá»‹ bá»™ nhá»›â€**: há» so sÃ¡nh lÆ°u trá»¯ theo tá»«ng lÆ°á»£t thoáº¡i, theo tá»«ng phiÃªn, vÃ  theo Ä‘oáº¡n tÃ³m táº¯t, nháº­n tháº¥y má»—i cÃ¡ch cÃ³ Æ°u nhÆ°á»£c Ä‘iá»ƒm riÃªng ([On Memory Construction and Retrieval for Personalized Conversational Agents](https://arxiv.org/html/2502.05589v2#:~:text=To%20deliver%20coherent%20and%20personalized,retrieval%20accuracy%20across%20different%20granularities)) ([On Memory Construction and Retrieval for Personalized Conversational Agents](https://arxiv.org/html/2502.05589v2#:~:text=Building%20on%20these%20insights%2C%20we,as%20DialSeg711%2C%20TIAGE%2C%20and%20SuperDialSeg)). SeCom Ä‘á» xuáº¥t má»™t chiáº¿n lÆ°á»£c káº¿t há»£p: dÃ¹ng má»™t mÃ´ hÃ¬nh phÃ¢n Ä‘oáº¡n chá»§ Ä‘á» Ä‘á»ƒ chia há»™i thoáº¡i thÃ nh cÃ¡c **Ä‘oáº¡n sá»± kiá»‡n ngáº¯n**, lÆ°u má»—i Ä‘oáº¡n nhÆ° má»™t báº£n ghi bá»™ nhá»›, Ä‘á»“ng thá»i Ã¡p dá»¥ng ká»¹ thuáº­t **â€œnÃ©n thÃ´ng tin nhiá»…uâ€** Ä‘á»ƒ lá»c bá»›t pháº§n khÃ´ng liÃªn quan trong má»—i Ä‘oáº¡n trÆ°á»›c khi lÆ°u ([On Memory Construction and Retrieval for Personalized Conversational Agents](https://arxiv.org/html/2502.05589v2#:~:text=Building%20on%20these%20insights%2C%20we,as%20DialSeg711%2C%20TIAGE%2C%20and%20SuperDialSeg)). Káº¿t quáº£, cÃ¡ch lÆ°u trá»¯ theo Ä‘oáº¡n chá»§ Ä‘á» giÃºp tÄƒng cháº¥t lÆ°á»£ng truy há»“i trÃªn cÃ¡c benchmark há»™i thoáº¡i dÃ i nhÆ° LOCOMO, vÃ¬ nÃ³ cÃ¢n báº±ng giá»¯a chi tiáº¿t vÃ  tá»•ng quÃ¡t. BÃªn cáº¡nh Ä‘Ã³, má»™t sá»‘ cáº£i tiáº¿n khÃ¡c gá»“m **truy há»“i theo thá»i gian** (Æ°u tiÃªn cÃ¡c sá»± kiá»‡n gáº§n Ä‘Ã¢y náº¿u cÃ¢u há»i chá»©a má»‘c thá»i gian â€“ xem Wu et al. 2023) hay **má»Ÿ rá»™ng truy váº¥n báº±ng tri thá»©c** (vÃ­ dá»¥ náº¿u há»i â€œanh áº¥yâ€ thÃ¬ truy váº¥n má»Ÿ rá»™ng â€œanh áº¥yâ€ = tÃªn cá»¥ thá»ƒ tá»« bá»™ nhá»›). Nhá»¯ng tá»‘i Æ°u nÃ y Ä‘Ã£ Ä‘Æ°á»£c tá»•ng káº¿t trong nghiÃªn cá»©u LongMemEval, Ä‘á» xuáº¥t khung â€œIndexing-Retrieval-Readingâ€ cho thiáº¿t káº¿ bá»™ nhá»›, trong Ä‘Ã³: **Ä‘Ã¡nh chá»‰ má»¥c** tá»‘i Æ°u báº±ng cÃ¡ch lÆ°u trá»¯ theo phiÃªn nhá» (session decomposition) vÃ  má»Ÿ rá»™ng khÃ³a báº±ng dá»¯ kiá»‡n, **truy há»“i** tá»‘i Æ°u báº±ng cÃ¡ch cÃ¢n nháº¯c ngá»¯ cáº£nh thá»i gian, vÃ  **Ä‘á»c** hiá»‡u quáº£ báº±ng cÃ¡ch káº¿t há»£p bá»™ nhá»› vÃ o input LLM ([[2410.10813] LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory](https://arxiv.org/abs/2410.10813#:~:text=showing%20a%2030,term)).

Gáº§n Ä‘Ã¢y, xuáº¥t hiá»‡n nhá»¯ng há»‡ thá»‘ng trÃ­ nhá»› tiÃªn tiáº¿n táº­n dá»¥ng sá»©c máº¡nh LLM: vÃ­ dá»¥ **MemoryBank** (Zhong et al., 2023) vÃ  **THEANINE** (Ong et al., 2024). MemoryBank tÃ­ch há»£p má»™t **cÆ¡ cháº¿ cáº­p nháº­t bá»™ nhá»› láº¥y cáº£m há»©ng tá»« Ä‘Æ°á»ng cong lÃ£ng quÃªn cá»§a Ebbinghaus** â€“ nghÄ©a lÃ  mÃ´ phá»ng viá»‡c kÃ½ á»©c phai nháº¡t dáº§n theo thá»i gian náº¿u khÃ´ng nháº¯c láº¡i ([[2305.10250] MemoryBank: Enhancing Large Language Models with Long-Term Memory](https://ar5iv.labs.arxiv.org/html/2305.10250#:~:text=personality%20over%20time%20by%20synthesizing,based%20chatbot%20named)). Cá»¥ thá»ƒ, MemoryBank cho phÃ©p AI â€œquÃªnâ€ bá»›t nhá»¯ng kÃ½ á»©c Ã­t quan trá»ng hoáº·c lÃ¢u khÃ´ng dÃ¹ng, vÃ  **cá»§ng cá»‘** nhá»¯ng kÃ½ á»©c hay Ä‘Æ°á»£c truy xuáº¥t, nhá» Ä‘Ã³ bá»™ nhá»› hoáº¡t Ä‘á»™ng hiá»‡u quáº£ vÃ  giá»‘ng ngÆ°á»i hÆ¡n ([[2305.10250] MemoryBank: Enhancing Large Language Models with Long-Term Memory](https://ar5iv.labs.arxiv.org/html/2305.10250#:~:text=personality%20over%20time%20by%20synthesizing,based%20chatbot%20named)) ([Augmenting LLMs with Retrieval, Tools, and Long-term Memory | by Alaa Dania Adimi | InfinitGraph | Mar, 2025 | Medium](https://medium.com/@ja_adimi/augmenting-llms-with-retrieval-tools-and-long-term-memory-b9e1e6b2fc28#:~:text=Memory%20Updating)). Há» triá»ƒn khai MemoryBank trÃªn má»™t chatbot báº¡n Ä‘á»“ng hÃ nh (SiliconFriend), cho tháº¥y bot cÃ³ thá»ƒ **tiáº¿p thu vÃ  thÃ­ch nghi vá»›i tÃ­nh cÃ¡ch ngÆ°á»i dÃ¹ng** qua thá»i gian, Ä‘á»“ng thá»i nhá»› Ä‘Æ°á»£c cÃ¡c sá»± kiá»‡n cá»‘t lÃµi trong quÃ¡ khá»© (vÃ­ dá»¥ sá»Ÿ thÃ­ch, má»¥c tiÃªu ngÆ°á»i dÃ¹ng) nhá» cÆ¡ cháº¿ nÃ y ([[2305.10250] MemoryBank: Enhancing Large Language Models with Long-Term Memory](https://ar5iv.labs.arxiv.org/html/2305.10250#:~:text=psychological%20counseling%2C%20and%20secretarial%20assistance,the%20memory%2C%20thereby%20offering%20a)) ([Augmenting LLMs with Retrieval, Tools, and Long-term Memory | by Alaa Dania Adimi | InfinitGraph | Mar, 2025 | Medium](https://medium.com/@ja_adimi/augmenting-llms-with-retrieval-tools-and-long-term-memory-b9e1e6b2fc28#:~:text=,memory%20works%20through%20repeated%20retrieval)). Trong khi Ä‘Ã³, THEANINE láº¡i chá»n cÃ¡ch **khÃ´ng xÃ³a bá» kÃ½ á»©c cÅ©**, thay vÃ o Ä‘Ã³ quáº£n lÃ½ má»™t **Ä‘á»“ thá»‹ kÃ½ á»©c theo dÃ²ng thá»i gian** ná»‘i cÃ¡c sá»± kiá»‡n theo quan há»‡ nhÃ¢n quáº£ vÃ  thá»i gian ([[2406.10996] Towards Lifelong Dialogue Agents via Timeline-based Memory Management](https://arxiv.org/abs/2406.10996#:~:text=to%20improve%20retrieval%20quality%2C%20we,human%20efforts%20when%20assessing%20agent)). Má»—i khi cáº§n táº¡o pháº£n há»“i, mÃ´ hÃ¬nh sáº½ láº§n theo _timeline_ cÃ¡c sá»± kiá»‡n liÃªn quan, táº¡o nÃªn má»™t ngá»¯ cáº£nh diá»…n giáº£i vÃ¬ sao ngÆ°á»i dÃ¹ng cÃ³ tráº¡ng thÃ¡i hiá»‡n táº¡i. CÃ¡ch nÃ y nháº¥n máº¡nh táº§m quan trá»ng cá»§a **ngá»¯ cáº£nh tiáº¿n hÃ³a**: vÃ­ dá»¥, thay vÃ¬ chá»‰ biáº¿t â€œngÆ°á»i dÃ¹ng thÃ­ch du lá»‹châ€, bot cÃ²n biáº¿t _lá»‹ch sá»­_ trÆ°á»›c Ä‘Ã¢y ngÆ°á»i dÃ¹ng Ä‘Ã£ tá»«ng _sá»£ Ä‘i mÃ¡y bay rá»“i sau Ä‘Ã³ má»›i thÃ­ch du lá»‹ch_ â€“ tá»« Ä‘Ã³ pháº£n há»“i tinh táº¿ hÆ¡n. THEANINE cho tháº¥y viá»‡c **liÃªn káº¿t cÃ¡c máº£nh memory** thÃ nh chuá»—i cÃ³ thá»ƒ giÃºp mÃ´ hÃ¬nh hiá»ƒu rÃµ sá»± thay Ä‘á»•i vÃ  nháº¥t quÃ¡n trong tÃ­nh cÃ¡ch ngÆ°á»i dÃ¹ng theo thá»i gian, mÃ  khÃ´ng cáº§n xÃ³a kÃ½ á»©c cÅ© (vá»‘n cÅ©ng mang thÃ´ng tin há»¯u Ã­ch vá» thay Ä‘á»•i hÃ nh vi) ([[2406.10996] Towards Lifelong Dialogue Agents via Timeline-based Memory Management](https://arxiv.org/abs/2406.10996#:~:text=constantly%20memorize%20perceived%20information%20and,Along)) ([[2406.10996] Towards Lifelong Dialogue Agents via Timeline-based Memory Management](https://arxiv.org/abs/2406.10996#:~:text=conversations,human%20efforts%20when%20assessing%20agent)).

Cuá»‘i cÃ¹ng, framework **LD-Agent** (Hao Li et al., 2024) Ä‘áº¡i diá»‡n cho xu hÆ°á»›ng tÃ­ch há»£p _Ä‘a thÃ nh pháº§n_: há»‡ thá»‘ng nÃ y chia tÃ¡c vá»¥ thÃ nh **3 mÃ´-Ä‘un** Ä‘á»™c láº­p â€“ (i) **nháº­n thá»©c sá»± kiá»‡n** (event perception) Ä‘á»ƒ tÃ³m táº¯t sá»± kiá»‡n chÃ­nh má»—i phiÃªn vÃ o bá»™ nhá»› dÃ i háº¡n, (ii) **trÃ­ch xuáº¥t persona** Ä‘á»™ng cho cáº£ ngÆ°á»i dÃ¹ng vÃ  chatbot, vÃ  (iii) **táº¡o pháº£n há»“i** (response generation) cÃ³ Ä‘iá»u kiá»‡n trÃªn ngá»¯ cáº£nh hiá»‡n táº¡i + bá»™ nhá»› sá»± kiá»‡n truy há»“i + persona Ä‘Ã£ nháº­n diá»‡n ([[2406.05925] Hello Again! LLM-powered Personalized Agent for Long-term Dialogue](https://arxiv.org/abs/2406.05925#:~:text=the%20Long,Agent%20are)). Bá»™ nhá»› sá»± kiá»‡n cá»§a LD-Agent bao gá»“m hai pháº§n: **bá»™ nhá»› dÃ i háº¡n** chá»©a lá»‹ch sá»­ cÃ¡c sá»± kiá»‡n tÃ³m táº¯t qua nhiá»u phiÃªn (Ä‘Æ°á»£c lÆ°u vá»›i dáº¥u thá»i gian vÃ  phÃ¢n Ä‘oáº¡n theo chá»§ Ä‘á»), vÃ  **bá»™ nhá»› ngáº¯n háº¡n** cho phiÃªn hiá»‡n táº¡i (Ä‘áº£m báº£o thÃ´ng tin má»›i nháº¥t luÃ´n Ä‘Æ°á»£c chÃº trá»ng) ([[2406.05925] Hello Again! LLM-powered Personalized Agent for Long-term Dialogue](https://arxiv.org/abs/2406.05925#:~:text=the%20Long,Agent%20are)) ([](https://openreview.net/pdf?id=lwCxVgVYoK#:~:text=200%20The%20event%20memory%20module,Specifically%2C%20this%20involves%20recording)). Khi pháº£n há»“i, há»‡ thá»‘ng dÃ¹ng má»™t cÆ¡ cháº¿ truy há»“i theo chá»§ Ä‘á» Ä‘á»ƒ láº¥y ra cÃ¡c sá»± kiá»‡n cÅ© liÃªn quan tá»« bá»™ nhá»› dÃ i háº¡n, káº¿t há»£p vá»›i ná»™i dung ngáº¯n háº¡n, cÃ¹ng vá»›i há»“ sÆ¡ persona Ä‘Ã£ cáº­p nháº­t, rá»“i Ä‘Æ°a vÃ o mÃ´-Ä‘un sinh. CÃ¡ch tiáº¿p cáº­n module hÃ³a nÃ y giÃºp dá»… dÃ ng tinh chá»‰nh tá»«ng pháº§n (vÃ­ dá»¥ thay mÃ´ hÃ¬nh tÃ³m táº¯t sá»± kiá»‡n khÃ¡c tá»‘t hÆ¡n, hoáº·c Ã¡p dá»¥ng ká»¹ thuáº­t LoRA Ä‘á»ƒ cáº­p nháº­t persona linh hoáº¡t), Ä‘á»“ng thá»i cho tháº¥y táº§m quan trá»ng cá»§a viá»‡c **quáº£n lÃ½ Ä‘á»“ng thá»i kiáº¿n thá»©c sá»± kiá»‡n vÃ  thÃ´ng tin cÃ¡ nhÃ¢n** cho Ä‘á»‘i thoáº¡i dÃ i háº¡n. CÃ¡c thÃ­ nghiá»‡m cá»§a LD-Agent chá»‰ ra ráº±ng viá»‡c tÃ­ch há»£p cáº£ hai loáº¡i bá»™ nhá»› (sá»± kiá»‡n + persona) giÃºp chatbot Ä‘áº¡t Ä‘á»™ tá»± nhiÃªn vÃ  chÃ­nh xÃ¡c cao hÆ¡n rÃµ rá»‡t trÃªn nhiá»u benchmark khÃ¡c nhau ([[2406.05925] Hello Again! LLM-powered Personalized Agent for Long-term Dialogue](https://arxiv.org/abs/2406.05925#:~:text=generation,various%20illustrative%20benchmarks%2C%20models%2C%20and)).

Tá»•ng káº¿t láº¡i, cÃ¡ch tiáº¿p cáº­n nÃ©n vÃ  truy há»“i ngá»¯ cáº£nh hiá»‡n lÃ  hÆ°á»›ng **Æ°u viá»‡t nháº¥t** Ä‘á»ƒ hiá»‡n thá»±c hÃ³a trÃ­ nhá»› dÃ i háº¡n trong Ä‘á»‘i thoáº¡i. NÃ³ táº­n dá»¥ng Ä‘Æ°á»£c sá»©c máº¡nh cá»§a cÃ¡c mÃ´ hÃ¬nh pretrained (báº±ng cÃ¡ch cung cáº¥p cho chÃºng â€œcontext má»Ÿ rá»™ngâ€ khi cáº§n), Ä‘á»“ng thá»i trÃ¡nh Ä‘Æ°á»£c cÃ¡c háº¡n cháº¿ vá» Ä‘á»™ dÃ i vÃ  quÃªn thÃ´ng tin do tá»± mÃ´ hÃ¬nh xá»­ lÃ½. CÃ¡c nghiÃªn cá»©u Ä‘ang tiáº¿p tá»¥c cáº£i tiáº¿n á»Ÿ cáº£ khÃ¢u tÃ³m táº¯t (Ä‘á»ƒ lÆ°u Ä‘Ãºng vÃ  Ä‘á»§ thÃ´ng tin cáº§n nhá»›) láº«n khÃ¢u truy há»“i (Ä‘á»ƒ tÃ¬m chÃ­nh xÃ¡c thÃ´ng tin khi cáº§n Ä‘áº¿n). Pháº§n tiáº¿p theo, chÃºng tÃ´i sáº½ so sÃ¡nh má»™t sá»‘ há»‡ thá»‘ng tiÃªu biá»ƒu thuá»™c hÆ°á»›ng nÃ y vÃ  cÃ¡c baseline liÃªn quan, trÆ°á»›c khi Ä‘i vÃ o Ä‘Ã¡nh giÃ¡ tá»•ng thá»ƒ trÃªn cÃ¡c benchmark.

# So sÃ¡nh cÃ¡c há»‡ thá»‘ng tiÃªu biá»ƒu cÃ³ bá»™ nhá»› há»™i thoáº¡i

Äá»ƒ minh há»a cá»¥ thá»ƒ sá»± khÃ¡c biá»‡t giá»¯a cÃ¡c hÆ°á»›ng tiáº¿p cáº­n vÃ  hiá»‡u quáº£ cá»§a trÃ­ nhá»› dÃ i háº¡n, báº£ng dÆ°á»›i Ä‘Ã¢y so sÃ¡nh **má»™t sá»‘ há»‡ thá»‘ng tiÃªu biá»ƒu** tá»« trÆ°á»›c Ä‘áº¿n nay:

- **MemNN (Memory Network, 2015)**: ÄÃ¢y lÃ  baseline kiá»ƒu (2) â€“ mÃ´ hÃ¬nh cÃ³ bá»™ nhá»› kháº£ vi. MemNN lÆ°u trá»¯ cÃ¡c phÃ¡t ngÃ´n trÆ°á»›c dÆ°á»›i dáº¡ng vector trong bá»™ nhá»› vÃ  sá»­ dá»¥ng attention Ä‘á»ƒ chá»n ra vector liÃªn quan nháº¥t khi tráº£ lá»i ([[1410.3916] Memory Networks](https://arxiv.org/abs/1410.3916#:~:text=,chaining%20multiple%20supporting%20sentences%20to)). MÃ´ hÃ¬nh nÃ y hoáº¡t Ä‘á»™ng tá»‘t trÃªn cÃ¡c bÃ i toÃ¡n giáº£ láº­p ngáº¯n (nhÆ° bAbI) nhÆ°ng chÆ°a Ä‘Æ°á»£c chá»©ng minh hiá»‡u quáº£ trÃªn Ä‘á»‘i thoáº¡i má»Ÿ phá»©c táº¡p. **Æ¯u Ä‘iá»ƒm**: cÃ³ kháº£ nÄƒng suy luáº­n nhiá»u bÆ°á»›c nhá» Ä‘á»c nhiá»u Ã´ nhá»›; **NhÆ°á»£c Ä‘iá»ƒm**: khÃ³ huáº¥n luyá»‡n end-to-end, khÃ´ng tá»± Ä‘á»™ng cáº­p nháº­t khi thÃ´ng tin thay Ä‘á»•i (cáº§n ghi Ä‘Ã¨ thá»§ cÃ´ng).
    
- **Baseline khÃ´ng nhá»› (No Memory)**: ÄÃ¢y lÃ  há»‡ thá»‘ng kiá»ƒu tráº£ lá»i Ä‘á»™c láº­p tá»«ng lÆ°á»£t, vÃ­ dá»¥ DrQA hoáº·c cÃ¡c model seq2seq khÃ´ng cung cáº¥p lá»‹ch sá»­ vÃ o input. Há»‡ thá»‘ng nÃ y hoÃ n toÃ n _quÃªn_ má»i thá»© sau má»—i lÆ°á»£t, nÃªn **khÃ´ng thá»ƒ** tráº£ lá»i cÃ¡c cÃ¢u há»i phá»¥ thuá»™c ngá»¯ cáº£nh trÆ°á»›c (vd: â€œAnh áº¥yâ€ lÃ  ai?) vÃ  dá»… tráº£ lá»i láº·p láº¡i. Káº¿t quáº£ Ä‘á»‘i thoáº¡i thÆ°á»ng kÃ©m tá»± nhiÃªn vÃ  khÃ´ng duy trÃ¬ Ä‘Æ°á»£c máº¡ch thÃ´ng tin.
    
- **Keep Me Updated (Bae et al., 2022)**: Há»‡ thá»‘ng nÃ y thuá»™c hÆ°á»›ng (3) â€“ dÃ¹ng bá»™ nhá»› ngoÃ i vÄƒn báº£n vá»›i cáº­p nháº­t Ä‘á»™ng. NÃ³ tÃ³m táº¯t thÃ´ng tin ngÆ°á»i dÃ¹ng sau má»—i phiÃªn vÃ  thá»±c hiá»‡n cÃ¡c phÃ©p cáº­p nháº­t (thÃªm/xÃ³a/thay tháº¿) Ä‘á»ƒ bá»™ nhá»› luÃ´n nháº¥t quÃ¡n ([](https://aclanthology.org/2022.findings-emnlp.276.pdf#:~:text=Specifically%2C%20the%20memory%20management%20mechanism,%E2%80%9CJust%20got%20positive%20results%20from)). **Æ¯u Ä‘iá»ƒm**: Ä‘áº£m báº£o thÃ´ng tin má»›i nháº¥t luÃ´n Ä‘Æ°á»£c ghi nhá»›, trÃ¡nh mÃ¢u thuáº«n (nhá» chiáº¿n lÆ°á»£c cáº­p nháº­t) ([](https://aclanthology.org/2022.findings-emnlp.276.pdf#:~:text=find%20and%20eliminate%20the%20information,in%20sub%02sequent%20sessions%2C%20a%20relevant)); cho tháº¥y _cÃ ng nhiá»u phiÃªn_ thÃ¬ bot cÃ ng nhá»› tá»‘t hÆ¡n vÃ  tÆ°Æ¡ng tÃ¡c tá»± nhiÃªn hÆ¡n ([](https://aclanthology.org/2022.findings-emnlp.276.pdf#:~:text=With%20extensive%20experiments%20and%20ablations%2C,date)). **Háº¡n cháº¿**: chá»‰ lÆ°u thÃ´ng tin dÆ°á»›i dáº¡ng vÄƒn báº£n ngáº¯n nÃªn Ä‘Ã´i khi máº¥t chi tiáº¿t, vÃ  chÆ°a xá»­ lÃ½ tá»‘t trÆ°á»ng há»£p nhiá»u thÃ´ng tin khÃ¡c loáº¡i (vÃ¬ táº¥t cáº£ lÆ°u chung má»™t nÆ¡i).
    
- **LD-Agent (Hao Li et al., 2024)**: Äáº¡i diá»‡n tiÃªn tiáº¿n cho hÆ°á»›ng (3) vá»›i cáº¥u trÃºc module hÃ³a. LD-Agent cÃ³ **bá»™ nhá»› hai táº§ng** (dÃ i háº¡n + ngáº¯n háº¡n) vÃ  thÃªm **mÃ´-Ä‘un persona** riÃªng ([[2406.05925] Hello Again! LLM-powered Personalized Agent for Long-term Dialogue](https://arxiv.org/abs/2406.05925#:~:text=the%20Long,Agent%20are)). Nhá» Ä‘Ã³, nÃ³ khÃ´ng chá»‰ nhá»› sá»± kiá»‡n mÃ  cÃ²n duy trÃ¬ Ä‘Æ°á»£c tÃ­nh cÃ¡ch, thÃ´ng tin nhÃ¢n kháº©u cá»§a cáº£ ngÆ°á»i dÃ¹ng vÃ  agent. **Æ¯u Ä‘iá»ƒm**: kiáº¿n trÃºc linh hoáº¡t, truy há»“i theo chá»§ Ä‘á» giÃºp tÃ¬m Ä‘Ãºng sá»± kiá»‡n; persona Ä‘á»™ng giÃºp Ä‘á»‘i thoáº¡i nháº¥t quÃ¡n vai; Ä‘áº¡t káº¿t quáº£ tá»‘t trÃªn nhiá»u tÃ¡c vá»¥ (há»i Ä‘Ã¡p, trÃ² chuyá»‡n nhiá»u chá»§ Ä‘á») ([[2406.05925] Hello Again! LLM-powered Personalized Agent for Long-term Dialogue](https://arxiv.org/abs/2406.05925#:~:text=generation,various%20illustrative%20benchmarks%2C%20models%2C%20and)). **NhÆ°á»£c Ä‘iá»ƒm**: phá»©c táº¡p, cáº§n dá»¯ liá»‡u huáº¥n luyá»‡n phong phÃº (vÃ­ dá»¥ dá»¯ liá»‡u gÃ¡n nhÃ£n persona).
    
- **Theanine (NAACL 2025)**: MÃ´ hÃ¬nh nÃ y cÅ©ng thuá»™c (3) nhÆ°ng vá»›i cÃ¡ch quáº£n lÃ½ memory Ä‘áº·c biá»‡t (Ä‘á»“ thá»‹ timeline) ([[2406.10996] Towards Lifelong Dialogue Agents via Timeline-based Memory Management](https://arxiv.org/abs/2406.10996#:~:text=to%20improve%20retrieval%20quality%2C%20we,human%20efforts%20when%20assessing%20agent)). **Æ¯u**: khÃ´ng xÃ³a kÃ½ á»©c cÅ©, do Ä‘Ã³ sá»­ dá»¥ng Ä‘Æ°á»£c cáº£ bá»‘i cáº£nh lÃ¢u dÃ i Ä‘á»ƒ suy luáº­n sá»± thay Ä‘á»•i; dÃ¹ng LLM táº¡o _memory timeline_ giÃºp giáº£i thÃ­ch Ä‘Æ°á»£c máº¡ch sá»± kiá»‡n. Tuy nhiÃªn, do khÃ´ng xÃ³a nÃªn **thÃ¡ch thá»©c** lÃ  kiá»ƒm soÃ¡t kÃ­ch thÆ°á»›c bá»™ nhá»› vÃ  trÃ¡nh retrieval nháº§m tá»« nhá»¯ng kÃ½ á»©c quÃ¡ cÅ© khÃ´ng cÃ²n Ä‘Ãºng.
    
- **MemoryBank (AAAI 2023)**: Há»‡ thá»‘ng (3) vá»›i cÆ¡ cháº¿ quÃªn cÃ³ chá»n lá»c. **Æ¯u**: giá»‘ng nÃ£o ngÆ°á»i hÆ¡n â€“ tá»± Ä‘á»™ng lÃ m má» cÃ¡c memory Ã­t quan trá»ng, cá»§ng cá»‘ memory quan trá»ng ([[2305.10250] MemoryBank: Enhancing Large Language Models with Long-Term Memory](https://ar5iv.labs.arxiv.org/html/2305.10250#:~:text=personality%20over%20time%20by%20synthesizing,based%20chatbot%20named)). NgoÃ i ra, MemoryBank lÆ°u trá»¯ Ä‘a dáº¡ng: _log há»™i thoáº¡i chi tiáº¿t, báº£n tÃ³m táº¯t sá»± kiá»‡n Ä‘á»‹nh ká»³, vÃ  há»“ sÆ¡ ngÆ°á»i dÃ¹ng_ (user portrait) ([Augmenting LLMs with Retrieval, Tools, and Long-term Memory | by Alaa Dania Adimi | InfinitGraph | Mar, 2025 | Medium](https://medium.com/@ja_adimi/augmenting-llms-with-retrieval-tools-and-long-term-memory-b9e1e6b2fc28#:~:text=Memory%20Storage%3A%20The%20Warehouse%20of,Memories)) ([Augmenting LLMs with Retrieval, Tools, and Long-term Memory | by Alaa Dania Adimi | InfinitGraph | Mar, 2025 | Medium](https://medium.com/@ja_adimi/augmenting-llms-with-retrieval-tools-and-long-term-memory-b9e1e6b2fc28#:~:text=level%20overviews%20of%20daily%20events,tailor%20its%20responses%20over%20time)), do Ä‘Ã³ cung cáº¥p ngá»¯ cáº£nh ráº¥t phong phÃº cho mÃ´ hÃ¬nh. Káº¿t quáº£ cho tháº¥y chatbot tÃ­ch há»£p MemoryBank cÃ³ thá»ƒ **thá»ƒ hiá»‡n sá»± tháº¥u hiá»ƒu vÃ  ghi nhá»›** vÆ°á»£t trá»™i, nhÆ° nhá»› sá»Ÿ thÃ­ch ngÆ°á»i dÃ¹ng qua nhiá»u tuáº§n lá»… ([[2305.10250] MemoryBank: Enhancing Large Language Models with Long-Term Memory](https://ar5iv.labs.arxiv.org/html/2305.10250#:~:text=psychological%20counseling%2C%20and%20secretarial%20assistance,the%20memory%2C%20thereby%20offering%20a)) ([Augmenting LLMs with Retrieval, Tools, and Long-term Memory | by Alaa Dania Adimi | InfinitGraph | Mar, 2025 | Medium](https://medium.com/@ja_adimi/augmenting-llms-with-retrieval-tools-and-long-term-memory-b9e1e6b2fc28#:~:text=,tailor%20its%20responses%20over%20time)). Äiá»ƒm cáº§n cáº£i tiáº¿n lÃ  Ä‘áº£m báº£o cÆ¡ cháº¿ quÃªn khÃ´ng vÃ´ tÃ¬nh loáº¡i bá» thÃ´ng tin cáº§n thiáº¿t náº¿u thá»i gian kÃ©o dÃ i (cÃ¢n báº±ng giá»¯a quÃªn vÃ  nhá»› Ä‘Ãºng).
    

NhÃ¬n chung, **xu hÆ°á»›ng phÃ¡t triá»ƒn** cho tháº¥y sá»± chuyá»ƒn dá»‹ch tá»« cÃ¡c mÃ´ hÃ¬nh khÃ´ng nhá»› hoáº·c nhá»› ngáº¯n háº¡n (BiDAF++, DrQA) sang cÃ¡c há»‡ thá»‘ng cÃ³ bá»™ nhá»› ngÃ y cÃ ng thÃ´ng minh hÆ¡n (Keep Me Updated, MemoryBank, Theanine, LD-Agent). Báº£ng so sÃ¡nh trÃªn nháº¥n máº¡nh vai trÃ² cá»§a cÃ¡c thÃ nh pháº§n nhÆ° **cáº­p nháº­t bá»™ nhá»›** (update), **cáº¥u trÃºc hÃ³a thÃ´ng tin** (theo sá»± kiá»‡n, theo persona), cÅ©ng nhÆ° nhá»¯ng phÆ°Æ¡ng phÃ¡p láº¥y cáº£m há»©ng tá»« tÃ¢m lÃ½ há»c (quÃªn cÃ³ chá»n lá»c) Ä‘á»ƒ nÃ¢ng cao cháº¥t lÆ°á»£ng tÆ°Æ¡ng tÃ¡c dÃ i háº¡n. Pháº§n tiáº¿p theo, chÃºng tÃ´i sáº½ giá»›i thiá»‡u cÃ¡c **benchmark vÃ  tiÃªu chÃ­ Ä‘Ã¡nh giÃ¡** Ä‘Æ°á»£c Ä‘á» xuáº¥t nháº±m Ä‘o lÆ°á»ng má»™t cÃ¡ch há»‡ thá»‘ng kháº£ nÄƒng ghi nhá»› dÃ i háº¡n cá»§a cÃ¡c mÃ´ hÃ¬nh Ä‘á»‘i thoáº¡i nÃ y.

# Benchmark vÃ  tiÃªu chÃ­ Ä‘Ã¡nh giÃ¡ trÃ­ nhá»› trong há»™i thoáº¡i

Äá»ƒ Ä‘Ã¡nh giÃ¡ khÃ¡ch quan kháº£ nÄƒng ghi nhá»› vÃ  sá»­ dá»¥ng thÃ´ng tin dÃ i háº¡n, cÃ¡c nhÃ  nghiÃªn cá»©u Ä‘Ã£ xÃ¢y dá»±ng má»™t sá»‘ **benchmark chuyÃªn biá»‡t** cÅ©ng nhÆ° sá»­ dá»¥ng cÃ¡c bá»™ dá»¯ liá»‡u há»™i thoáº¡i cÃ³ yáº¿u tá»‘ nhá»›. DÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c bá»™ dá»¯ liá»‡u vÃ  tiÃªu chÃ­ ná»•i báº­t:

- **LongMemEval (Wu et al., 2024)** â€“ ÄÃ¢y lÃ  má»™t bá»™ Ä‘Ã¡nh giÃ¡ toÃ n diá»‡n Ä‘áº§u tiÃªn táº­p trung vÃ o **5 ká»¹ nÄƒng trÃ­ nhá»› lÃµi** cá»§a trá»£ lÃ½ chat ([[2410.10813] LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory](https://arxiv.org/abs/2410.10813#:~:text=capabilities%20in%20sustained%20interactions%20remain,on%20memorizing%20information%20across%20sustained)). NÄƒm ká»¹ nÄƒng Ä‘Ã³ bao gá»“m: (1) **Nhá»› vÃ  trÃ­ch thÃ´ng tin** (Information Extraction) â€“ kiá»ƒm tra xem mÃ´ hÃ¬nh cÃ³ nhá»› chÃ­nh xÃ¡c cÃ¡c chi tiáº¿t Ä‘Æ°á»£c Ä‘á» cáº­p trÆ°á»›c Ä‘Ã³ hay khÃ´ng; (2) **Suy luáº­n Ä‘a phiÃªn** (Multi-session reasoning) â€“ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng káº¿t ná»‘i thÃ´ng tin qua nhiá»u phiÃªn trÃ² chuyá»‡n rá»i (vÃ­ dá»¥: ngÆ°á»i dÃ¹ng nÃ³i A á»Ÿ tuáº§n trÆ°á»›c vÃ  B á»Ÿ tuáº§n nÃ y, liá»‡u bot cÃ³ káº¿t há»£p A vÃ  B Ä‘á»ƒ tráº£ lá»i?); (3) **Suy luáº­n thá»i gian** (Temporal reasoning) â€“ kiá»ƒm tra hiá»ƒu biáº¿t vá» trÃ¬nh tá»± thá»i gian, nguyÃªn nhÃ¢n-káº¿t quáº£ theo thá»i gian (vÃ­ dá»¥ sá»± kiá»‡n X xáº£y ra sau Y thÃ¬ há»‡ quáº£ ra sao); (4) **Cáº­p nháº­t kiáº¿n thá»©c** (Knowledge updates) â€“ Ä‘Ã¡nh giÃ¡ viá»‡c bot cÃ³ sá»­ dá»¥ng thÃ´ng tin má»›i thay cho thÃ´ng tin cÅ© khi chÃºng mÃ¢u thuáº«n (giá»‘ng bÃ i toÃ¡n cáº­p nháº­t trÃ­ nhá»› COVID á»Ÿ trÃªn); (5) **Abstention (tá»« chá»‘i)** â€“ xem mÃ´ hÃ¬nh cÃ³ biáº¿t tá»« chá»‘i tráº£ lá»i khi khÃ´ng cháº¯c do thiáº¿u trÃ­ nhá»› hay khÃ´ng (trÃ¡nh trÆ°á»ng há»£p Ä‘oÃ¡n bá»«a/hallucinate) ([[2410.10813] LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory](https://arxiv.org/abs/2410.10813#:~:text=capabilities%20in%20sustained%20interactions%20remain,term)). LongMemEval gá»“m 500 cÃ¢u há»i Ä‘Æ°á»£c gÃ i cáº©n tháº­n vÃ o cÃ¡c lá»‹ch sá»­ há»™i thoáº¡i dÃ i, má»—i cÃ¢u há»i tÆ°Æ¡ng á»©ng kiá»ƒm tra má»™t khÃ­a cáº¡nh trÃªn. Káº¿t quáº£ thá»±c nghiá»‡m cho tháº¥y cÃ¡c chatbot hiá»‡n táº¡i (ká»ƒ cáº£ mÃ´ hÃ¬nh lá»›n vá»›i ngá»¯ cáº£nh dÃ i) **giáº£m hiá»‡u suáº¥t tá»›i ~30%** khi pháº£i ghi nhá»› thÃ´ng tin tráº£i dÃ i, so vá»›i cÃ¡c cÃ¢u há»i ngáº¯n háº¡n ([[2410.10813] LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory](https://arxiv.org/abs/2410.10813#:~:text=meticulously%20curated%20questions%20embedded%20within,augmented%20key)). Äiá»u nÃ y kháº³ng Ä‘á»‹nh Ä‘á»™ khÃ³ cá»§a bÃ i toÃ¡n vÃ  sá»± cáº§n thiáº¿t cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p memory augmentation. LongMemEval hiá»‡n Ä‘Æ°á»£c coi lÃ  thÆ°á»›c Ä‘o tiÃªu chuáº©n, khuyáº¿n khÃ­ch cÃ¡c nghiÃªn cá»©u tÆ°Æ¡ng lai cáº£i thiá»‡n cáº£ 5 ká»¹ nÄƒng ká»ƒ trÃªn Ä‘á»ƒ tiáº¿n tá»›i trá»£ lÃ½ Ä‘á»‘i thoáº¡i Ä‘Ã¡ng tin cáº­y hÆ¡n ([[2410.10813] LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory](https://arxiv.org/abs/2410.10813#:~:text=interactions,term)).
    
- **LOCOMO (Maharana et al., 2024)** â€“ LÃ  viáº¿t táº¯t cá»§a _Long Conversation Model_, Ä‘Ã¢y Ä‘Æ°á»£c bÃ¡o cÃ¡o lÃ  bá»™ dá»¯ liá»‡u há»™i thoáº¡i _dÃ i nháº¥t_ hiá»‡n nay, vá»›i trung bÃ¬nh **300 lÆ°á»£t thoáº¡i (9k token)** má»—i há»™i thoáº¡i ([On Memory Construction and Retrieval for Personalized Conversational Agents](https://arxiv.org/html/2502.05589v2#:~:text=%28i%29%20LOCOMO%C2%A0%28Maharana%20et%C2%A0al,on%20the%20recently%20released%20official)). LOCOMO mÃ´ phá»ng cÃ¡c cuá»™c trÃ² chuyá»‡n liÃªn tá»¥c, nhiá»u chá»§ Ä‘á», Ä‘Ã²i há»i mÃ´ hÃ¬nh pháº£i duy trÃ¬ tÆ°Æ¡ng tÃ¡c máº¡ch láº¡c trong thá»i gian ráº¥t dÃ i. Äá»ƒ Ä‘Ã¡nh giÃ¡, tÃ¡c giáº£ dÃ¹ng GPT-4 sinh ra cÃ¡c cÃ¢u há»i kiá»ƒm tra vá» ná»™i dung Ä‘Ã£ nÃ³i tá»« ráº¥t sá»›m trong phiÃªn, nháº±m xem bot cÃ³ nhá»› hay khÃ´ng ([On Memory Construction and Retrieval for Personalized Conversational Agents](https://arxiv.org/html/2502.05589v2#:~:text=%28i%29%20LOCOMO%C2%A0%28Maharana%20et%C2%A0al,on%20the%20recently%20released%20official)). NgoÃ i ra, LOCOMO cÃ²n Ä‘o lÆ°á»ng má»©c Ä‘á»™ trÃ´i cháº£y vÃ  nháº¥t quÃ¡n qua thÆ°á»›c Ä‘o **GPT4Score** vÃ  cÃ¡c chá»‰ sá»‘ ngÃ´n ngá»¯ tá»± nhiÃªn (BLEU, ROUGE) cho pháº£n há»“i cá»§a mÃ´ hÃ¬nh ([On Memory Construction and Retrieval for Personalized Conversational Agents](https://arxiv.org/html/2502.05589v2#:~:text=long,in%20performance%20improvements%20up%20to)) ([On Memory Construction and Retrieval for Personalized Conversational Agents](https://arxiv.org/html/2502.05589v2#:~:text=Methods%20LOCOMO%20Long,44)). CÃ¹ng vá»›i LOCOMO, má»™t sá»‘ biáº¿n thá»ƒ nhÆ° **Long-MT-Bench+** cÅ©ng Ä‘Æ°á»£c dÃ¹ng â€“ Ä‘Ã¢y lÃ  má»Ÿ rá»™ng cá»§a bá»™ Ä‘Ã¡nh giÃ¡ Multi-Turn Dialogue (MT-Bench) dÃ nh riÃªng cho há»™i thoáº¡i dÃ i. CÃ¡c káº¿t quáº£ baseline trÃªn LOCOMO cho tháº¥y náº¿u mÃ´ hÃ¬nh chá»‰ dÃ¹ng lá»‹ch sá»­ ráº¥t ngáº¯n (hoáº·c khÃ´ng lá»‹ch sá»­) thÃ¬ Ä‘iá»ƒm sá»‘ tráº£ lá»i Ä‘Ãºng ráº¥t tháº¥p (~25-50), trong khi dÃ¹ng full history nÃ¢ng lÃªn ~54 ([On Memory Construction and Retrieval for Personalized Conversational Agents](https://arxiv.org/html/2502.05589v2#:~:text=match%20at%20L389%20LOCOMO%20Zero,77%203%2C288)). Tuy nhiÃªn, dÃ¹ng full history phiáº¿n diá»‡n cÅ©ng gÃ¢y má»i model (13,000 token) vÃ  khÃ´ng nháº¥t thiáº¿t tá»‘i Æ°u. Do váº­y LOCOMO Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ thá»­ nghiá»‡m cÃ¡c chiáº¿n lÆ°á»£c nhá»›: thÃ­ dá»¥ SeCom trÃªn LOCOMO Ä‘áº¡t **GPT4Score ~69**, cao hÆ¡n háº³n so vá»›i mÃ´ hÃ¬nh khÃ´ng module nhá»› (~24) ([On Memory Construction and Retrieval for Personalized Conversational Agents](https://arxiv.org/html/2502.05589v2#:~:text=LOCOMO%20Zero%20History%2024,77%203%2C288)) ([On Memory Construction and Retrieval for Personalized Conversational Agents](https://arxiv.org/html/2502.05589v2#:~:text=Methods%20LOCOMO%20Long,44)). Äiá»u nÃ y xÃ¡c nháº­n lá»£i Ã­ch rÃµ rá»‡t cá»§a memory Ä‘á»‘i vá»›i há»™i thoáº¡i siÃªu dÃ i.
    
- **CÃ¡c bá»™ dá»¯ liá»‡u personalized vÃ  multi-session**: TrÆ°á»›c khi cÃ³ cÃ¡c benchmark trÃªn, má»™t sá»‘ bá»™ dá»¯ liá»‡u há»™i thoáº¡i Ä‘Æ°á»£c táº¡o ra nháº±m kiá»ƒm tra má»™t pháº§n khÃ­a cáº¡nh cá»§a trÃ­ nhá»›. **Persona-Chat (Zhang et al., 2018)** cung cáº¥p cho má»—i nhÃ¢n váº­t má»™t há»“ sÆ¡ sá»Ÿ thÃ­ch (5 cÃ¢u mÃ´ táº£) vÃ  yÃªu cáº§u mÃ´ hÃ¬nh trÃ² chuyá»‡n giá»¯ Ä‘Ãºng persona nÃ y. ÄÃ¢y lÃ  kiá»ƒm tra kháº£ nÄƒng **nhá»› thÃ´ng tin há»“ sÆ¡ tÄ©nh** â€“ gáº§n vá»›i memory ngáº¯n háº¡n (vÃ¬ persona khÃ´ng Ä‘á»•i). **MuTual (Cui et al., 2020)** vÃ  **DSTC7,8** cung cáº¥p cÃ¡c Ä‘oáº¡n há»™i thoáº¡i yÃªu cáº§u suy luáº­n logic giá»¯a cÃ¡c lÆ°á»£t â€“ giÃ¡n tiáº¿p Ä‘Ã²i há»i nhá»› ná»™i dung trÆ°á»›c. **QuAC, CoQA (2018)** nhÆ° Ä‘Ã£ Ä‘á» cáº­p, Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng tráº£ lá»i dá»±a vÃ o nhiá»u lÆ°á»£t há»i trÆ°á»›c (context co-reference). Tuy nhiÃªn, cÃ¡c dataset nÃ y thÆ°á»ng chá»‰ kÃ©o dÃ i tá»‘i Ä‘a vÃ i chá»¥c lÆ°á»£t trong má»™t phiÃªn, vÃ  khÃ´ng Ä‘Ã¡nh giÃ¡ xuyÃªn phiÃªn hay cáº­p nháº­t. Gáº§n Ä‘Ã¢y, má»™t sá»‘ dataset hÆ°á»›ng Ä‘áº¿n **Ä‘a phiÃªn**: vÃ­ dá»¥ **MSC (Multi-Session Chat)** (Xu et al., 2022) ná»‘i 2-3 phiÃªn PersonaChat láº¡i Ä‘á»ƒ xem bot cÃ³ nhá»› thÃ´ng tin giá»¯a cÃ¡c phiÃªn; hay **CareCall-Mem** (Bae et al., 2022) â€“ dá»¯ liá»‡u tiáº¿ng HÃ n mÃ  nhÃ³m Keep Me Updated xÃ¢y dá»±ng â€“ gá»“m 5 phiÃªn trÃ² chuyá»‡n giá»¯a bot vÃ  má»™t ngÆ°á»i dÃ¹ng hÆ° cáº¥u vá»›i cÃ¡c thÃ´ng tin cÃ¡ nhÃ¢n thay Ä‘á»•i theo thá»i gian (sá»©c khá»e, thÃ³i quen) ([](https://aclanthology.org/2022.findings-emnlp.276.pdf#:~:text=3,We%20extend%20this)) ([](https://aclanthology.org/2022.findings-emnlp.276.pdf#:~:text=single,Sessions%207%2C665%20Session%201%202%2C812)). CÃ¡c dataset nÃ y phá»¥c vá»¥ huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh trong bá»‘i cáº£nh **thÃ´ng tin ngÆ°á»i dÃ¹ng thay Ä‘á»•i**: vÃ­ dá»¥ phiÃªn 1 nÃ³i â€œghÃ©t váº­n Ä‘á»™ngâ€, phiÃªn 3 láº¡i nÃ³i â€œÄ‘ang há»c bÆ¡iâ€ thÃ¬ bot pháº£i hiá»ƒu sá»Ÿ thÃ­ch Ä‘Ã£ thay Ä‘á»•i. TiÃªu chÃ­ Ä‘Ã¡nh giÃ¡ gá»“m Ä‘á»™ tá»± nhiÃªn, tÃ­nh gáº¯n káº¿t, vÃ  quan trá»ng lÃ  **Ä‘á»™ chÃ­nh xÃ¡c cá»§a thÃ´ng tin** mÃ  bot nÃ³i ra so vá»›i há»“ sÆ¡ thá»±c táº¿ (trÃ¡nh nháº§m thÃ´ng tin cÅ©).
    
- **TiÃªu chÃ­ Ä‘Ã¡nh giÃ¡**: Dá»±a trÃªn cÃ¡c benchmark trÃªn, ta cÃ³ thá»ƒ liá»‡t kÃª nhá»¯ng tiÃªu chÃ­ chÃ­nh Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng trÃ­ nhá»› dÃ i háº¡n cá»§a há»‡ thá»‘ng há»™i thoáº¡i:
    
    - _ChÃ­nh xÃ¡c thÃ´ng tin Ä‘Ã£ nhá»› (Memory Recall)_: Kiá»ƒm tra tá»‰ lá»‡ thÃ´ng tin Ä‘Ãºng Ä‘Æ°á»£c bot nháº¯c láº¡i khi cáº§n. VÃ­ dá»¥, user Ä‘Ã£ nÃ³i há» sinh nÄƒm 1990, sau 10 lÆ°á»£t bot Ä‘á» cáº­p láº¡i Ä‘Ãºng nÄƒm sinh hay khÃ´ng. TiÃªu chÃ­ nÃ y Ä‘o báº±ng cÃ¢u há»i trá»±c tiáº¿p (nhÆ° LongMemEval) hoáº·c so khá»›p vá»›i log quÃ¡ khá»©.
        
    - _Pháº£n há»“i nháº¥t quÃ¡n, khÃ´ng áº£o giÃ¡c (Consistency & No-hallucination)_: ÄÃ¡nh giÃ¡ xem bot cÃ³ mÃ¢u thuáº«n vá»›i chÃ­nh nÃ³ hoáº·c vá»›i thá»±c táº¿ Ä‘Ã£ biáº¿t khÃ´ng, vÃ  cÃ³ bá»‹a Ä‘áº·t thÃ´ng tin khÃ´ng cÃ³ trong bá»™ nhá»› khÃ´ng. Náº¿u bot _quÃªn_ má»™t chi tiáº¿t vÃ  tá»± cháº¿ ra, Ä‘Ã³ lÃ  Ä‘iá»ƒm trá»« lá»›n. ThÆ°á»›c Ä‘o cÃ³ thá»ƒ báº±ng kiá»ƒm tra logic (vÃ­ dá»¥ Persona-Chat yÃªu cáº§u khÃ´ng nÃ³i sai persona), hoáº·c nhá» Ä‘Ã¡nh giÃ¡ cá»§a mÃ´ hÃ¬nh/human xem cÃ¢u tráº£ lá»i cÃ³ cÄƒn cá»© quÃ¡ khá»© hay khÃ´ng.
        
    - _Cáº­p nháº­t kiáº¿n thá»©c ká»‹p thá»i (Knowledge Update Accuracy)_: Khi ngÆ°á»i dÃ¹ng cung cáº¥p thÃ´ng tin má»›i hoáº·c Ä‘Ã­nh chÃ­nh, bot cÃ³ pháº£n Ã¡nh Ä‘Ãºng sá»± thay Ä‘á»•i trong cÃ¡c lÆ°á»£t sau khÃ´ng. TiÃªu chÃ­ nÃ y thÆ°á»ng Ä‘Ã¡nh giÃ¡ theo ká»‹ch báº£n: vÃ­ dá»¥ nhÆ° bÃ i toÃ¡n COVID test á»Ÿ trÃªn â€“ sau khi user bÃ¡o dÆ°Æ¡ng tÃ­nh, bot pháº£i quÃªn thÃ´ng tin â€œchÆ°a xÃ©t nghiá»‡mâ€ trÆ°á»›c Ä‘Ã³. CÃ³ thá»ƒ Ä‘o báº±ng truy váº¥n sau update xem bot tráº£ lá»i dá»±a trÃªn thÃ´ng tin nÃ o.
        
    - _Suy luáº­n theo dÃ²ng thá»i gian (Temporal Reasoning)_: Bot cÃ³ hiá»ƒu má»‘i quan há»‡ thá»i gian giá»¯a cÃ¡c sá»± kiá»‡n trong trÃ­ nhá»› khÃ´ng. VÃ­ dá»¥, user nÃ³i â€œnÄƒm 2020 tÃ´i tá»‘t nghiá»‡pâ€, sau Ä‘Ã³ há»i â€œ2 nÄƒm sau tÃ´i lÃ m gÃ¬â€ â€“ bot pháº£i biáº¿t 2 nÄƒm sau 2020 lÃ  2022 vÃ  tÃ¬m trong memory xem 2022 cÃ³ sá»± kiá»‡n gÃ¬ (hoáº·c tráº£ lá»i chÆ°a biáº¿t náº¿u khÃ´ng cÃ³). Kháº£ nÄƒng nÃ y thÆ°á»ng Ä‘o báº±ng cÃ¡c cÃ¢u há»i yÃªu cáº§u káº¿t há»£p má»‘c thá»i gian (nhÆ° trong LongMemEval) ([[2410.10813] LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory](https://arxiv.org/abs/2410.10813#:~:text=capabilities%20in%20sustained%20interactions%20remain,on%20memorizing%20information%20across%20sustained)).
        
    - _Kháº£ nÄƒng tá»« chá»‘i khi khÃ´ng nhá»› (Abstention)_: Má»™t há»‡ thá»‘ng tá»‘t cáº§n biáº¿t giá»›i háº¡n trÃ­ nhá»› cá»§a mÃ¬nh, tá»©c lÃ  náº¿u thÃ´ng tin khÃ´ng cÃ³ trong bá»™ nhá»› thÃ¬ nÃªn xin lá»—i hoáº·c tá»« chá»‘i hÆ¡n lÃ  bá»‹a. TiÃªu chÃ­ nÃ y Ä‘Ã¡nh giÃ¡ tá»· lá»‡ bot **khÃ´ng Ä‘oÃ¡n bá»«a**. LongMemEval Ä‘Æ°a ra cÃ¡c tÃ¬nh huá»‘ng mÃ  cÃ¢u há»i ngoÃ i pháº¡m vi nhá»¯ng gÃ¬ Ä‘Ã£ nÃ³i, yÃªu cáº§u bot pháº£i pháº£n há»“i kiá»ƒu â€œTÃ´i khÃ´ng nhá»› rÃµâ€¦â€ thay vÃ¬ cung cáº¥p thÃ´ng tin sai ([[2410.10813] LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory](https://arxiv.org/abs/2410.10813#:~:text=capabilities%20in%20sustained%20interactions%20remain,term)).
        

NgoÃ i ra, cÃ¡c tiÃªu chÃ­ tá»•ng quan nhÆ° **Ä‘á»™ hÃ i lÃ²ng ngÆ°á»i dÃ¹ng, Ä‘á»™ tá»± nhiÃªn cá»§a há»™i thoáº¡i, Ä‘iá»ƒm Ä‘Ã¡nh giÃ¡ cá»§a giÃ¡m kháº£o** cÅ©ng ráº¥t quan trá»ng, nhÆ°ng chÃºng chá»‹u áº£nh hÆ°á»Ÿng nhiá»u yáº¿u tá»‘ ngoÃ i trÃ­ nhá»› (nhÆ° ká»¹ nÄƒng ngÃ´n ngá»¯ chung cá»§a mÃ´ hÃ¬nh). Do Ä‘Ã³, cÃ¡c benchmark chuyÃªn biá»‡t cá»‘ gáº¯ng cÃ´ láº­p áº£nh hÆ°á»Ÿng cá»§a trÃ­ nhá»› Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cÃ´ng báº±ng giá»¯a cÃ¡c giáº£i phÃ¡p.

# HÆ°á»›ng má»Ÿ rá»™ng vÃ  káº¿t luáº­n

**TrÃ­ nhá»› dÃ i háº¡n cho há»‡ thá»‘ng Ä‘á»‘i thoáº¡i** váº«n lÃ  má»™t bÃ i toÃ¡n má»Ÿ vá»›i nhiá»u hÆ°á»›ng nghiÃªn cá»©u tiá»m nÄƒng. Dá»±a trÃªn cÃ¡c xu hÆ°á»›ng hiá»‡n táº¡i, cÃ³ thá»ƒ gá»£i Ã½ má»™t sá»‘ hÆ°á»›ng phÃ¡t triá»ƒn chÃ­nh sau:

- **Káº¿t há»£p cháº·t cháº½ giá»¯a truy há»“i vÃ  cáº­p nháº­t tri thá»©c**: Hiá»‡n nay, retrieval augmented generation (RAG) Ä‘Ã£ phá»• biáº¿n trong QA má»Ÿ, nhÆ°ng thÆ°á»ng vá»›i _knowledge base_ tÄ©nh. Má»Ÿ rá»™ng hÆ¡n, ta cÃ³ thá»ƒ tÃ­ch há»£p RAG vÃ o Ä‘á»‘i thoáº¡i sao cho **kho tri thá»©c Ä‘Æ°á»£c cáº­p nháº­t liÃªn tá»¥c trong quÃ¡ trÃ¬nh trÃ² chuyá»‡n**. VÃ­ dá»¥, khi ngÆ°á»i dÃ¹ng cung cáº¥p má»™t thÃ´ng tin má»›i, há»‡ thá»‘ng ngay láº­p tá»©c thÃªm nÃ³ vÃ o _bá»™ nhá»› tri thá»©c_ vÃ  cÃ¡c lÆ°á»£t sau truy há»“i cÃ³ thá»ƒ láº¥y ra. Äiá»u nÃ y Ä‘Ã²i há»i giáº£i quyáº¿t bÃ i toÃ¡n Ä‘á»“ng bá»™ giá»¯a thÃ nh pháº§n ghi nhá»› vÃ  thÃ nh pháº§n tÃ¬m kiáº¿m. Má»™t hÆ°á»›ng lÃ  phÃ¡t triá»ƒn cÃ¡c phÆ°Æ¡ng phÃ¡p **index Ä‘á»™ng**: cáº­p nháº­t chá»‰ má»¥c bá»™ nhá»› theo thá»i gian thá»±c, hoáº·c sá»­ dá»¥ng mÃ´ hÃ¬nh há»c tÄƒng cÆ°á»ng Ä‘á»ƒ quyáº¿t Ä‘á»‹nh khi nÃ o cáº§n _re-index_.
    
- **Truy há»“i thÃ­ch á»©ng vÃ  cÃ³ hÆ°á»›ng dáº«n**: Thay vÃ¬ luÃ´n truy há»“i má»™t cÃ¡ch mÃ¡y mÃ³c top-k Ä‘oáº¡n giá»‘ng nhÆ° hiá»‡n nay, mÃ´ hÃ¬nh cÃ³ thá»ƒ há»c cÃ¡ch **Ä‘áº·t truy váº¥n thÃ´ng minh** hoáº·c **chá»n lá»c** tÃ¹y tÃ¬nh huá»‘ng. Cháº³ng háº¡n, náº¿u cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng ráº¥t rÃµ rÃ ng (nhÆ° há»i tÃªn Ä‘Ã£ cho trÆ°á»›c Ä‘Ã³), má»™t truy váº¥n tháº³ng sáº½ hiá»‡u quáº£; nhÆ°ng náº¿u cÃ¢u há»i mÆ¡ há»“, mÃ´ hÃ¬nh cÃ³ thá»ƒ tá»± sinh ra má»™t truy váº¥n rÃµ hÆ¡n dá»±a trÃªn ngá»¯ cáº£nh â€“ tÆ°Æ¡ng tá»± ká»¹ thuáº­t _query rewriting_ ([Augmenting LLMs with Retrieval, Tools, and Long-term Memory | by Alaa Dania Adimi | InfinitGraph | Mar, 2025 | Medium](https://medium.com/@ja_adimi/augmenting-llms-with-retrieval-tools-and-long-term-memory-b9e1e6b2fc28#:~:text=Query%20Rewriting)). NgoÃ i ra, mÃ´ hÃ¬nh nÃªn há»c _khi nÃ o_ thÃ¬ cáº§n truy há»“i: Ä‘Ã´i khi, cÃ¢u há»i hiá»‡n táº¡i khÃ´ng liÃªn quan gÃ¬ Ä‘áº¿n quÃ¡ khá»©, viá»‡c truy há»“i chá»‰ thÃªm nhiá»…u. CÃ³ thá»ƒ dÃ¹ng má»™t module phá»¥ (nhÆ° má»™t classifier) Ä‘á»ƒ quyáº¿t Ä‘á»‹nh cÃ³ truy há»“i memory khÃ´ng á»Ÿ má»—i lÆ°á»£t. Má»™t Ã½ tÆ°á»Ÿng khÃ¡c lÃ  cho chÃ­nh LLM **hÆ°á»›ng dáº«n viá»‡c truy há»“i**: vÃ­ dá»¥ trÆ°á»›c khi tráº£ lá»i, mÃ´ hÃ¬nh tá»± suy luáº­n "Äá»ƒ tráº£ lá»i, tÃ´i cáº§n nhá»› X", sau Ä‘Ã³ dÃ¹ng suy luáº­n nÃ y lÃ m chÃ¬a khÃ³a tÃ¬m kiáº¿m bá»™ nhá»›. ÄÃ¢y lÃ  má»™t dáº¡ng _chain-of-thought for retrieval_ Ä‘áº§y há»©a háº¹n.
    
- **Sá»­ dá»¥ng mÃ´ hÃ¬nh ngÃ´n ngá»¯ phá»¥ trá»£ cho quáº£n lÃ½ trÃ­ nhá»›**: Thay vÃ¬ cÃ¡c rule cá»©ng (nhÆ° 4 thao tÃ¡c cá»§a Keep Me Updated), ta cÃ³ thá»ƒ dÃ¹ng má»™t LLM nhá» hoáº·c cÃ¡c prompt Ä‘áº·c biá»‡t cho chÃ­nh LLM lá»›n Ä‘á»ƒ quáº£n lÃ½ memory. VÃ­ dá»¥, cÃ³ thá»ƒ triá»ƒn khai má»™t _â€œMemory Manager Agentâ€_ cháº¡y song song: agent nÃ y dÃ¹ng LLM Ä‘á»ƒ Ä‘á»‹nh ká»³ Ä‘á»c lá»‹ch sá»­ vÃ  viáº¿t tÃ³m táº¯t, lÆ°u vÃ o vector DB; khi cáº§n thÃ¬ há»— trá»£ truy váº¥n vector DB vÃ  cung cáº¥p káº¿t quáº£ cho LLM chÃ­nh. CÃ¡ch tiáº¿p cáº­n kiáº¿n trÃºc agent nÃ y Ä‘Ã£ Ä‘Æ°á»£c Park et al. (2023) thá»­ nghiá»‡m trong **Generative Agents**, nÆ¡i nhiá»u agent LLM tÆ°Æ¡ng tÃ¡c vá»›i nhau vÃ  cÃ³ bá»™ nhá»› sá»± kiá»‡n Ä‘Æ°á»£c ghi láº¡i vÃ  suy diá»…n báº±ng LLM. Má»™t á»©ng dá»¥ng khÃ¡c lÃ  dÃ¹ng LLM Ä‘á»ƒ **Ä‘Ã¡nh giÃ¡ vÃ  chá»‰nh sá»­a** memory: vÃ­ dá»¥ dÃ¹ng GPT-4 Ä‘á»c toÃ n bá»™ memory log vÃ  phÃ¡t hiá»‡n mÃ¢u thuáº«n hoáº·c lá»—i Ä‘á»ƒ sá»­a (má»™t dáº¡ng reviewer). NhÃ¬n chung, táº­n dá»¥ng kháº£ nÄƒng ngÃ´n ngá»¯ Ä‘a nÄƒng cá»§a LLM cho viá»‡c quáº£n trá»‹ trÃ­ nhá»› cÃ³ thá»ƒ Ä‘em láº¡i linh hoáº¡t hÆ¡n so vá»›i cÃ¡ch lÃ m thuáº§n heuristic.
    
- **Má»Ÿ rá»™ng sang Ä‘a mÃ´ hÃ¬nh vÃ  tri thá»©c tháº¿ giá»›i**: TrÃ­ nhá»› há»™i thoáº¡i khÃ´ng chá»‰ gá»“m lá»i thoáº¡i â€“ trong nhiá»u á»©ng dá»¥ng, nÃ³ cáº§n nhá»› cáº£ cÃ¡c **thÃ´ng tin thá»‹ giÃ¡c, cáº£m biáº¿n, hay tri thá»©c ngoÃ i**. HÆ°á»›ng má»Ÿ lÃ  tÃ­ch há»£p **bá»™ nhá»› chung cho Ä‘a mÃ´ hÃ¬nh**: vÃ­ dá»¥ má»™t robot trá»£ lÃ½ nhÃ  thÃ´ng minh cáº§n nhá»› hÃ´m qua camera tháº¥y gÃ¬, ai Ä‘Ã£ ghÃ© thÄƒm, Ä‘á»“ váº­t Ä‘áº·t á»Ÿ Ä‘Ã¢u... cÃ¹ng vá»›i há»™i thoáº¡i vá»›i chá»§ nhÃ . Äiá»u nÃ y Ä‘áº·t ra bÃ i toÃ¡n lÆ°u trá»¯ vÃ  truy há»“i cÃ¡c **Ä‘áº¡i diá»‡n Ä‘a mÃ´ hÃ¬nh** (hÃ¬nh áº£nh, Ã¢m thanh) bÃªn cáº¡nh vÄƒn báº£n. TÆ°Æ¡ng tá»±, káº¿t há»£p **knowledge graph** hoáº·c cÆ¡ sá»Ÿ tri thá»©c vÃ o memory: vÃ­ dá»¥ khi ngÆ°á»i dÃ¹ng nÃ³i sá»Ÿ thÃ­ch, bot cÃ³ thá»ƒ lÆ°u vÃ o má»™t _knowledge graph node_ vá» ngÆ°á»i dÃ¹ng, liÃªn káº¿t vá»›i cÃ¡c node hoáº¡t Ä‘á»™ng tÆ°Æ¡ng á»©ng. Viá»‡c káº¿t há»£p cáº¥u trÃºc tri thá»©c cÃ³ thá»ƒ giÃºp bot suy luáº­n logic vÃ  nháº¥t quÃ¡n hÆ¡n (trÃ¡nh mÃ¢u thuáº«n thá»±c táº¿). Má»™t hÆ°á»›ng lÃ  má»—i khi memory update, Ä‘á»“ng thá»i cáº­p nháº­t knowledge graph, vÃ  dÃ¹ng graph embedding Ä‘á»ƒ há»— trá»£ retrieval song song.
    
- **ÄÃ¡nh giÃ¡ vÃ  giáº£m thiá»ƒu nhiá»…u do trÃ­ nhá»› sai**: Khi tÃ­ch há»£p bá»™ nhá»›, má»™t nguy cÆ¡ lÃ  _nhá»› sai hoáº·c nhá»› mÆ¡ há»“_ cÃ³ thá»ƒ dáº«n Ä‘áº¿n pháº£n há»“i sai (hallucination do memory). Do Ä‘Ã³, cáº§n cÆ¡ cháº¿ **Ä‘Ã¡nh giÃ¡ Ä‘á»™ tin cáº­y cá»§a memory**. Má»™t hÆ°á»›ng lÃ  kÃ¨m theo má»—i máº©u memory má»™t Ä‘á»™ tin cáº­y (confidence score) vÃ  thá»i gian, Ä‘á»ƒ mÃ´ hÃ¬nh Æ°u tiÃªn dÃ¹ng thÃ´ng tin má»›i vÃ  cÃ³ Ä‘á»™ tin cáº­y cao. Náº¿u memory quÃ¡ cÅ©, mÃ´ hÃ¬nh cÃ³ thá»ƒ cáº£nh bÃ¡o. Má»™t hÆ°á»›ng khÃ¡c lÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh **phÃ¡t hiá»‡n mÃ¢u thuáº«n** giá»¯a memory vÃ  message hiá»‡n táº¡i: náº¿u phÃ¡t hiá»‡n user nÃ³i Ä‘iá»u trÃ¡i ngÆ°á»£c háº³n vá»›i memory cÅ©, cÃ³ thá»ƒ kÃ­ch hoáº¡t má»™t _quy trÃ¬nh xÃ¡c minh_, há»i láº¡i ngÆ°á»i dÃ¹ng Ä‘á»ƒ cháº¯c cháº¯n trÆ°á»›c khi cáº­p nháº­t.
    

TÃ³m láº¡i, **há»‡ thá»‘ng Ä‘á»‘i thoáº¡i tÃ­ch há»£p trÃ­ nhá»› dÃ i háº¡n** Ä‘ang dáº§n trá»Ÿ nÃªn kháº£ thi nhá» cÃ¡c tiáº¿n bá»™ trong cáº£ mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n láº«n ká»¹ thuáº­t quáº£n lÃ½ tri thá»©c. Tá»« nhá»¯ng mÃ´ hÃ¬nh QA Ä‘Æ¡n lÆ°á»£t Ä‘Æ¡n giáº£n, chÃºng ta Ä‘Ã£ chá»©ng kiáº¿n sá»± ra Ä‘á»i cá»§a cÃ¡c chatbot cÃ³ kháº£ nÄƒng ghi nhá»› hÃ ng trÄƒm lÆ°á»£t thoáº¡i, cÃ¡ nhÃ¢n hÃ³a theo ngÆ°á»i dÃ¹ng, vÃ  cáº­p nháº­t hiá»ƒu biáº¿t theo thá»i gian. DÃ¹ váº«n cÃ²n nhá»¯ng thÃ¡ch thá»©c vá» tá»‘i Æ°u vÃ  Ä‘á»™ tin cáº­y, hÆ°á»›ng nghiÃªn cá»©u nÃ y há»©a háº¹n Ä‘em láº¡i cÃ¡c trá»£ lÃ½ áº£o **nhá»› lÃ¢u, hiá»ƒu sÃ¢u vÃ  pháº£n há»“i tá»± nhiÃªn** hÆ¡n â€“ má»™t bÆ°á»›c tiáº¿n lá»›n tá»›i **AI Ä‘á»‘i thoáº¡i mang tÃ­nh cÃ¡ nhÃ¢n vÃ  Ä‘Ã¡ng tin cáº­y** trong tÆ°Æ¡ng lai gáº§n. CÃ¡c nghiÃªn cá»©u má»›i nhÆ° LongMemEval Ä‘ang táº¡o ná»n táº£ng Ä‘á»ƒ **Ä‘Ã¡nh giÃ¡ cÃ³ há»‡ thá»‘ng** cÃ¡c tiáº¿n bá»™, cÃ²n cÃ¡c Ã½ tÆ°á»Ÿng káº¿t há»£p memory vÃ  LLM (MemoryBank, THEANINE, LD-Agent) Ä‘ang má»Ÿ Ä‘Æ°á»ng cho tháº¿ há»‡ mÃ´ hÃ¬nh há»™i thoáº¡i thÃ´ng minh káº¿ tiáº¿p. ChÃºng ta cÃ³ thá»ƒ ká»³ vá»ng trong tÆ°Æ¡ng lai, sá»± káº¿t há»£p giá»¯a **cá»­a sá»• ngá»¯ cáº£nh lá»›n** vÃ  **bá»™ nhá»› ngoÃ i linh hoáº¡t** sáº½ giÃºp xÃ³a nhÃ²a ranh giá»›i vá» trÃ­ nhá»› trong Ä‘á»‘i thoáº¡i, cho phÃ©p cÃ¡c há»‡ thá»‘ng AI trÃ² chuyá»‡n má»™t cÃ¡ch máº¡ch láº¡c vÃ  hiá»ƒu biáº¿t qua _nhiá»u thÃ¡ng, nhiá»u nÄƒm_ tÆ°Æ¡ng tÃ¡c vá»›i con ngÆ°á»i.

**TÃ i liá»‡u tham kháº£o:**

1. Wu, D. _et al._ (2024). _LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory_. **ICLR 2025 (preprint)** ([[2410.10813] LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory](https://arxiv.org/abs/2410.10813#:~:text=capabilities%20in%20sustained%20interactions%20remain,term)) ([[2410.10813] LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory](https://arxiv.org/abs/2410.10813#:~:text=meticulously%20curated%20questions%20embedded%20within,augmented%20key)).
    
2. Qu, C. _et al._ (2020). _Open-Retrieval Conversational Question Answering_. **SIGIR 2020** ([[2005.11364] Open-Retrieval Conversational Question Answering](https://arxiv.org/abs/2005.11364#:~:text=retrieval%20conversational%20question%20answering%20,the%20reranker%20component%20contributes%20to)).
    
3. Bae, S. _et al._ (2022). _Keep Me Updated! Memory Management in Long-term Conversations_. **Findings of EMNLP 2022** ([](https://aclanthology.org/2022.findings-emnlp.276.pdf#:~:text=Specifically%2C%20the%20memory%20management%20mechanism,%E2%80%9CJust%20got%20positive%20results%20from)) ([](https://aclanthology.org/2022.findings-emnlp.276.pdf#:~:text=find%20and%20eliminate%20the%20information,in%20sub%02sequent%20sessions%2C%20a%20relevant)).
    
4. Li, H. _et al._ (2025). _Hello Again! LLM-powered Personalized Agent for Long-term Dialogue (LD-Agent)_. **NAACL 2025 (to appear)** ([[2406.05925] Hello Again! LLM-powered Personalized Agent for Long-term Dialogue](https://arxiv.org/abs/2406.05925#:~:text=the%20Long,Agent%20are)).
    
5. Zhong, W. _et al._ (2023). _MemoryBank: Enhancing Large Language Models with Long-Term Memory_. **arXiv:2305.10250** ([[2305.10250] MemoryBank: Enhancing Large Language Models with Long-Term Memory](https://ar5iv.labs.arxiv.org/html/2305.10250#:~:text=personality%20over%20time%20by%20synthesizing,based%20chatbot%20named)) ([Augmenting LLMs with Retrieval, Tools, and Long-term Memory | by Alaa Dania Adimi | InfinitGraph | Mar, 2025 | Medium](https://medium.com/@ja_adimi/augmenting-llms-with-retrieval-tools-and-long-term-memory-b9e1e6b2fc28#:~:text=Memory%20Updating)).
    
6. Ong, K.T. _et al._ (2025). _THEANINE: Timeline-based Memory Management for Lifelong Dialogue Agents_. **NAACL 2025 (to appear)** ([[2406.10996] Towards Lifelong Dialogue Agents via Timeline-based Memory Management](https://arxiv.org/abs/2406.10996#:~:text=to%20improve%20retrieval%20quality%2C%20we,human%20efforts%20when%20assessing%20agent)).
    
7. Weston, J. _et al._ (2015). _Memory Networks_. **ICLR 2015** ([[1410.3916] Memory Networks](https://arxiv.org/abs/1410.3916#:~:text=,chaining%20multiple%20supporting%20sentences%20to)).
    
8. Graves, A. _et al._ (2016). _Hybrid computing using a neural network with dynamic external memory (DNC)_. **Nature 538, 471â€“476 (2016)** ([Differentiable neural computer - Wikipedia](https://en.wikipedia.org/wiki/Differentiable_neural_computer#:~:text=DNC%20indirectly%20takes%20inspiration%20from,by%20finding%20a%20%2052)).
    
9. Seo, M. _et al._ (2017). _Bidirectional Attention Flow for Machine Comprehension (BiDAF)_. **ICLR 2017** ([BERT with History Answer Embedding for Conversational Question Answering](https://arxiv.org/pdf/1905.05412#:~:text=4,representation%20generated%20when%20answering%20previous)).
    
10. Chen, D. _et al._ (2017). _Reading Wikipedia to Answer Open-Domain Questions (DrQA)_. **ACL 2017** ([BERT with History Answer Embedding for Conversational Question Answering](https://arxiv.org/pdf/1905.05412#:~:text=,JASIS%2C%2038%3A389%E2%80%93404%2C%201987)).




```
TrÃ­ch dáº«n

[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

BERT with History Answer Embedding for Conversational Question Answering

4.2.1 Competing Methods. We consider all the methods on the QuAC leaderboard as baselines. The competing methods are: â€¢ BiDAF++ [3]: BiDAF++ augments BiDAF [14] with self-attention and contextualized embeddings. â€¢ BiDAF++ w/ 2-Context [3]: It incorporates 2 history turns in BiDAF++ by encoding the dialog turn # in question embeddings and concatenating marker embeddings to passage embeddings. â€¢ FlowQA [7]: It considers conversation history by integrating intermediate representation generated when answering previous

](https://arxiv.org/pdf/1905.05412#:~:text=4,representation%20generated%20when%20answering%20previous)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

BERT with History Answer Embedding for Conversational Question Answering

[2] D. Chen, A. Fisch, J. Weston, and A. Bordes. Reading Wikipedia to Answer Open-Domain Questions. In ACL, 2017. [3] E. Choi, H. He, M. Iyyer, M. Yatskar, W. Yih, Y. Choi, P. Liang, and L. S. Zettlemoyer. QuAC: Question Answering in Context. In EMNLP, 2018. [4] W. B. Croft and R. H. Thompson. I3R: A new approach to the design of document retrieval systems. JASIS, 38:389â€“404, 1987.

](https://arxiv.org/pdf/1905.05412#:~:text=,JASIS%2C%2038%3A389%E2%80%93404%2C%201987)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

[2410.10813] LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory

integrated memory components to track user-assistant chat histories, enabling more accurate and personalized responses. However, their long-term memory capabilities in sustained interactions remain underexplored. We introduce LongMemEval, a comprehensive benchmark designed to evaluate five core long-term memory abilities of chat assistants: information extraction, multi-session reasoning, temporal reasoning, knowledge updates, and abstention. With 500 meticulously curated questions embedded within freely scalable user-assistant chat histories, LongMemEval presents a significant challenge to existing long- term memory systems, with commercial chat assistants and long-context LLMs

](https://arxiv.org/abs/2410.10813#:~:text=integrated%20memory%20components%20to%20track,context%20LLMs)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

[2410.10813] LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory

meticulously curated questions embedded within freely scalable user-assistant chat histories, LongMemEval presents a significant challenge to existing long- term memory systems, with commercial chat assistants and long-context LLMs showing a 30% accuracy drop on memorizing information across sustained interactions. We then present a unified framework that breaks down the long-term memory design into three stages: indexing, retrieval, and reading. Built upon key experimental insights, we propose several memory design optimizations including session decomposition for value granularity, fact-augmented key

](https://arxiv.org/abs/2410.10813#:~:text=meticulously%20curated%20questions%20embedded%20within,augmented%20key)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

[1410.3916] Memory Networks

> Abstract:We describe a new class of learning models called memory networks. Memory networks reason with inference components combined with a long-term memory component; they learn how to use these jointly. The long-term memory can be read and written to, with the goal of using it for prediction. We investigate these models in the context of question answering (QA) where the long-term memory effectively acts as a (dynamic) knowledge base, and the output is a textual response. We evaluate them on a large-scale QA task, and a smaller, but more complex, toy task generated from a simulated world. In the latter, we show the reasoning power of such models by chaining multiple supporting sentences to

](https://arxiv.org/abs/1410.3916#:~:text=,chaining%20multiple%20supporting%20sentences%20to)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

[1410.3916] Memory Networks

these models in the context of question answering (QA) where the long-term memory effectively acts as a (dynamic) knowledge base, and the output is a textual response. We evaluate them on a large-scale QA task, and a smaller, but more complex, toy task generated from a simulated world. In the latter, we show the reasoning power of such models by chaining multiple supporting sentences to answer questions that require understanding the intension of verbs.

](https://arxiv.org/abs/1410.3916#:~:text=these%20models%20in%20the%20context,understanding%20the%20intension%20of%20verbs)[

![Favicon](https://www.google.com/s2/favicons?domain=https://en.wikipedia.org&sz=32)en.wikipedia.org

Differentiable neural computer - Wikipedia

In artificial intelligence , a differentiable neural computer (DNC) is a memory augmented 47 architecture (MANN), which is typically (but not by definition) recurrent in its implementation. The model was published in 2016 by Alex Graves et al. of 49.[ 1 ]

](https://en.wikipedia.org/wiki/Differentiable_neural_computer#:~:text=In%20artificial%20intelligence%20%2C%20a,1)[

![Favicon](https://www.google.com/s2/favicons?domain=https://en.wikipedia.org&sz=32)en.wikipedia.org

Differentiable neural computer - Wikipedia

DNC indirectly takes inspiration from Von-Neumann architecture , making it likely to outperform conventional architectures in tasks that are fundamentally algorithmic that cannot be learned by finding a 52.

](https://en.wikipedia.org/wiki/Differentiable_neural_computer#:~:text=DNC%20indirectly%20takes%20inspiration%20from,by%20finding%20a%20%2052)[

![Favicon](https://www.google.com/s2/favicons?domain=https://en.wikipedia.org&sz=32)en.wikipedia.org

Differentiable neural computer - Wikipedia

So far, DNCs have been demonstrated to handle only relatively simple tasks, which can be solved using conventional programming. But DNCs don't need to be programmed for each problem, but can instead be trained. This attention span allows the user to feed complex data structures such as 54 sequentially, and recall them for later use. Furthermore, they can learn aspects of symbolic reasoning and apply it to working memory. The researchers who published the method see promise that DNCs can be trained to perform complex, structured tasks[ 1 ][ 2 ] and address big-data applications that require some sort of reasoning, such as generating video commentaries or semantic text

](https://en.wikipedia.org/wiki/Differentiable_neural_computer#:~:text=So%20far%2C%20DNCs%20have%20been,video%20commentaries%20or%20semantic%20text)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

[1410.3916] Memory Networks

memory component; they learn how to use these jointly. The long-term memory can be read and written to, with the goal of using it for prediction. We investigate these models in the context of question answering (QA) where the long-term memory effectively acts as a (dynamic) knowledge base, and the output is a textual response. We evaluate them on a large-scale QA task, and a smaller, but more complex, toy task generated from a simulated world. In the latter, we show the reasoning power of such models by chaining multiple supporting sentences to

](https://arxiv.org/abs/1410.3916#:~:text=memory%20component%3B%20they%20learn%20how,chaining%20multiple%20supporting%20sentences%20to)[

openreview.net

Language model with Plug-in Knowldge Memory | OpenReview

of knowledge PLM needs to solve certain task. In this paper, we introduce PlugLM, a pre-training model with differentiable plug-in memory(DPM). The key intuition behind is to decouple the knowledge storage from model parameters with an editable and scalable key-value memory and leverage knowledge in an explainable manner by knowledge retrieval in the DPM. We conduct extensive experiments under various settings to justify this design choice. In domain adaptation setting, PlugLM could be easily adapted to different domains with plugable in-domain memory---obtaining 3.95 F1 improvements across four domains, without any in-domain training. PlugLM could also keep absorbing new knowledge

](https://openreview.net/forum?id=Plr5l7r0jY6#:~:text=of%20knowledge%20PLM%20needs%20to,also%20keep%20absorbing%20new%20knowledge)[

openreview.net

Language model with Plug-in Knowldge Memory | OpenReview

adaptation setting, PlugLM could be easily adapted to different domains with plugable in-domain memory---obtaining 3.95 F1 improvements across four domains, without any in-domain training. PlugLM could also keep absorbing new knowledge after pre-training is done by knowledge updating operation in the DPM without re-training. Finally, we show that by incorporating training samples into DPM with knowledge prompting, PlugLM could further be improved by the instruction of in-task knowledge.

](https://openreview.net/forum?id=Plr5l7r0jY6#:~:text=adaptation%20setting%2C%20PlugLM%20could%20be,task%20knowledge)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

[2005.11364] Open-Retrieval Conversational Question Answering

retrieval conversational question answering (ORConvQA) setting, where we learn to retrieve evidence from a large collection before extracting answers, as a further step towards building functional conversational search systems. We create a dataset, OR-QuAC, to facilitate research on ORConvQA. We build an end- to-end system for ORConvQA, featuring a retriever, a reranker, and a reader that are all based on Transformers. Our extensive experiments on OR-QuAC demonstrate that a learnable retriever is crucial for ORConvQA. We further show that our system can make a substantial improvement when we enable history modeling in all system components. Moreover, we show that the reranker component contributes to

](https://arxiv.org/abs/2005.11364#:~:text=retrieval%20conversational%20question%20answering%20,the%20reranker%20component%20contributes%20to)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

[2005.11364] Open-Retrieval Conversational Question Answering

passage. These simplifications neglect the fundamental role of retrieval in conversational search. To address this limitation, we introduce an open- retrieval conversational question answering (ORConvQA) setting, where we learn to retrieve evidence from a large collection before extracting answers, as a further step towards building functional conversational search systems. We create a dataset, OR-QuAC, to facilitate research on ORConvQA. We build an end- to-end system for ORConvQA, featuring a retriever, a reranker, and a reader that are all based on Transformers. Our extensive experiments on OR-QuAC demonstrate that a learnable retriever is crucial for ORConvQA. We further show that our

](https://arxiv.org/abs/2005.11364#:~:text=passage,We%20further%20show%20that%20our)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

[2005.11364] Open-Retrieval Conversational Question Answering

to-end system for ORConvQA, featuring a retriever, a reranker, and a reader that are all based on Transformers. Our extensive experiments on OR-QuAC demonstrate that a learnable retriever is crucial for ORConvQA. We further show that our system can make a substantial improvement when we enable history modeling in all system components. Moreover, we show that the reranker component contributes to

](https://arxiv.org/abs/2005.11364#:~:text=to,the%20reranker%20component%20contributes%20to)[

![Favicon](https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32)aclanthology.org

interlocutors revealed in the previous conversation is abstractively summarized and stored in memory. Specifically, the memory management mechanism decides which information to keep in memory. For this purpose, we define four pairwise operations (PASS, REPLACE, APPEND, and DELETE) to find and eliminate the information that can cause confusion or redundancy in later conversations. For example, if the previous memory sentence is â€œHavenâ€™t got COVID tested yetâ€ and the new incoming summary is â€œJust got

](https://aclanthology.org/2022.findings-emnlp.276.pdf#:~:text=interlocutors%20revealed%20in%20the%20previous,in%02coming%20summary%20is%20%E2%80%9CJust%20got)[

![Favicon](https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32)aclanthology.org

For example, if the previous memory sentence is â€œHavenâ€™t got COVID tested yetâ€ and the new incoming summary is â€œJust got positive results from COVID testâ€, the two sentences are contradictory, in which the former needs to be replaced in memory by the latter. Through this process, only valid information remains in new memory. Then, in subsequent sessions, a relevant information from this memory is retrieved and given as additional condition for generating chatbot

](https://aclanthology.org/2022.findings-emnlp.276.pdf#:~:text=For%20example%2C%20if%20the%20previous,additional%20condi%02tion%20for%20generating%20chatbot)[

![Favicon](https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32)aclanthology.org

Specifically, the memory management mechanism decides which information to keep in memory. For this purpose, we define four pairwise operations (PASS, REPLACE, APPEND, and DELETE) to find and eliminate the information that can cause confusion or redundancy in later conversations. For example, if the previous memory sentence is â€œHavenâ€™t got COVID tested yetâ€ and the new incoming summary is â€œJust got positive results from

](https://aclanthology.org/2022.findings-emnlp.276.pdf#:~:text=Specifically%2C%20the%20memory%20management%20mechanism,%E2%80%9CJust%20got%20positive%20results%20from)[

![Favicon](https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32)aclanthology.org

find and eliminate the information that can cause confusion or redundancy in later conversations. For example, if the previous memory sentence is â€œHavenâ€™t got COVID tested yetâ€ and the new incoming summary is â€œJust got positive results from COVID testâ€, the two sentences are contradictory, in which the former needs to be replaced in memory by the latter. Through this process, only valid information remains in new memory. Then, in subsequent sessions, a relevant

](https://aclanthology.org/2022.findings-emnlp.276.pdf#:~:text=find%20and%20eliminate%20the%20information,in%20sub%02sequent%20sessions%2C%20a%20relevant)[

![Favicon](https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32)aclanthology.org

With extensive experiments and ablations, we show that the proposed memory management mechanism becomes more advantageous in terms of memorability as the sessions proceed, leading to better engagingness and humanness in multisession dialogues. Our contributions are as follows: 1. We make a step towards long-term conversations with dynamic memory that must be kept up-to-date.

](https://aclanthology.org/2022.findings-emnlp.276.pdf#:~:text=With%20extensive%20experiments%20and%20ablations%2C,date)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

[2308.15022] Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models

long conversation, these chatbots fail to recall past information and tend to generate inconsistent responses. To address this, we propose to recursively generate summaries/ memory using large language models (LLMs) to enhance long- term memory ability. Specifically, our method first stimulates LLMs to memorize small dialogue contexts and then recursively produce new memory using previous memory and following contexts. Finally, the chatbot can easily generate a highly consistent response with the help of the latest memory. We evaluate our method on both open and closed LLMs, and the experiments on the widely-used public dataset show that our method can generate more consistent responses in a long-

](https://arxiv.org/abs/2308.15022#:~:text=long%20conversation%2C%20these%20chatbots%20fail,consistent%20responses%20in%20a%20long)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

[2308.15022] Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models

consistent response with the help of the latest memory. We evaluate our method on both open and closed LLMs, and the experiments on the widely-used public dataset show that our method can generate more consistent responses in a long- context conversation. Also, we show that our strategy could nicely complement both long-context (e.g., 8K and 16K) and retrieval-enhanced LLMs, bringing further long-term dialogue performance. Notably, our method is a potential solution to enable the LLM to model the extremely long context. The code and scripts will be released later.

](https://arxiv.org/abs/2308.15022#:~:text=consistent%20response%20with%20the%20help,scripts%20will%20be%20released%20later)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

On Memory Construction and Retrieval for Personalized Conversational Agents

To deliver coherent and personalized experiences in long-term conversations, existing approaches typically perform retrieval augmented response generation by constructing memory banks from conversation history at either the turn-level, session-level, or through summarization techniques. In this paper, we present two key findings: (1) The granularity of memory unit matters: Turn-level, session-level, and summarization-based methods each exhibit limitations in both memory retrieval accuracy and the semantic quality of the retrieved content. (2) Prompt compression methods, such as LLMLingua-2, can effectively serve as a denoising mechanism, enhancing memory retrieval accuracy across different granularities.

](https://arxiv.org/html/2502.05589v2#:~:text=To%20deliver%20coherent%20and%20personalized,retrieval%20accuracy%20across%20different%20granularities)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

On Memory Construction and Retrieval for Personalized Conversational Agents

Building on these insights, we propose SeCom, a method that constructs the memory bank at segment level by introducing a conversation Se gmentation model that partitions long-term conversations into topically coherent segments, while applying Com pression based denoising on memory units to enhance memory retrieval. Experimental results show that SeCom exhibits a significant performance advantage over baselines on long-term conversation benchmarks LOCOMO and Long-MT-Bench+. Additionally, the proposed conversation segmentation method demonstrates superior performance on dialogue segmentation datasets such as DialSeg711, TIAGE, and SuperDialSeg.

](https://arxiv.org/html/2502.05589v2#:~:text=Building%20on%20these%20insights%2C%20we,as%20DialSeg711%2C%20TIAGE%2C%20and%20SuperDialSeg)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

[2410.10813] LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory

showing a 30% accuracy drop on memorizing information across sustained interactions. We then present a unified framework that breaks down the long-term memory design into three stages: indexing, retrieval, and reading. Built upon key experimental insights, we propose several memory design optimizations including session decomposition for value granularity, fact-augmented key expansion for indexing, and time-aware query expansion for refining the search scope. Extensive experiments show that these optimizations greatly improve both memory recall and downstream question answering on LongMemEval. Overall, our study provides valuable resources and guidance for advancing the long-term

](https://arxiv.org/abs/2410.10813#:~:text=showing%20a%2030,term)[

![Favicon](https://www.google.com/s2/favicons?domain=https://ar5iv.labs.arxiv.org&sz=32)ar5iv.labs.arxiv.org

[2305.10250] MemoryBank: Enhancing Large Language Models with Long-Term Memory

personality over time by synthesizing information from previous interactions. To mimic anthropomorphic behaviors and selectively preserve memory, MemoryBank incorporates a memory updating mechanism, inspired by the Ebbinghaus Forgetting Curve theory. This mechanism permits the AI to forget and reinforce memory based on time elapsed and the relative significance of the memory, thereby offering a more human-like memory mechanism and enriched user experience. MemoryBank is versatile in accommodating both closed-source models like ChatGPT and open- source models such as ChatGLM. To validate MemoryBankâ€™s effectiveness, we exemplify its application through the creation of an LLM-based chatbot named

](https://ar5iv.labs.arxiv.org/html/2305.10250#:~:text=personality%20over%20time%20by%20synthesizing,based%20chatbot%20named)[

![Favicon](https://www.google.com/s2/favicons?domain=https://medium.com&sz=32)medium.com

Augmenting LLMs with Retrieval, Tools, and Long-term Memory | by Alaa Dania Adimi | InfinitGraph | Mar, 2025 | Medium

Memory Updating

](https://medium.com/@ja_adimi/augmenting-llms-with-retrieval-tools-and-long-term-memory-b9e1e6b2fc28#:~:text=Memory%20Updating)[

![Favicon](https://www.google.com/s2/favicons?domain=https://ar5iv.labs.arxiv.org&sz=32)ar5iv.labs.arxiv.org

[2305.10250] MemoryBank: Enhancing Large Language Models with Long-Term Memory

psychological counseling, and secretarial assistance. Recognizing the necessity for long-term memory, we propose MemoryBank, a novel memory mechanism tailored for LLMs. MemoryBank enables the models to summon relevant memories, continually evolve through continuous memory updates, comprehend, and adapt to a userâ€™s personality over time by synthesizing information from previous interactions. To mimic anthropomorphic behaviors and selectively preserve memory, MemoryBank incorporates a memory updating mechanism, inspired by the Ebbinghaus Forgetting Curve theory. This mechanism permits the AI to forget and reinforce memory based on time elapsed and the relative significance of the memory, thereby offering a

](https://ar5iv.labs.arxiv.org/html/2305.10250#:~:text=psychological%20counseling%2C%20and%20secretarial%20assistance,the%20memory%2C%20thereby%20offering%20a)[

![Favicon](https://www.google.com/s2/favicons?domain=https://medium.com&sz=32)medium.com

Augmenting LLMs with Retrieval, Tools, and Long-term Memory | by Alaa Dania Adimi | InfinitGraph | Mar, 2025 | Medium

* Selective Forgetting: Drawing inspiration from the Ebbinghaus Forgetting Curve, MemoryBank ensures that not all stored memories remain equally strong. Over time, if a memory isnâ€™t recalled or reinforced, its strength decays and it may eventually be pruned from active storage. This selective forgetting keeps the memory bank relevant and uncluttered. * Reinforcement of Key Memories: Conversely, memories that are frequently accessed are reinforced. Each time a memory is recalled, its â€œstrengthâ€ is boosted, ensuring that important details persist over longer periods â€” mirroring how human memory works through repeated retrieval.

](https://medium.com/@ja_adimi/augmenting-llms-with-retrieval-tools-and-long-term-memory-b9e1e6b2fc28#:~:text=,memory%20works%20through%20repeated%20retrieval)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

[2406.10996] Towards Lifelong Dialogue Agents via Timeline-based Memory Management

to improve retrieval quality, we argue that such memories provide rich, important contextual cues for RG (e.g., changes in user behaviors) in long-term conversations. We present THEANINE, a framework for LLM-based lifelong dialogue agents. THEANINE discards memory removal and manages large-scale memories by linking them based on their temporal and cause-effect relation. Enabled by this linking structure, THEANINE augments RG with memory timelines - series of memories representing the evolution or causality of relevant past events. Along with THEANINE, we introduce TeaFarm, a counterfactual-driven evaluation scheme, addressing the limitation of G-Eval and human efforts when assessing agent

](https://arxiv.org/abs/2406.10996#:~:text=to%20improve%20retrieval%20quality%2C%20we,human%20efforts%20when%20assessing%20agent)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

[2406.10996] Towards Lifelong Dialogue Agents via Timeline-based Memory Management

constantly memorize perceived information and properly retrieve it for response generation (RG). While prior studies focus on getting rid of outdated memories to improve retrieval quality, we argue that such memories provide rich, important contextual cues for RG (e.g., changes in user behaviors) in long-term conversations. We present THEANINE, a framework for LLM-based lifelong dialogue agents. THEANINE discards memory removal and manages large-scale memories by linking them based on their temporal and cause-effect relation. Enabled by this linking structure, THEANINE augments RG with memory timelines - series of memories representing the evolution or causality of relevant past events. Along

](https://arxiv.org/abs/2406.10996#:~:text=constantly%20memorize%20perceived%20information%20and,Along)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

[2406.10996] Towards Lifelong Dialogue Agents via Timeline-based Memory Management

conversations. We present THEANINE, a framework for LLM-based lifelong dialogue agents. THEANINE discards memory removal and manages large-scale memories by linking them based on their temporal and cause-effect relation. Enabled by this linking structure, THEANINE augments RG with memory timelines - series of memories representing the evolution or causality of relevant past events. Along with THEANINE, we introduce TeaFarm, a counterfactual-driven evaluation scheme, addressing the limitation of G-Eval and human efforts when assessing agent

](https://arxiv.org/abs/2406.10996#:~:text=conversations,human%20efforts%20when%20assessing%20agent)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

[2406.05925] Hello Again! LLM-powered Personalized Agent for Long-term Dialogue

the Long-term Dialogue Agent (LD-Agent), which incorporates three independently tunable modules dedicated to event perception, persona extraction, and response generation. For the event memory module, long and short-term memory banks are employed to separately focus on historical and ongoing sessions, while a topic- based retrieval mechanism is introduced to enhance the accuracy of memory retrieval. Furthermore, the persona module conducts dynamic persona modeling for both users and agents. The integration of retrieved memories and extracted personas is subsequently fed into the generator to induce appropriate responses. The effectiveness, generality, and cross-domain capabilities of LD-Agent are

](https://arxiv.org/abs/2406.05925#:~:text=the%20Long,Agent%20are)[

openreview.net

200 The event memory module is designed to perceive 201 historical events to generate coherent responses 202 across interval time. As shown in Figure 2, this 203 event memory module is segmented into two major 204 sub-modules that focus separately on long-term 205 and short-term memory. 206 2.2.1 Long-term Memory 207 Memory Storage. The long-term memory mod208 ule aims to extract and encode events from past 209 sessions. Specifically, this involves recording

](https://openreview.net/pdf?id=lwCxVgVYoK#:~:text=200%20The%20event%20memory%20module,Specifically%2C%20this%20involves%20recording)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

[2406.05925] Hello Again! LLM-powered Personalized Agent for Long-term Dialogue

generation. For the event memory module, long and short-term memory banks are employed to separately focus on historical and ongoing sessions, while a topic- based retrieval mechanism is introduced to enhance the accuracy of memory retrieval. Furthermore, the persona module conducts dynamic persona modeling for both users and agents. The integration of retrieved memories and extracted personas is subsequently fed into the generator to induce appropriate responses. The effectiveness, generality, and cross-domain capabilities of LD-Agent are empirically demonstrated across various illustrative benchmarks, models, and

](https://arxiv.org/abs/2406.05925#:~:text=generation,various%20illustrative%20benchmarks%2C%20models%2C%20and)[

![Favicon](https://www.google.com/s2/favicons?domain=https://medium.com&sz=32)medium.com

Augmenting LLMs with Retrieval, Tools, and Long-term Memory | by Alaa Dania Adimi | InfinitGraph | Mar, 2025 | Medium

Memory Storage: The Warehouse of Memories

](https://medium.com/@ja_adimi/augmenting-llms-with-retrieval-tools-and-long-term-memory-b9e1e6b2fc28#:~:text=Memory%20Storage%3A%20The%20Warehouse%20of,Memories)[

![Favicon](https://www.google.com/s2/favicons?domain=https://medium.com&sz=32)medium.com

Augmenting LLMs with Retrieval, Tools, and Long-term Memory | by Alaa Dania Adimi | InfinitGraph | Mar, 2025 | Medium

level overviews of daily events and key interactions, much like how humans remember â€œthe gistâ€ of an experience rather than every minute detail. * User Portraits: Beyond mere conversation logs, MemoryBank constructs dynamic user portraits. These profiles encapsulate a userâ€™s personality traits, recurring preferences, and evolving interests, enabling the LLM to tailor its responses over time.

](https://medium.com/@ja_adimi/augmenting-llms-with-retrieval-tools-and-long-term-memory-b9e1e6b2fc28#:~:text=level%20overviews%20of%20daily%20events,tailor%20its%20responses%20over%20time)[

![Favicon](https://www.google.com/s2/favicons?domain=https://medium.com&sz=32)medium.com

Augmenting LLMs with Retrieval, Tools, and Long-term Memory | by Alaa Dania Adimi | InfinitGraph | Mar, 2025 | Medium

* User Portraits: Beyond mere conversation logs, MemoryBank constructs dynamic user portraits. These profiles encapsulate a userâ€™s personality traits, recurring preferences, and evolving interests, enabling the LLM to tailor its responses over time.

](https://medium.com/@ja_adimi/augmenting-llms-with-retrieval-tools-and-long-term-memory-b9e1e6b2fc28#:~:text=,tailor%20its%20responses%20over%20time)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

[2410.10813] LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory

capabilities in sustained interactions remain underexplored. We introduce LongMemEval, a comprehensive benchmark designed to evaluate five core long-term memory abilities of chat assistants: information extraction, multi-session reasoning, temporal reasoning, knowledge updates, and abstention. With 500 meticulously curated questions embedded within freely scalable user-assistant chat histories, LongMemEval presents a significant challenge to existing long- term memory systems, with commercial chat assistants and long-context LLMs showing a 30% accuracy drop on memorizing information across sustained

](https://arxiv.org/abs/2410.10813#:~:text=capabilities%20in%20sustained%20interactions%20remain,on%20memorizing%20information%20across%20sustained)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

[2410.10813] LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory

capabilities in sustained interactions remain underexplored. We introduce LongMemEval, a comprehensive benchmark designed to evaluate five core long-term memory abilities of chat assistants: information extraction, multi-session reasoning, temporal reasoning, knowledge updates, and abstention. With 500 meticulously curated questions embedded within freely scalable user-assistant chat histories, LongMemEval presents a significant challenge to existing long- term memory systems, with commercial chat assistants and long-context LLMs showing a 30% accuracy drop on memorizing information across sustained interactions. We then present a unified framework that breaks down the long-term

](https://arxiv.org/abs/2410.10813#:~:text=capabilities%20in%20sustained%20interactions%20remain,term)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

[2410.10813] LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory

interactions. We then present a unified framework that breaks down the long-term memory design into three stages: indexing, retrieval, and reading. Built upon key experimental insights, we propose several memory design optimizations including session decomposition for value granularity, fact-augmented key expansion for indexing, and time-aware query expansion for refining the search scope. Extensive experiments show that these optimizations greatly improve both memory recall and downstream question answering on LongMemEval. Overall, our study provides valuable resources and guidance for advancing the long-term

](https://arxiv.org/abs/2410.10813#:~:text=interactions,term)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

On Memory Construction and Retrieval for Personalized Conversational Agents

(i) LOCOMOÂ (Maharana etÂ al., 2024), which is the longest conversation dataset to date, with an average of 300 turns with 9K tokens per sample. For the test set, we prompt GPT-4 to generate QA pairs for each session as in Alonso etÂ al. (2024). We also conduct evaluation on the recently released official

](https://arxiv.org/html/2502.05589v2#:~:text=%28i%29%20LOCOMO%C2%A0%28Maharana%20et%C2%A0al,on%20the%20recently%20released%20official)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

On Memory Construction and Retrieval for Personalized Conversational Agents

long-conversation benchmark LOCOMO. Interestingly, there is a significant performance disparity in Turn-Level and Session-Level methods when using different retrieval models. For instance, switching from the MPNet-based retriever to the BM25-based retriever results in performance improvements up to

](https://arxiv.org/html/2502.05589v2#:~:text=long,in%20performance%20improvements%20up%20to)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

On Memory Construction and Retrieval for Personalized Conversational Agents

Methods LOCOMO Long-MT-Bench+ GPT4Score BLEU Rouge2 BERTScore GPT4Score BLEU Rouge2 BERTScore SeCom 69.33 7.19 13.74 88.60 88.81 13.80 19.21 87.72 Denoise 59.87 6.49 12.11 88.16 87.51 12.94 18.73 87.44

](https://arxiv.org/html/2502.05589v2#:~:text=Methods%20LOCOMO%20Long,44)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

On Memory Construction and Retrieval for Personalized Conversational Agents

match at L389 LOCOMO Zero History 24.86 1.94 17.36 3.72 13.24 85.83 0.00 0 Full History 54.15 6.26 27.20 12.07 22.39 88.06 210.34 13,330 Turn-Level (MPNet) 57.99 6.07 26.61 11.38 21.60 88.01 54.77 3,288

](https://arxiv.org/html/2502.05589v2#:~:text=match%20at%20L389%20LOCOMO%20Zero,77%203%2C288)[

![Favicon](https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32)arxiv.org

On Memory Construction and Retrieval for Personalized Conversational Agents

LOCOMO Zero History 24.86 1.94 17.36 3.72 13.24 85.83 0.00 0 Full History 54.15 6.26 27.20 12.07 22.39 88.06 210.34 13,330 Turn-Level (MPNet) 57.99 6.07 26.61 11.38 21.60 88.01 54.77 3,288

](https://arxiv.org/html/2502.05589v2#:~:text=LOCOMO%20Zero%20History%2024,77%203%2C288)[

![Favicon](https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32)aclanthology.org

3.2 Dataset Construction To study this task, we build a new dataset based on CareCall dataset2(Bae et al., 2022), which consists of single sessions of open-domain dialogues between bots and users. We choose this dataset because the sessions contain various topics that are likely to change in a short period of time, such as userâ€™s health, sleep, and diet, as well as those in a relatively longer period of time, such as family, pets, and frequently visited places. We extend this

](https://aclanthology.org/2022.findings-emnlp.276.pdf#:~:text=3,We%20extend%20this)[

![Favicon](https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32)aclanthology.org

single-session dataset to a multi-session setting, which is a similar procedure presented in MSC (Xu et al., 2022a). Our resulting dataset contains more persona updates than other datasets (Xu et al., 2 https://github.com/naver-ai/carecall-corpus Statistics Sessions 7,665 Session 1 2,812

](https://aclanthology.org/2022.findings-emnlp.276.pdf#:~:text=single,Sessions%207%2C665%20Session%201%202%2C812)[

![Favicon](https://www.google.com/s2/favicons?domain=https://medium.com&sz=32)medium.com

Augmenting LLMs with Retrieval, Tools, and Long-term Memory | by Alaa Dania Adimi | InfinitGraph | Mar, 2025 | Medium

Query Rewriting

](https://medium.com/@ja_adimi/augmenting-llms-with-retrieval-tools-and-long-term-memory-b9e1e6b2fc28#:~:text=Query%20Rewriting)
```