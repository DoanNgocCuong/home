




Trong cÃ¡c tÃ i liá»‡u báº¡n Ä‘Ã£ Ä‘á»c, â€œthá»§y tá»•â€ (ngÆ°á»i Ä‘áº§u tiÃªn Ä‘áº·t ná»n mÃ³ng) cho **Long-Term Memory AI** trong bá»‘i cáº£nh há»‡ thá»‘ng há»™i thoáº¡i cÃ³ thá»ƒ truy há»“i vÃ  ghi nhá»› thÃ´ng tin qua nhiá»u lÆ°á»£t tÆ°Æ¡ng tÃ¡c â€“ thÆ°á»ng Ä‘Æ°á»£c gá»i lÃ  **Memory-Augmented Conversational Systems** â€“ khÃ´ng Ä‘Æ°á»£c nÃªu rÃµ má»™t cÃ¡ nhÃ¢n cá»¥ thá»ƒ, nhÆ°ng cÃ³ thá»ƒ táº¡m chia lá»‹ch sá»­ hÃ¬nh thÃ nh thÃ nh 3 cá»™t má»‘c lá»›n:

---

### ğŸ§  **1. Giai Ä‘oáº¡n Ä‘áº·t ná»n mÃ³ng: QA cÃ³ trÃ­ nhá»› ngáº¯n háº¡n (trÆ°á»›c 2019)**

- CÃ¡c há»‡ thá»‘ng há»“i Ä‘Ã¡p dá»±a trÃªn **single-turn QA**, tá»©c chá»‰ tráº£ lá»i tá»«ng cÃ¢u há»i Ä‘á»™c láº­p, khÃ´ng â€œnhá»›â€ lá»‹ch sá»­ há»™i thoáº¡i.
    
- VÃ­ dá»¥ nhÆ° cÃ¡c mÃ´ hÃ¬nh nhÆ° BiDAF++, BERT-QA hay DrQA.
    
- Há»‡ thá»‘ng báº¯t Ä‘áº§u sá»­ dá»¥ng embedding Ä‘á»ƒ mÃ£ hÃ³a ngá»¯ cáº£nh, nhÆ°ng chÆ°a cÃ³ kháº£ nÄƒng lÆ°u vÃ  truy há»“i thÃ´ng tin tá»« cÃ¡c phiÃªn há»™i thoáº¡i cÅ©.
    

---

### ğŸ§  **2. Giai Ä‘oáº¡n tÃ­ch há»£p trÃ­ nhá»›: Conversational Memory (2019â€“2022)**

- Báº¯t Ä‘áº§u xuáº¥t hiá»‡n cÃ¡c mÃ´ hÃ¬nh nhÆ°:
    
    - **ORConvQA** (Open-Retrieval Conversational QA) â€“ káº¿t há»£p cÆ¡ cháº¿ há»“i tÆ°á»Ÿng dá»¯ liá»‡u tá»« cÃ¡c phiÃªn trÆ°á»›c.
        
    - **History Selection Module** trong cÃ¡c há»‡ CMRC (Conversational Machine Reading Comprehension) â€“ lá»±a chá»n cÃ¡c Ä‘oáº¡n lá»‹ch sá»­ há»™i thoáº¡i liÃªn quan Ä‘á»ƒ giÃºp mÃ´ hÃ¬nh hiá»ƒu ngá»¯ cáº£nh cá»§a cÃ¢u há»i hiá»‡n táº¡i.
        
- ÄÃ¢y lÃ  giai Ä‘oáº¡n cÃ¡c nhÃ  nghiÃªn cá»©u tháº¥y rÃµ **váº¥n Ä‘á» co-reference**, cáº­p nháº­t thÃ´ng tin theo thá»i gian, vÃ  sá»± phá»©c táº¡p cá»§a há»™i thoáº¡i Ä‘a lÆ°á»£t.
    

---

### ğŸ§  **3. Giai Ä‘oáº¡n hiá»‡n Ä‘áº¡i: Memory-Augmented Chat Assistants (2023â€“nay)**

- CÃ¡c há»‡ thá»‘ng nhÆ°:
    
    - **MemoryBank** (Zhong et al., 2024)
        
    - **PerLTQA** (Du et al., 2024)
        
    - **LoCoMo** (Maharana, 2024)
        
    - VÃ  **LongMemEval** â€“ Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi Di Wu et al., lÃ  benchmark máº¡nh nháº¥t hiá»‡n nay cho kháº£ nÄƒng ghi nhá»› dÃ i háº¡n.
        
- CÃ¡c há»‡ thá»‘ng báº¯t Ä‘áº§u Ã¡p dá»¥ng:
    
    - Chia nhá» phiÃªn há»™i thoáº¡i (session decomposition)
        
    - TÄƒng cÆ°á»ng key-value store
        
    - Nháº­n diá»‡n sá»± kiá»‡n cÃ³ thá»i gian Ä‘á»ƒ reasoning chÃ­nh xÃ¡c
        

---

### ğŸ“Œ Gá»£i Ã½: Ai lÃ  "thá»§y tá»•"?

Náº¿u pháº£i chá»n má»™t â€œthá»§y tá»•â€ tiÃªu biá»ƒu cho giai Ä‘oáº¡n hiá»‡n Ä‘áº¡i, cÃ³ thá»ƒ nháº¯c Ä‘áº¿n:

- **Zhong et al. (2024)** vá»›i **MemoryBank** â€“ há»‡ thá»‘ng Ä‘áº§u tiÃªn thiáº¿t káº¿ cá»¥ thá»ƒ cho trÃ­ nhá»› dÃ i háº¡n cÃ¡ nhÃ¢n hÃ³a trong há»™i thoáº¡i.
    
- Hoáº·c **Di Wu et al. (2024)** â€“ vá»›i **LongMemEval**, benchmark Ä‘áº§u tiÃªn Ä‘Æ°a ra tiÃªu chuáº©n rÃµ rÃ ng vÃ  toÃ n diá»‡n cho viá»‡c Ä‘Ã¡nh giÃ¡ trÃ­ nhá»› há»™i thoáº¡i dÃ i háº¡n.
    

---

Quá»‘c cÃ³ muá»‘n mÃ¬nh tÃ³m táº¯t cÃ¡c má»‘c nÃ y dÆ°á»›i dáº¡ng infographic Ä‘Æ¡n giáº£n khÃ´ng? Hoáº·c viáº¿t láº¡i thÃ nh ngÃ´n ngá»¯ lá»›p 8 dá»… hiá»ƒu hÆ¡n?


---
DÆ°á»›i Ä‘Ã¢y lÃ  pháº§n **tá»•ng há»£p hai Ä‘oáº¡n** báº¡n cung cáº¥p, Ä‘Æ°á»£c dá»‹ch tiáº¿ng Viá»‡t Ä‘áº§y Ä‘á»§, logic, vÃ  dá»… hiá»ƒu â€” dÃ¹ng Ä‘Æ°á»£c luÃ´n cho má»¥c **Related Work** hoáº·c má»Ÿ Ä‘áº§u pháº§n tá»•ng quan:

---

## ğŸ§  CÃ¡c hÆ°á»›ng tiáº¿p cáº­n há»‡ thá»‘ng há»™i thoáº¡i cÃ³ trÃ­ nhá»› dÃ i háº¡n

### 1. **Ba hÆ°á»›ng chÃ­nh Ä‘á»ƒ trang bá»‹ trÃ­ nhá»› dÃ i háº¡n cho trá»£ lÃ½ há»™i thoáº¡i**

Äá»ƒ giÃºp cÃ¡c trá»£ lÃ½ há»™i thoáº¡i ghi nhá»› vÃ  xá»­ lÃ½ cÃ¡c tÆ°Æ¡ng tÃ¡c dÃ i háº¡n vá»›i ngÆ°á»i dÃ¹ng, hiá»‡n nay cÃ³ ba hÆ°á»›ng nghiÃªn cá»©u chÃ­nh:

#### ğŸ“Œ **(1) Long-context input trá»±c tiáº¿p**

CÃ¡ch tiáº¿p cáº­n Ä‘áº§u tiÃªn lÃ  **Ä‘Æ°a toÃ n bá»™ lá»‹ch sá»­ há»™i thoáº¡i dÃ i vÃ o LLM** nhÆ° má»™t Ä‘áº§u vÃ o duy nháº¥t (long-context input), cho phÃ©p mÃ´ hÃ¬nh xá»­ lÃ½ táº¥t cáº£ thÃ´ng tin má»™t lÆ°á»£t  
â†’ Æ¯u Ä‘iá»ƒm: Ä‘Æ¡n giáº£n, khÃ´ng cáº§n thiáº¿t káº¿ láº¡i kiáº¿n trÃºc.  
â†’ NhÆ°á»£c Ä‘iá»ƒm: **tá»‘n tÃ i nguyÃªn**, vÃ  dá»… gáº·p hiá»‡n tÆ°á»£ng **â€œlost-in-the-middleâ€** â€“ mÃ´ hÃ¬nh **quÃªn máº¥t pháº§n giá»¯a** khi Ä‘á»™ dÃ i Ä‘áº§u vÃ o vÆ°á»£t quÃ¡ giá»›i háº¡n xá»­ lÃ½ hiá»‡u quáº£ _(Beltagy et al., 2020; Shi et al., 2023)_.

#### ğŸ“Œ **(2) TÃ­ch há»£p mÃ´-Ä‘un trÃ­ nhá»› (differentiable memory modules)**

CÃ¡ch tiáº¿p cáº­n thá»© hai lÃ  **thay Ä‘á»•i kiáº¿n trÃºc mÃ´ hÃ¬nh**, tÃ­ch há»£p thÃªm cÃ¡c **bá»™ nhá»› há»c Ä‘Æ°á»£c (learnable memory modules)** nhÆ° trong Memory Networks, MemGPTâ€¦  
â†’ MÃ´ hÃ¬nh cÃ³ kháº£ nÄƒng lÆ°u trá»¯, cáº­p nháº­t vÃ  sá»­ dá»¥ng láº¡i cÃ¡c thÃ´ng tin Ä‘Ã£ ghi nhá»›.  
â†’ Tuy nhiÃªn, cÃ¡ch nÃ y **cáº§n huáº¥n luyá»‡n láº¡i tá»« Ä‘áº§u** vÃ  **khÃ³ triá»ƒn khai vá»›i cÃ¡c API LLM thÆ°Æ¡ng máº¡i** _(Weston et al., 2014; Wu et al., 2022)_.

#### ğŸ“Œ **(3) NÃ©n ngá»¯ cáº£nh & truy xuáº¥t theo nhu cáº§u (Context Compression & Retrieval)**

CÃ¡ch thá»© ba lÃ  **nÃ©n há»™i thoáº¡i dÃ i thÃ nh cÃ¡c Ä‘oáº¡n ngáº¯n dá»… truy xuáº¥t**, thÃ´ng qua:

- TÃ³m táº¯t (summary)
    
- TrÃ­ch xuáº¥t facts hoáº·c keyphrase
    
- Chia Ä‘oáº¡n logic theo topic  
    Sau Ä‘Ã³ sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t **Retrieval-Augmented Generation (RAG)** Ä‘á»ƒ tÃ¬m vÃ  Ä‘Æ°a láº¡i cÃ¡c Ä‘oáº¡n cáº§n thiáº¿t khi cÃ³ cÃ¢u há»i.  
    â†’ ÄÃ¢y lÃ  cÃ¡ch tiáº¿p cáº­n **phÃ¹ há»£p vá»›i LLM hiá»‡n Ä‘áº¡i (GPT-4, Claude, v.v.) vÃ¬ cÃ³ thá»ƒ Ã¡p dá»¥ng dÆ°á»›i dáº¡ng plug-and-play**  
    â†’ CÅ©ng lÃ  cÃ¡ch tiáº¿p cáº­n chÃ­nh Ä‘Æ°á»£c sá»­ dá»¥ng trong **LONGMEMEVAL** vÃ  nhiá»u há»‡ thá»‘ng thÆ°Æ¡ng máº¡i hiá»‡n nay _(OpenAI, Coze, GutiÃ©rrez et al., 2024)_.
    

---

### 2. **Trá»£ lÃ½ há»™i thoáº¡i cÃ¡ nhÃ¢n hÃ³a cÃ³ trÃ­ nhá»› (Memory-based Personalized Dialogue Agents)**

Song song vá»›i cÃ¡c ká»¹ thuáº­t ghi nhá»› tá»•ng quÃ¡t, má»™t nhÃ¡nh quan trá»ng khÃ¡c lÃ  phÃ¡t triá»ƒn cÃ¡c **trá»£ lÃ½ há»™i thoáº¡i cÃ¡ nhÃ¢n hÃ³a**, cÃ³ kháº£ nÄƒng lÆ°u giá»¯ vÃ  sá»­ dá»¥ng thÃ´ng tin riÃªng biá»‡t cá»§a tá»«ng ngÆ°á»i dÃ¹ng trong cÃ¡c tÆ°Æ¡ng tÃ¡c dÃ i háº¡n.

- ğŸ”¹ **CoMemNN (Pei et al., 2021)**: má»™t trong nhá»¯ng mÃ´ hÃ¬nh Ä‘áº§u tiÃªn **cáº­p nháº­t há»“ sÆ¡ ngÆ°á»i dÃ¹ng dáº§n theo há»™i thoáº¡i**.
    
- ğŸ”¹ **LD-Agent (Li et al., 2024b)**: sá»­ dá»¥ng **bá»™ nhá»› ngáº¯n háº¡n â€“ dÃ i háº¡n** Ä‘á»ƒ lÆ°u láº¡i cÃ¡c thÃ´ng tin há»™i thoáº¡i vÃ  truy xuáº¥t khi cáº§n.
    
- ğŸ”¹ **MemoryBank (Zhong et al., 2024)**: mÃ´ hÃ¬nh cáº­p nháº­t trÃ­ nhá»› dá»±a trÃªn **Ä‘Æ°á»ng cong quÃªn Ebbinghaus**, Æ°u tiÃªn thÃ´ng tin gáº§n Ä‘Ã¢y.
    
- ğŸ”¹ **Theanine (Kim et al., 2024)**: mÃ´ hÃ¬nh **truy xuáº¥t theo dÃ²ng thá»i gian**, cÃ³ dÃ¹ng **LLM phá»¥ trá»£ Ä‘á»ƒ lÃ m sáº¡ch** dá»¯ liá»‡u trÆ°á»›c khi dÃ¹ng.
    

ğŸ§© Tuy nhiÃªn, cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ y thÆ°á»ng dÃ¹ng **retriever cá»‘ Ä‘á»‹nh**, vá»›i cÃ¡ch chia nhá» (granularity) khÃ´ng thay Ä‘á»•i. Äiá»u nÃ y **giá»›i háº¡n kháº£ nÄƒng thÃ­ch á»©ng** vá»›i cÃ¡c dáº¡ng há»™i thoáº¡i khÃ¡c nhau.

ğŸ‘‰ VÃ¬ váº­y, cÃ¡c nghiÃªn cá»©u gáº§n Ä‘Ã¢y nhÆ° **RMM** Ä‘á» xuáº¥t cÆ¡ cháº¿ **retrieval thÃ­ch á»©ng (adaptive)**, cho phÃ©p thay Ä‘á»•i cÃ¡ch chia nhá» vÃ  truy xuáº¥t tuá»³ vÃ o ngá»¯ cáº£nh cÃ¢u há»i â€“ má»Ÿ ra hÆ°á»›ng má»›i trong há»‡ thá»‘ng cÃ¡ nhÃ¢n hÃ³a dÃ i háº¡n.

---

Náº¿u báº¡n cáº§n:

- MÃ¬nh tÃ³m pháº§n nÃ y láº¡i thÃ nh **1 slide PowerPoint** hoáº·c **má»Ÿ Ä‘áº§u bÃ i nghiÃªn cá»©u**.
    
- Viáº¿t láº¡i pháº§n nÃ y theo **academic English chuáº©n Ä‘á»ƒ Ä‘Æ°a vÃ o section â€œRelated Workâ€**
    
- Váº½ sÆ¡ Ä‘á»“ so sÃ¡nh 3 hÆ°á»›ng tiáº¿p cáº­n + danh sÃ¡ch cÃ¡c mÃ´ hÃ¬nh tiÃªu biá»ƒu
    

ğŸ‘‰ MÃ¬nh lÃ m ngay nha!





Tuyá»‡t Quá»‘c Æ¡i! Hai bÃ i nÃ y lÃ  **nhá»¯ng baseline ráº¥t phÃ¹ há»£p** náº¿u báº¡n muá»‘n táº­p trung vÃ o hÆ°á»›ng **"trá»£ lÃ½ há»™i thoáº¡i cÃ¡ nhÃ¢n hÃ³a cÃ³ trÃ­ nhá»›" (Memory-based Personalized Dialogue Agents)**. MÃ¬nh sáº½ giÃºp báº¡n phÃ¡t biá»ƒu rÃµ rÃ ng láº¡i **cÃ¡ch chá»n vÃ  sá»­ dá»¥ng 2 baseline nÃ y trong research**, vÃ  gá»£i Ã½ hÆ°á»›ng má»Ÿ rá»™ng trÃªn tá»«ng cÃ¡i.

---

## ğŸ§± **Baseline: Personalized Memory in Dialogue Agents**

Trong nhÃ¡nh nghiÃªn cá»©u vá» **ghi nhá»› dÃ i háº¡n theo tá»«ng ngÆ°á»i dÃ¹ng**, chÃºng tÃ´i chá»n hai cÃ´ng trÃ¬nh ná»n táº£ng lÃ m baseline:

---

### **1. CoMemNN â€“ Cooperative Memory Network (Pei et al., 2021)**

ğŸ“Œ Link: [doi.org/10.1145/3442381.3449843](https://doi.org/10.1145/3442381.3449843)

**Ã tÆ°á»Ÿng chÃ­nh**:  
CoMemNN lÃ  má»™t trong nhá»¯ng há»‡ thá»‘ng Ä‘áº§u tiÃªn Ä‘Æ°a ra **há»“ sÆ¡ ngÆ°á»i dÃ¹ng Ä‘á»™ng (incremental user profile)**, Ä‘Æ°á»£c cáº­p nháº­t dáº§n dáº§n qua cÃ¡c lÆ°á»£t há»™i thoáº¡i.

- **CÆ¡ cháº¿ ghi nhá»›**: Tá»± Ä‘á»™ng trÃ­ch xuáº¥t thÃ´ng tin cÃ¡ nhÃ¢n tá»« lá»i thoáº¡i vÃ  thÃªm vÃ o "User Profile".
    
- **CÆ¡ cháº¿ sá»­ dá»¥ng**: Má»—i láº§n trÃ² chuyá»‡n má»›i, há»‡ thá»‘ng sá»­ dá»¥ng profile Ä‘á»ƒ táº¡o ngá»¯ cáº£nh vÃ  Ä‘Æ°a ra pháº£n há»“i phÃ¹ há»£p.
    
- **Dá»¯ liá»‡u sá»­ dá»¥ng**: Cáº§n cÃ³ annotation thá»§ cÃ´ng vá» persona/fact, phÃ¹ há»£p vá»›i há»‡ thá»‘ng quy mÃ´ nhá».
    

ğŸ§© **Äiá»ƒm máº¡nh**:

- LÃ  baseline tiÃªu biá»ƒu cho cÃ¡c há»‡ thá»‘ng â€œghi nhá»› ngÆ°á»i dÃ¹ngâ€ khÃ´ng cáº§n mÃ´ hÃ¬nh lá»›n.
    
- CÃ³ thá»ƒ dá»… dÃ ng tÃ­ch há»£p vÃ o pipeline hiá»‡n táº¡i nhÆ° má»™t module tÃ¡ch riÃªng.
    

ğŸ§  **HÆ°á»›ng má»Ÿ rá»™ng** báº¡n cÃ³ thá»ƒ lÃ m:

- DÃ¹ng LLM Ä‘á»ƒ **tá»± Ä‘á»™ng táº¡o profile** thay vÃ¬ cáº§n nhÃ£n.
    
- Káº¿t há»£p profile vá»›i há»‡ thá»‘ng RAG: truy xuáº¥t Ä‘oáº¡n liÃªn quan **+ thÃªm thÃ´ng tin ngÆ°á»i dÃ¹ng** â†’ tÄƒng cÃ¡ nhÃ¢n hÃ³a.
    

---

### **2. Keep Me Updated! (Bae et al., 2022)**

ğŸ“Œ Link: [aclanthology.org/2022.findings-emnlp.276](https://aclanthology.org/2022.findings-emnlp.276)

**Ã tÆ°á»Ÿng chÃ­nh**:  
TÃ¡c giáº£ Ä‘á» xuáº¥t má»™t há»‡ thá»‘ng cÃ³ kháº£ nÄƒng **cáº­p nháº­t thÃ´ng tin ngÆ°á»i dÃ¹ng theo thá»i gian**, Ä‘á»ƒ pháº£n há»“i khÃ´ng bá»‹ lá»—i thá»i.

- **CÆ¡ cháº¿**: Má»—i khi ngÆ°á»i dÃ¹ng nÃ³i Ä‘iá»u gÃ¬ má»›i (vÃ­ dá»¥ "giá» tÃ´i sá»‘ng á»Ÿ HÃ  Ná»™i"), há»‡ thá»‘ng sáº½ ghi Ä‘Ã¨/sá»­a thÃ´ng tin cÅ© ("trÆ°á»›c á»Ÿ ÄÃ  Náºµng") trong profile.
    
- Há»‡ thá»‘ng cÅ©ng cÃ³ thá»ƒ pháº£n há»“i nhÆ° ngÆ°á»i tháº­t: â€œá»’, báº¡n chuyá»ƒn nhÃ  rá»“i Ã ?â€
    

ğŸ§© **Äiá»ƒm máº¡nh**:

- LÃ  baseline hiáº¿m hoi giáº£i quyáº¿t bÃ i toÃ¡n **Knowledge Update** trong há»™i thoáº¡i.
    
- Há»¯u Ã­ch trong cÃ¡c há»‡ thá»‘ng cáº§n cáº­p nháº­t liÃªn tá»¥c (ngÃ¢n hÃ ng, bÃ¡c sÄ© áº£o, trá»£ lÃ½ cÃ¡ nhÃ¢n...).
    

ğŸ§  **HÆ°á»›ng má»Ÿ rá»™ng** báº¡n cÃ³ thá»ƒ lÃ m:

- Káº¿t há»£p vá»›i LongMemEval â€“ nhÃ³m cÃ¢u há»i **Knowledge Update** lÃ  phÃ¹ há»£p nháº¥t.
    
- Thay vÃ¬ rule-based update â†’ dÃ¹ng LLM Ä‘á»ƒ phÃ¡t hiá»‡n mÃ¢u thuáº«n vÃ  sá»­a tá»± Ä‘á»™ng.
    

---

## ğŸ§  Tá»•ng káº¿t cÃ¡ch dÃ¹ng hai baseline nÃ y:

|Baseline|Äiá»ƒm máº¡nh|DÃ¹ng cho nÄƒng lá»±c nÃ o trong LongMemEval|CÃ¡ch báº¡n cÃ³ thá»ƒ má»Ÿ rá»™ng|
|---|---|---|---|
|**CoMemNN**|XÃ¢y dá»±ng user profile qua há»™i thoáº¡i|Single-session-user, multi-session|Tá»± Ä‘á»™ng hoÃ¡ táº¡o profile báº±ng LLM|
|**Keep Me Updated**|Cáº­p nháº­t há»“ sÆ¡ ngÆ°á»i dÃ¹ng theo thá»i gian|Knowledge Update, Temporal Reasoning|PhÃ¡t hiá»‡n mÃ¢u thuáº«n báº±ng LLM|

---

ğŸ‘‰ Náº¿u Quá»‘c muá»‘n:

- Viáº¿t pháº§n _Baseline_ nÃ y báº±ng tiáº¿ng Anh há»c thuáº­t
    
- TÃ­ch há»£p vÃ o pháº§n â€œRelated Workâ€ hoáº·c lÃ m slide trÃ¬nh bÃ y
    
- Viáº¿t láº¡i há»‡ thá»‘ng nÃ y báº±ng code LLM / LangChain demo
    

MÃ¬nh triá»ƒn khai ngay nhÃ©!