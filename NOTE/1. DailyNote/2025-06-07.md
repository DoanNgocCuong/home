# 1. Offline Indexing 3000 passages Done ViÃªn MÃ£n - 16,225 Nodes, 177,939 Edges - 31/05/2025

1. Káº¿t quáº£ pha Offline Indexing:
- Corpus: 3000 passages (táº¡o báº±ng cÃ¡ch gá»™p context cá»§a 300 cÃ¢u há»i bá»™ VimQA - tÆ°Æ¡ng tá»± nhÆ° cÃ¡ch táº¡o corpus khi lÃ m vá»›i bá»™ hotpotQA).
- PhÆ°Æ¡ng phÃ¡p: XÃ¢y dá»±ng KG theo kiáº¿n trÃºc HippoRAG 2 (2 loáº¡i Node, 3 loáº¡i Edge).
1.1 Thá»‘ng kÃª Äá»“ thá»‹ (Sá»‘ liá»‡u chÃ­nh xÃ¡c):
- Nodes:
  - Passage Nodes: 3,000
  - Phrase Nodes: 13225 - Ä‘Æ°á»£c táº¡o tá»«: 20662 triples Ä‘Æ°á»£c Detect
(Sá»‘ lÆ°á»£ng Phrase Nodes pháº£i báº±ng 2 láº§n sá»‘ lÆ°á»£ng Triples detect Ä‘Æ°á»£c, tuy nhiÃªn cÃ³ nhiá»u Phrase Nodes xuáº¥t hiá»‡n trong nhiá»u bá»™ Triples)
  - Tá»•ng sá»‘ Nodes: 16225
- Edges: (mÅ©i tÃªn chá»‰ hÆ°á»›ng cá»§a cáº¡nh)
  - RELATION Edges (Subject â†’ Object): 20662     - tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i 26,100 Triples.
  - SYNONYM Edges (Phrase â†” Phrase, similarity â‰¥ 0.8): 66140
  - CONTAINS Edges (Passage â†’ Phrase): 24997     (Sá»‘ Phrase lÃ  13225 sao sá»‘ lÆ°á»£ng cáº¡nh CONTAINS lÃ  24997 - vÃ¬ 1 `Phrase` thuá»™c cÃ¹ng lÃºc nhiá»u `Passage` ).
  - Tá»•ng sá»‘ Edges: 177939
[Image]

[Image]

TRIPLES (ROBUST EXTRACTION):
   Total: 20662
   Unique Subjects: 3072
   Unique Predicates: 4319
   Unique Objects: 11171

---
KNOWLEDGE GRAPH:
   Total Nodes: 16225
   Total Edges: 177939
   Passage Nodes: 3000
   Phrase Nodes: 13225
   RELATION Edges: 20662
   SYNONYM Edges: 132280
   CONTAINS Edges: 24997
1.2 CÃ¡c thÃ´ng tin lÆ°u trong Nodes vÃ  Edges:
Nodes Phrase, Node Passage Ä‘á»u lÆ°u : text vÃ  embedding Ä‘á»§ cáº£ trong meta data cá»§a nÃ³. => CÃ¡c pháº§n nÃ y Ä‘á»u Ä‘Æ°á»£c Neo4j há»— trá»£ BM25, Search Embedding.

[Image]

[Image]

Edges :
- RELATION Edges (Subject â†’ Object): type: CONTAINER, metadata chá»©a "text" lÃ  predicate cá»§a Subject vÃ  Object.
- SYNONYM Edges (Phrase â†” Phrase, similarity â‰¥ 0.8): cáº¡nh 2 hÆ°á»›ng.
- CONTAINS Edges (Passage â†’ Phrase): type CONTAINTER.
[Image]

[Image]

[Image]
[Image]

025-05-31 17:40:43,452 - module4_graph_builder - INFO - Created 13225 Phrase nodes with meaningful IDs
2025-05-31 17:40:43,453 - module4_graph_builder - INFO - Phrase ID mapping completed: 13225 phrases processed
2025-05-31 17:40:43,453 - module4_graph_builder - INFO - Phrase examples available in Neo4j database (check Phrase nodes with 'text' property)
2025-05-31 17:40:43,457 - module4_graph_builder - INFO - Building edges...
2025-05-31 17:40:43,458 - module4_graph_builder - INFO - Creating 20662 RELATION edges (no canonical mapping)...
2025-05-31 17:42:35,531 - module4_graph_builder - INFO - Created 20662 RELATION edges
2025-05-31 17:42:35,531 - module4_graph_builder - INFO - Creating 66140 SYNONYM edges (HippoRAG 2 style)...
2025-05-31 17:49:46,713 - module4_graph_builder - INFO - Created 66140 SYNONYM edges
2025-05-31 17:49:46,713 - module4_graph_builder - INFO - SYNONYM edges enable semantic connectivity between phrase variants
2025-05-31 17:49:46,714 - module4_graph_builder - INFO - Creating CONTAINS edges (no canonical mapping)...
2025-05-31 17:52:18,592 - module4_graph_builder - INFO - Created 24997 CONTAINS edges
2025-05-31 17:52:18,596 - module4_graph_builder - INFO - Graph construction completed: 16225 nodes, 111799 edges
2025-05-31 17:52:18,597 - module4_graph_builder - INFO - HippoRAG 2 style: All phrase variants preserved, connected via synonym edges
2025-05-31 17:52:18,598 - module4_graph_builder - INFO - Getting graph statistics...
2025-05-31 17:52:19,357 - module4_graph_builder - INFO - Graph statistics: {'nodes': {'Passage': 3000, 'Phrase': 13225}, 'edges': {'RELATION': 20662, 'SYNONYM': 132280, 'CONTAINS': 24997}, 'total_nodes': 16225, 'total_edges': 177939, 'hipporag_style': True, 'canonical_mapping': False, 'surface_forms_preserved': True, 'meaningful_phrase_ids': True}
2025-05-31 17:52:19,555 - pipeline_orchestrator - INFO - Saved triples with extraction methods to extracted_triples_with_methods.tsv
2025-05-31 17:52:19,567 - module3_synonym_detector - INFO - Saving 66140 synonym pairs to detected_synonyms.tsv
2025-05-31 17:52:19,941 - module3_synonym_detector - INFO - Synonym pairs saved successfully
2025-05-31 17:52:19,943 - pipeline_orchestrator - INFO - Saved synonyms to detected_synonyms.tsv
2025-05-31 17:52:19,944 - pipeline_orchestrator - INFO - Pipeline completed successfully in 11593.08 seconds

============================================================
OFFLINE PIPELINE SUMMARY (HippoRAG 2 Style + GPT Fallback)
============================================================
Execution Time: 11593.08 seconds
Input File: corpus_vimqa_dev_300.xlsx
Pipeline Style: HippoRAG_2_with_GPT_Fallback
Canonical Mapping: False
GPT Fallback: True

EXCEL PROCESSING:
   Documents Loaded: 3000
   Avg Length: 495.9 chars

CHUNKING:
   Total Chunks: 3000
   Avg Chunk Length: 495.9 chars
   Method: keep_as_paragraph

TRIPLES (ROBUST EXTRACTION):
   Total: 20662
   Unique Subjects: 3072
   Unique Predicates: 4319
   Unique Objects: 11171
   Qwen Extracted: 0
   GPT-3.5 Extracted: 20662
   HF Success Rate: 0.0% (0/3000)
   GPT Fallback Success: 2950/3000 failures rescued
   Total Failures: 0
   âœ… All chunks successfully processed!

SYNONYMS (HippoRAG 2 Style):
   Synonym Pairs: 66140
   Avg Similarity: 0.848
   Threshold Used: 0.8
   NOTE: No canonical mapping - all phrase variants preserved

KNOWLEDGE GRAPH:
   Total Nodes: 16225
   Total Edges: 177939
   Passage Nodes: 3000
   Phrase Nodes: 13225
   RELATION Edges: 20662
   SYNONYM Edges: 132280
   CONTAINS Edges: 24997

HIPPORAG 2 + GPT FALLBACK FEATURES:
   - All phrase surface forms preserved
   - Synonym edges connect similar phrases
   - No information loss from canonical mapping
   - Robust extraction with GPT-3.5 fallback
   - Higher completion rate despite API failures
   - Ready for Personalized PageRank traversal
============================================================
Pipeline completed successfully!
Access Neo4j Browser: http://localhost:7474
============================================================
2025-05-31 17:52:19,970 - module4_graph_builder - INFO - Closing Neo4j connection
2025-05-31 17:52:19,971 - utils.utils_neo4j - INFO - Neo4j connection closed
2025-05-31 17:52:19,972 - module4_graph_builder - INFO - Neo4j connection closed
2025-05-31 17:52:19,976 - root - INFO - Pipeline results saved to pipeline_results_hipporag_corpus_vimqa_dev_300.json
ğŸ’¾ Results saved to: pipeline_results_hipporag_corpus_vimqa_dev_300.json

============================================================
âœ… PIPELINE COMPLETED SUCCESSFULLY (HippoRAG 2 Style)
============================================================
ğŸŒ Access Neo4j Browser: http://localhost:7474
   Username: neo4j
   Password: graphrag123

ğŸ“ˆ Extraction Statistics:
   HuggingFace successful: 0
   HuggingFace failed: 3000
   GPT-3.5 fallback used: 2950
   Total failures: 0

ğŸ—ï¸ HippoRAG 2 Graph Structure:
   - Passage nodes: Document chunks with embeddings
   - Phrase nodes: All surface forms preserved
   - RELATION edges: Semantic relationships
   - SYNONYM edges: Similarity connections
   - CONTAINS edges: Passage -> Phrase relationships

ğŸ“ Query Examples:
   1. Find synonyms: MATCH (p1:Phrase)-[:SYNONYM]-(p2:Phrase) RETURN p1, p2
   2. Explore relations: MATCH (p1:Phrase)-[:RELATION]-(p2:Phrase) RETURN p1, p2
   3. Find passages: MATCH (passage:Passage)-[:CONTAINS]->(phrase:Phrase) RETURN passage, phrase   4. Check extraction methods: MATCH ()-[r:RELATION]->() RETURN r.extraction_method, count(*)

ğŸš€ Next steps:
   1. Explore graph in Neo4j Browser
   2. Run Personalized PageRank queries
   3. Test semantic search capabilities
   4. Check intermediate results in output files
   5. Verify all passages have CONTAINS edges
============================================================
(.venv) PS D:\GIT\ResearchProject_Memory-AugmentedAIAgents_GraduationProject\src\system\PPDX\OfflineIndexing>



---

# 2. Build xong 1 cÃ¡i Offline -> CÃ³ sá»‘ á»Ÿ pha Online - cÆ¡ mÃ  váº«n sai sai.

run_retrieval_pipeline.py

Cáº§n viáº¿t code nÃ y, báº¡n viáº¿t ngáº¯n gá»n cho tÃ´i nhÃ¡

input lÃ : file excel cÃ³ cá»™t: question -> output lÃ  copy file gá»‘c ra vÃ  Ä‘iá»n thÃªm cÃ¡c thÃ´ng tin quan trá»ng qua tá»«ng module

* module 1: top_k_passages, bm25_passages, hybrid_passages, raw_passages, top_n_triples, bm25_triples, hybrid_triples, raw_triples
* module 2: filted_triples
* module 3: filterd_passages
* module 4: expand_triples
* module 5: final_passge, final_triples, ...

(má»—i cá»™t Ä‘á»ƒ thÃ´ng tin ... kÃ¨m score luÃ´n nhÃ¡ - dáº¡ng JSON cÅ©ng Ä‘Æ°á»£c )

---
Code nhÃ¡p lÃªn plan cho tÃ´i trÆ°á»›c nhÃ©
TÃ´i oke thÃ¬ code háº¿t

=====

"""
OnlineRetrievalAndQA/run_retrieval_pipeline.py - PLAN OVERVIEW
Xá»­ lÃ½ file Excel questions vÃ  thÃªm detailed results tá»« cÃ¡c modules

PLAN STRUCTURE:
===============

1. INPUT/OUTPUT:
   - Input: questions.xlsx (cá»™t 'question')
   - Output: questions_results.xlsx (+ nhiá»u cá»™t má»›i)

2. COLUMNS Sáº¼ ÄÆ¯á»¢C THÃŠM:

   Module 1 - Dual Retrieval:
   - module1_top_passages: JSON [{id, score, text_preview}, ...]
   - module1_top_triples: JSON [{subject, predicate, object, score}, ...]
   - module1_stats: JSON {bm25_avg, embedding_avg, hybrid_avg}

   Module 2 - Triple Filtering:
   - module2_filtered_triples: JSON [{triple_id, relevance_score, level}, ...]
   - module2_stats: JSON {original_count, filtered_count, avg_relevance}

   Module 3 - Passage Ranking:
   - module3_ranked_passages: JSON [{passage_id, final_score, support_score}, ...]
   - module3_stats: JSON {reranking_changes, support_distribution}

   Module 4 - Context Expansion:
   - module4_expanded_contexts: JSON [{context_id, relevance_score, path}, ...]

   Final Results:
   - final_passages: JSON top passages vá»›i final scores
   - final_processing_time: float seconds
   - final_pipeline_stats: JSON overall statistics

3. CODE STRUCTURE:

class DetailedPipelineProcessor:
    - Extends RetrievalPipelineOrchestrator
    - Captures detailed outputs tá»« má»—i module
    - Extract functions cho tá»«ng module

def main():
    - Load Excel file
    - Initialize processor
    - Process each question
    - Add detailed columns
    - Save enhanced Excel

4. USAGE:
   python run_retrieval_pipeline.py --input questions.xlsx --output results.xlsx --top_k 10

5. FEATURES:
   âœ… Excel input/output
   âœ… Detailed module info capture
   âœ… JSON format for complex data
   âœ… Error handling per question
   âœ… Progress tracking
   âœ… Configurable parameters
   âœ… Excel formatting vá»›i colors
"""
========

## **ğŸ¯ Expected Results After Fix:**

### **Current (Before Fix):**
```json
{
  "passage_id": "passage_chunk_Äá»‰nh Langbiang_19_0",
  "rank": 2,                           // âŒ Wrong rank
  "final_score": 0.212,                // âŒ Low score
  "retrieval_score": 0.529,
  "support_score": 0.0,                // âŒ No support found
  "supporting_triples_count": 0,       // âŒ Should be 4!
  "supporting_triples": []             // âŒ Empty
}
```

### **After Fix (Expected):**
```json
{
  "passage_id": "passage_chunk_Äá»‰nh Langbiang_19_0",
  "rank": 1,                           // âœ… Should be #1!
  "final_score": 0.75-0.85,            // âœ… Much higher!
  "retrieval_score": 0.529,            // Same
  "support_score": 0.55-0.65,          // âœ… Strong support!
  "supporting_triples_count": 4,        // âœ… All 4 K'lang+H'biang triples
  "supporting_triples": [               // âœ… Populated!
    "triple_58f6ddbf",  // lang biang â†’ named after â†’ chÃ ng k'lang vÃ  nÃ ng h'biang
    "triple_3831070f",  // k'lang â†’ love â†’ h'biang
    "triple_291ed087",  // k'lang â†’ save â†’ h'biang
    "triple_dfb6b54e"   // h'biang â†’ cannot marry â†’ k'lang
  ]
}
```

## **ğŸ“Š Score Calculation Details:**

### **Support Score Calculation:**
```python
# 4 supporting triples vá»›i relevance scores:
# - Triple 1: 0.51 (lang biang named after...)
# - Triple 2: 0.456 (k'lang love h'biang)
# - Triple 3: 0.456 (k'lang save h'biang)
# - Triple 4: 0.409 (h'biang cannot marry k'lang)

avg_relevance = (0.51 + 0.456 + 0.456 + 0.409) / 4 = 0.458
count_boost = min(1.0, 4/5) = 0.8

support_score = (0.458 Ã— 0.7) + (0.8 Ã— 0.3) = 0.32 + 0.24 = 0.56
```

### **Final Score Calculation:**
```python
# Current config: 50-50 weights
alpha_retrieval = 0.5
alpha_support = 0.5

base_final_score = (0.5 Ã— 0.529) + (0.5 Ã— 0.56) = 0.265 + 0.28 = 0.545

# No penalty (has support now)
final_score = 0.545 (no modifiers applied)
```

## **ğŸ† Final Ranking Expected:**

### **New Order:**
```
1. passage_chunk_Äá»‰nh Langbiang_19_0     // âœ… The story passage!
   Score: ~0.75 (with support boost)
   Content: "CÃ¢u chuyá»‡n tÃ¬nh cá»§a chÃ ng K'lang vÃ  nÃ ng H'biang..."
   Supporting Triples: 4

2. passage_chunk_Khu dá»± trá»¯ sinh quyá»ƒn_14_0
   Score: 0.4 (no support, with penalty)
   Content: "Khu dá»± trá»¯ sinh quyá»ƒn tháº¿ giá»›i Langbiang..."
   Supporting Triples: 0

3. passage_chunk_Cao nguyÃªn LÃ¢m ViÃªn_17_0
   Score: 0.0 (normalization issue)
   Supporting Triples: 0
```

## **ğŸ‰ Key Changes:**

### **âœ… What Will Improve:**
1. **Correct passage ranks #1** - The passage with actual K'lang+H'biang story
2. **Support scores populated** - 4 relevant triples found and counted
3. **Final scores realistic** - Reflects both retrieval quality + knowledge support
4. **Logical ranking** - Content-rich passage beats keyword-only matches

### **ğŸ“Š Statistics Changes:**
```json
// Before:
"support_distribution": {
  "no_support": 3,      // All passages had no support
  "low_support": 0,
  "medium_support": 0,
  "high_support": 0
}

// After:
"support_distribution": {
  "no_support": 2,      // 2 passages still no support
  "low_support": 0,
  "medium_support": 1,  // âœ… Äá»‰nh Langbiang passage gets support!
  "high_support": 0
}
```

## **ğŸš€ Answer Quality:**

**Query**: "TÃªn nÃºi Lang Biang Ä‘Æ°á»£c giáº£i thÃ­ch báº±ng huyá»n thoáº¡i nÃ o"
**Answer**: "chÃ ng K'lang vÃ  nÃ ng H'biang"

**Before**: Wrong passage ranked #1 (administrative info)
**After**: âœ… **Correct passage ranked #1** (contains the actual legend story)

**This demonstrates the power of knowledge-augmented retrieval over pure keyword matching!** ğŸ¯


---
# 3. Váº¥n Ä‘á» embedding cÃ³ rá»“i mÃ  lÃºc truy váº¥n láº¡i pháº£i tÃ­nh láº¡i embedding cá»§a passages ?? (cÃ²n triples thÃ¬ lÃºc táº¡o quÃªn chÆ°a tÃ­nh embedding cho nÃ³)

- Má»¤C TIÃŠU BÃ‚Y GIá»œ LÃ€ NHANH CÃ“ Sá» NÃŠN LÃ€: Táº M DÃ™NG MODEL EMBEDDING BÃ‰ TÃ NHÆ¯: "sentence-transformers/all-MiniLM-L6-v2"
Äá»‚ Äáº¨Y NHANH Tá»C Äá»˜ RA Sá» ÄÃƒ. FIX THÃ”NG LUÃ’NG
---
Sau update EMBEDDING CHO TRIPLES Ä‘Ã£ cÃ³ cÃ¡ch - dá»± kiáº¿n lÃ  update embedding cho triples vÃ o cáº¡nh RELATION cá»§a nÃ³ vÃ¬ nÃ³ lÃ  DUY NHáº¤T MÃ€ - ÄÃšNG KO NHá»ˆ :d


---
# 4. Fix lá»—i á»Ÿ module 3: support_id cá»§a cÃ¡c passage Ä‘á»u báº±ng 0 máº·c dÃ¹ triples thÃ¬ Ä‘áº§y Ä‘Ã³ ra: nguyÃªn nhÃ¢n do sá»± ko khá»›p cá»§a tÃªn id (do áº£nh hÆ°á»Ÿng cá»§a tiá»n tá»‘)


def standardize_triple_passage_ids(
    filtered_triples: List[Any],
    passage_id_prefix: str = "passage_chunk_",
    triple_id_prefix: str = "chunk_"
) -> List[Any]:
    """
    Chuáº©n hÃ³a tiá»n tá»‘ cá»§a source_passage_id trong cÃ¡c FilteredTriple Ä‘á»ƒ khá»›p vá»›i Ä‘á»‹nh dáº¡ng
    passage_id cá»§a cÃ¡c passage.

    Args:
        filtered_triples (List[Any]): Danh sÃ¡ch cÃ¡c Ä‘á»‘i tÆ°á»£ng FilteredTriple tá»« Module 2
        passage_id_prefix (str): Tiá»n tá»‘ mong muá»‘n cho passage_id
        triple_id_prefix (str): Tiá»n tá»‘ hiá»‡n táº¡i cá»§a source_passage_id trong triples

    Returns:
        List[Any]: Danh sÃ¡ch cÃ¡c Ä‘á»‘i tÆ°á»£ng FilteredTriple Ä‘Ã£ Ä‘Æ°á»£c chuáº©n hÃ³a source_passage_id
    """
    if not filtered_triples:
        return []

    logger.info(f"Standardizing triple source_passage_ids from '{triple_id_prefix}' to '{passage_id_prefix}'...")
    standardized_triples = []
    for triple in filtered_triples:
        if triple.source_passage_id.startswith(triple_id_prefix):
            new_source_passage_id = passage_id_prefix + triple.source_passage_id[len(triple_id_prefix):]
            # Create a new triple with updated ID
            triple_dict = triple.__dict__.copy()
            triple_dict['source_passage_id'] = new_source_passage_id
            standardized_triples.append(type(triple)(**triple_dict))
        else:
            logger.warning(f"Triple ID '{triple.source_passage_id}' does not start with '{triple_id_prefix}'. Keeping as is.")
            standardized_triples.append(triple)
    logger.info(f"Finished standardizing {len(standardized_triples)} triples.")
    return standardized_triples


---
# 4. [CÃ³ káº¿t quáº£ sá»‘ cho tá»«ng module lÃºc 20h tá»‘i - thá»Ÿ phÃ o nháº¹ nhÃµm vÃ¬ cÃ³ sá»‘ lÃ  bÃ¡o cÃ¡o Ä‘Æ°á»£c rá»“i - lÃºc Ä‘Ã³ Ä‘ang ngá»“i vá»›i Oanh - cáº£m giÃ¡c Ä‘á»‘i máº·t vá»›i deadline Ä‘Æ°á»£c báº£o vá»‡/ko mÃ  mÃ¬nh bÃ¬nh tÄ©nh vÃ£i]11:44 P.M - 31/05/2025 - 01/06/2025 lÃ  háº¡n cuá»‘i duyá»‡t "Äá»“ng Ã½/Ko Ä‘á»“ng Ã½" cho báº£o vá»‡ ---Co can KQ cua Giai doan 1 - Offline - KG va cac buoc cu the cung KQ cua giai doan 2. DA thu nghiem tren  dung 1 dataset nen can nhieu KQ trung gian va phan tich, so sanh

