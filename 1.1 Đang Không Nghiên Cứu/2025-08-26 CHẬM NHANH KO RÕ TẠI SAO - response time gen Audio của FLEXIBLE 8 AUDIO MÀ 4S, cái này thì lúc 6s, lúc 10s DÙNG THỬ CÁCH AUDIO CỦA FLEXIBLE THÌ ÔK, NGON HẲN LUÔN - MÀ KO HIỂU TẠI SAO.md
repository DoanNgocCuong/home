

// conversationCardController.js
// ƒêo√†n Ng·ªçc C∆∞·ªùng - 26/08/2025
// Sinh h·ªôi tho·∫°i + audio cho response/answer

const OpenAI = require('openai');
const { textToSpeechAndUpload } = require('../utils/utils_textToSpeechUploadAudio');
const { MAX_TOKENS } = require('../config/batchConfig');
const getPromptFromDB = require('./getPromptFromDBController').getPromptFromDB;

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY || ''
});

// Prompt m·∫∑c ƒë·ªãnh (fallback)
const DEFAULT_LYLYTHECOACH_SYSTEM_PROMPT = `
Act as a conversation builder. You will be given scenario and a question. Your task is
1. Generate a response when user correctly answer the question, make it general and neutral so it fits all intent, event good or bad. Do not compliment.
2. Generate an answer when user ask the question.
You talk cute, witty.
Both english and vietnamese should be natural
You will return in JSON
{"response_to_answer":"<your response>","response_to_answer_vi":"<Vietnamese version of response>","answer_question":"<your creative answer to question that fits the scenario, make it short and witty>","answer_question_vi":"<Vietnamese version of answer>"}
`;

// L·∫•y prompt t·ª´ DB (n·∫øu fail th√¨ d√πng m·∫∑c ƒë·ªãnh)
const getLyLyTheCoachSystemPrompt = async () => {
  try {
    const promptResponse = await getPromptFromDB(
      { body: { name_prompt: 'lyly_thecoach_system_prompt' } },
      {
        json: (data) => data,
        status: (code) => ({
          json: (data) => { throw new Error(`Failed to get prompt: ${JSON.stringify(data)}`); }
        })
      }
    );
    console.log('Successfully retrieved lyly prompt from DB');
    return promptResponse.system_prompt;
  } catch (error) {
    console.error('Error getting lyly prompt from DB, fallback to default:', error);
    return DEFAULT_LYLYTHECOACH_SYSTEM_PROMPT;
  }
};

// H√†m enrich th√™m audio v√†o JSON
// H√†m sanitize text ƒë·ªÉ tr√°nh l·ªói TTS API
function sanitizeTextForTTS(text) {
  if (!text) return '';
  
  return text
    .replace(/["""]/g, '') // Lo·∫°i b·ªè quotes
    .replace(/[^\w\s.,!?-]/g, '') // Ch·ªâ gi·ªØ l·∫°i ch·ªØ, s·ªë, kho·∫£ng tr·∫Øng v√† d·∫•u c√¢u c∆° b·∫£n
    .trim();
}

// H√†m enrich th√™m audio v√†o JSON - S·ª≠ d·ª•ng c√°ch gen audio gi·ªëng nh∆∞ generateLearningCardController
async function enrichConversationWithAudio(conversationData, originalQuestion) {
    try {
      console.log('Starting audio generation for conversation data...');
      
      // Sanitize texts tr∆∞·ªõc khi g·ª≠i ƒë·∫øn TTS API
      const sanitizedResponse = sanitizeTextForTTS(conversationData.response_to_answer) || conversationData.response_to_answer;
      const sanitizedAnswer = sanitizeTextForTTS(conversationData.answer_question) || conversationData.answer_question;
      const sanitizedQuestion = sanitizeTextForTTS(originalQuestion) || originalQuestion;
      
      console.log('Sanitized texts:', {
        original_response: conversationData.response_to_answer,
        sanitized_response: sanitizedResponse,
        original_answer: conversationData.answer_question,
        sanitized_answer: sanitizedAnswer,
        original_question: originalQuestion,
        sanitized_question: sanitizedQuestion
      });
      
      const [
        audioResponse,
        audioAnswer,
        audioQuestion,
        audioAskMe
      ] = await Promise.all([
        textToSpeechAndUpload(
          sanitizedResponse,
          'en-AU-WilliamNeural',
          1,
          'web_mvp/thecoach/audio_TC2025/lyly'
        ),
        textToSpeechAndUpload(
          sanitizedAnswer,
          'en-AU-WilliamNeural',
          1,
          'web_mvp/thecoach/audio_TC2025/lyly'
        ),
        textToSpeechAndUpload(
          sanitizedQuestion,
          'en-AU-WilliamNeural',
          1,
          'web_mvp/thecoach/audio_TC2025/lyly'
        ),
        // Audio c·ª©ng cho "It's your turn to ask me" - kh√¥ng c·∫ßn gen m·ªõi
        Promise.resolve({ url: "https://smedia.stepup.edu.vn/web_mvp/thecoach/audio_TC2025/lyly/it_s_your_turn_to_ask_me_20250826_010250_bx3uia.mp3" })
      ]);
  
            conversationData.audio_response = audioResponse?.url || '';
      conversationData.audio_answer = audioAnswer?.url || '';
      conversationData.question = originalQuestion;
      conversationData.question_audio = audioQuestion?.url || '';
      conversationData.ask_me_audio = audioAskMe?.url || '';

      console.log('Successfully generated all audio files');
      console.log('Audio URLs:', {
        response: conversationData.audio_response,
        answer: conversationData.audio_answer,
        question: conversationData.question_audio,
        ask_me: conversationData.ask_me_audio
      });

      return conversationData;
    } catch (error) {
      console.error('Error enriching conversation with audio:', error);
      conversationData.audio_response = '';
      conversationData.audio_answer = '';
      conversationData.question = originalQuestion;
      conversationData.question_audio = '';
      conversationData.ask_me_audio = '';
      return conversationData;
    }
  }
  
  

// Controller ch√≠nh
exports.generateLyLyTheCoach = async (req, res) => {
  console.time('generateConversationCard');
  try {
    const { situation, scenario, question } = req.body.data;

    if (!situation || !scenario || !question) {
      return res.status(400).json({ error: 'Missing situation, scenario or question' });
    }

    const systemPrompt = await getLyLyTheCoachSystemPrompt();

    const response = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: systemPrompt },
        { 
          role: 'user', 
          content: JSON.stringify({ 
            Situation: situation,
            Scenario: scenario,
            Question: question
          })
        }
      ],
      max_tokens: MAX_TOKENS,
      temperature: 0,
      top_p: 1,
      frequency_penalty: 0,
      presence_penalty: 0
    });

    const content = response.choices[0].message.content;
    const cleaned = content.trim().replace(/```json|```/g, '');
    let conversationData = JSON.parse(cleaned);

    // G·∫Øn th√™m audio
    conversationData = await enrichConversationWithAudio(conversationData, question);

    console.timeEnd('generateConversationCard');
    res.json(conversationData);

  } catch (error) {
    console.error('Error in generateConversationCard:', error);
    console.timeEnd('generateConversationCard');
    res.status(500).json({ error: error.message });
  }
};


// curl -X POST "http://localhost:3000/api/generate-learning-lyly-the-coach" ^
//   -H "Content-Type: application/json" ^
//   -d "{\"data\":{\"situation\":\"First day at new job\",\"scenario\":\"Meeting the team for the first time\",\"question\":\"How should I introduce myself?\"}}"


c√°ch n√†y ƒë√£ song song gen audio ch∆∞a 
// conversationCardController.js
// ƒêo√†n Ng·ªçc C∆∞·ªùng - 26/08/2025
// Sinh h·ªôi tho·∫°i + audio cho response/answer

const OpenAI = require('openai');
const { textToSpeechAndUpload } = require('../utils/utils_textToSpeechUploadAudio');
const { MAX_TOKENS } = require('../config/batchConfig');
const getPromptFromDB = require('./getPromptFromDBController').getPromptFromDB;

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY || ''
});

// Prompt m·∫∑c ƒë·ªãnh (fallback)
const DEFAULT_LYLYTHECOACH_SYSTEM_PROMPT = `
Act as a conversation builder. You will be given scenario and a question. Your task is
1. Generate a response when user correctly answer the question, make it general and neutral so it fits all intent, event good or bad. Do not compliment.
2. Generate an answer when user ask the question.
You talk cute, witty.
Both english and vietnamese should be natural
You will return in JSON
{"response_to_answer":"<your response>","response_to_answer_vi":"<Vietnamese version of response>","answer_question":"<your creative answer to question that fits the scenario, make it short and witty>","answer_question_vi":"<Vietnamese version of answer>"}
`;

// L·∫•y prompt t·ª´ DB (n·∫øu fail th√¨ d√πng m·∫∑c ƒë·ªãnh)
const getLyLyTheCoachSystemPrompt = async () => {
  try {
    const promptResponse = await getPromptFromDB(
      { body: { name_prompt: 'lyly_thecoach_system_prompt' } },
      {
        json: (data) => data,
        status: (code) => ({
          json: (data) => { throw new Error(`Failed to get prompt: ${JSON.stringify(data)}`); }
        })
      }
    );
    console.log('Successfully retrieved lyly prompt from DB');
    return promptResponse.system_prompt;
  } catch (error) {
    console.error('Error getting lyly prompt from DB, fallback to default:', error);
    return DEFAULT_LYLYTHECOACH_SYSTEM_PROMPT;
  }
};

// H√†m enrich th√™m audio v√†o JSON
// H√†m sanitize text ƒë·ªÉ tr√°nh l·ªói TTS API
function sanitizeTextForTTS(text) {
  if (!text) return '';
  
  return text
    .replace(/["""]/g, '') // Lo·∫°i b·ªè quotes
    .replace(/[^\w\s.,!?-]/g, '') // Ch·ªâ gi·ªØ l·∫°i ch·ªØ, s·ªë, kho·∫£ng tr·∫Øng v√† d·∫•u c√¢u c∆° b·∫£n
    .trim();
}

// H√†m enrich th√™m audio v√†o JSON - S·ª≠ d·ª•ng c√°ch gen audio gi·ªëng nh∆∞ generateLearningCardController
async function enrichConversationWithAudio(conversationData, originalQuestion) {
    try {
      console.log('Starting audio generation for conversation data...');
      
      // Sanitize texts tr∆∞·ªõc khi g·ª≠i ƒë·∫øn TTS API
      const sanitizedResponse = sanitizeTextForTTS(conversationData.response_to_answer) || conversationData.response_to_answer;
      const sanitizedAnswer = sanitizeTextForTTS(conversationData.answer_question) || conversationData.answer_question;
      const sanitizedQuestion = sanitizeTextForTTS(originalQuestion) || originalQuestion;
      
      console.log('Sanitized texts:', {
        original_response: conversationData.response_to_answer,
        sanitized_response: sanitizedResponse,
        original_answer: conversationData.answer_question,
        sanitized_answer: sanitizedAnswer,
        original_question: originalQuestion,
        sanitized_question: sanitizedQuestion
      });
      
      // T·ªëi ∆∞u: S·ª≠ d·ª•ng c√°ch song song gi·ªëng generateLearningFlexibleController
      const audioMap = {};
      const audioPromises = [];
      
      // TTS cho response_to_answer
      if (sanitizedResponse && sanitizedResponse.length > 3) {
        audioPromises.push(
          textToSpeechAndUpload(
            sanitizedResponse,
            'en-AU-WilliamNeural',
            1,
            'web_mvp/thecoach/audio_TC2025/lyly'
          ).then(audio => {
            if (audio && audio.url) {
              audioMap['response'] = audio.url;
            }
            return { type: 'response', url: audio?.url || '' };
          }).catch(error => {
            console.error(`‚ùå Error generating audio for response: "${sanitizedResponse}"`, error.message);
            audioMap['response'] = '';
            return { type: 'response', url: '' };
          })
        );
      } else {
        audioMap['response'] = '';
        audioPromises.push(Promise.resolve({ type: 'response', url: '' }));
      }
      
      // TTS cho answer_question
      if (sanitizedAnswer && sanitizedAnswer.length > 3) {
        audioPromises.push(
          textToSpeechAndUpload(
            sanitizedAnswer,
            'en-AU-WilliamNeural',
            1,
            'web_mvp/thecoach/audio_TC2025/lyly'
          ).then(audio => {
            if (audio && audio.url) {
              audioMap['answer'] = audio.url;
            }
            return { type: 'answer', url: audio?.url || '' };
          }).catch(error => {
            console.error(`‚ùå Error generating audio for answer: "${sanitizedAnswer}"`, error.message);
            audioMap['answer'] = '';
            return { type: 'answer', url: '' };
          })
        );
      } else {
        audioMap['answer'] = '';
        audioPromises.push(Promise.resolve({ type: 'answer', url: '' }));
      }
      
      // TTS cho c√¢u h·ªèi g·ªëc
      if (sanitizedQuestion && sanitizedQuestion.length > 3) {
        audioPromises.push(
          textToSpeechAndUpload(
            sanitizedQuestion,
            'en-AU-WilliamNeural',
            1,
            'web_mvp/thecoach/audio_TC2025/lyly'
          ).then(audio => {
            if (audio && audio.url) {
              audioMap['question'] = audio.url;
            }
            return { type: 'question', url: audio?.url || '' };
          }).catch(error => {
            console.error(`‚ùå Error generating audio for question: "${sanitizedQuestion}"`, error.message);
            audioMap['question'] = '';
            return { type: 'question', url: '' };
          })
        );
      } else {
        audioMap['question'] = '';
        audioPromises.push(Promise.resolve({ type: 'question', url: '' }));
      }
      
      // Audio c·ª©ng cho "It's your turn to ask me" - kh√¥ng c·∫ßn gen m·ªõi
      audioMap['ask_me'] = "https://smedia.stepup.edu.vn/web_mvp/thecoach/audio_TC2025/lyly/it_s_your_turn_to_ask_me_20250826_010250_bx3uia.mp3";
      audioPromises.push(Promise.resolve({ type: 'ask_me', url: audioMap['ask_me'] }));

      // Ch·∫°y t·∫•t c·∫£ audio generation song song
      console.log('üöÄ Starting parallel audio generation for', audioPromises.length, 'audio files...');
      const audioResults = await Promise.all(audioPromises);
      
      // Map k·∫øt qu·∫£ theo type
      const audioResponse = audioResults.find(r => r.type === 'response') || { url: '' };
      const audioAnswer = audioResults.find(r => r.type === 'answer') || { url: '' };
      const audioQuestion = audioResults.find(r => r.type === 'question') || { url: '' };
      const audioAskMe = audioResults.find(r => r.type === 'ask_me') || { url: '' };
      
      console.log('‚úÖ Audio generation completed. Audio Map:', audioMap);
  
            conversationData.audio_response = audioResponse?.url || '';
      conversationData.audio_answer = audioAnswer?.url || '';
      conversationData.question = originalQuestion;
      conversationData.question_audio = audioQuestion?.url || '';
      conversationData.ask_me_audio = audioAskMe?.url || '';

      console.log('Successfully generated all audio files');
      console.log('Audio URLs:', {
        response: conversationData.audio_response,
        answer: conversationData.audio_answer,
        question: conversationData.question_audio,
        ask_me: conversationData.ask_me_audio
      });

      return conversationData;
    } catch (error) {
      console.error('Error enriching conversation with audio:', error);
      conversationData.audio_response = '';
      conversationData.audio_answer = '';
      conversationData.question = originalQuestion;
      conversationData.question_audio = '';
      conversationData.ask_me_audio = '';
      return conversationData;
    }
  }
  
  

// Controller ch√≠nh
exports.generateLyLyTheCoach = async (req, res) => {
  console.time('generateConversationCard');
  try {
    const { situation, scenario, question } = req.body.data;

    if (!situation || !scenario || !question) {
      return res.status(400).json({ error: 'Missing situation, scenario or question' });
    }

    const systemPrompt = await getLyLyTheCoachSystemPrompt();

    const response = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: systemPrompt },
        { 
          role: 'user', 
          content: JSON.stringify({ 
            Situation: situation,
            Scenario: scenario,
            Question: question
          })
        }
      ],
      max_tokens: MAX_TOKENS,
      temperature: 0,
      top_p: 1,
      frequency_penalty: 0,
      presence_penalty: 0
    });

    const content = response.choices[0].message.content;
    const cleaned = content.trim().replace(/```json|```/g, '');
    let conversationData = JSON.parse(cleaned);

    // G·∫Øn th√™m audio
    conversationData = await enrichConversationWithAudio(conversationData, question);

    console.timeEnd('generateConversationCard');
    res.json(conversationData);

  } catch (error) {
    console.error('Error in generateConversationCard:', error);
    console.timeEnd('generateConversationCard');
    res.status(500).json({ error: error.message });
  }
};


// curl -X POST "http://localhost:3000/api/generate-learning-lyly-the-coach" ^
//   -H "Content-Type: application/json" ^
//   -d "{\"data\":{\"situation\":\"First day at new job\",\"scenario\":\"Meeting the team for the first time\",\"question\":\"How should I introduce myself?\"}}"



2 C√ÅCH N√ÄY KH√ÅC G√å NHAU 



Hay, em so s√°nh chi ti·∫øt cho anh 2 c√°ch anh ƒë∆∞a nh√© üöÄ

---

## üü¢ C√°ch 1 (Promise.all tr·ª±c ti·∫øp, anh vi·∫øt tr∆∞·ªõc ƒë√≥)

```js
const [
  audioResponse,
  audioAnswer,
  audioQuestion,
  audioAskMe
] = await Promise.all([
  textToSpeechAndUpload(...response...),
  textToSpeechAndUpload(...answer...),
  textToSpeechAndUpload(...question...),
  Promise.resolve({ url: "link c·ª©ng" })
]);
```

### ‚úÖ ƒê·∫∑c ƒëi·ªÉm:

- **Song song 100%**: b·∫Øn 3 request TTS c√πng l√∫c.
    
- **Code ng·∫Øn g·ªçn**, d·ªÖ ƒë·ªçc.
    
- Nh∆∞ng: n·∫øu 1 request TTS l·ªói (throw error) ‚Üí **c·∫£ Promise.all fail** ‚Üí to√†n b·ªô b·ªã catch, c√°c audio kh√°c kh√¥ng c√≥ k·∫øt qu·∫£.
    
- Kh√¥ng check text r·ªóng/ng·∫Øn, n√™n c√≥ th·ªÉ b·∫Øn TTS ngay c·∫£ khi input kh√¥ng h·ª£p l·ªá ‚Üí d·ªÖ g√¢y l·ªói ‚Äúempty text‚Äù.
    

---

## üü¢ C√°ch 2 (Promise.all + `.then/.catch` cho t·ª´ng audio, anh vi·∫øt sau)

```js
const audioPromises = [];

if (sanitizedResponse && sanitizedResponse.length > 3) {
  audioPromises.push(
    textToSpeechAndUpload(...)
      .then(audio => ({ type: 'response', url: audio?.url || '' }))
      .catch(err => ({ type: 'response', url: '' }))
  );
} else {
  audioPromises.push(Promise.resolve({ type: 'response', url: '' }));
}

const audioResults = await Promise.all(audioPromises);
```

### ‚úÖ ƒê·∫∑c ƒëi·ªÉm:

- **V·∫´n song song**, v√¨ cu·ªëi c√πng v·∫´n `Promise.all`.
    
- **Robust h∆°n**:
    
    - C√≥ `.catch` cho t·ª´ng audio ‚Üí 1 c√°i fail th√¨ c√°c c√°i kh√°c v·∫´n th√†nh c√¥ng.
        
    - C√≥ check `length > 3` ‚Üí tr√°nh request r√°c cho TTS API.
        
- **Code d√†i h∆°n**, ph·ª©c t·∫°p h∆°n ch√∫t.
    
- T·ªën th√™m v√†i ms x·ª≠ l√Ω logic (kh√¥ng ƒë√°ng k·ªÉ).
    

---

## üìä So s√°nh t·ªïng quan

|Ti√™u ch√≠|C√°ch 1 (Promise.all tr·ª±c ti·∫øp)|C√°ch 2 (Promise.all + catch t·ª´ng c√°i)|
|---|---|---|
|T·ªëc ƒë·ªô|‚ö° Nhanh (song song)|‚ö° Nhanh (song song, g·∫ßn nh∆∞ b·∫±ng nhau)|
|ƒê·ªô an to√†n (1 fail)|‚ùå To√†n batch fail|‚úÖ Fail 1 c√°i kh√¥ng ·∫£nh h∆∞·ªüng c√°i kh√°c|
|X·ª≠ l√Ω input r·ªóng/ng·∫Øn|‚ùå Kh√¥ng|‚úÖ C√≥ check skip n·∫øu < 3 k√Ω t·ª±|
|Code simplicity|‚úÖ Ng·∫Øn g·ªçn|‚ùå D√†i h∆°n, ph·ª©c t·∫°p h∆°n|
|Th√≠ch h·ª£p khi|Input ch·∫Øc ch·∫Øn h·ª£p l·ªá, √≠t l·ªói|Input c√≥ th·ªÉ l·ªói/r√°c, c·∫ßn robust h∆°n|

---

## ‚úÖ K·∫øt lu·∫≠n cho anh

- N·∫øu **demo/test nh·ªè, √≠t audio, input lu√¥n s·∫°ch** ‚Üí C√°ch 1 cho g·ªçn code.
    
- N·∫øu **production, scale l·ªõn, input ƒë√¥i khi r√°c/l·ªói** ‚Üí C√°ch 2 an to√†n h∆°n, gi·ªØ k·∫øt qu·∫£ c·ªßa nh·ªØng audio c√≤n l·∫°i khi 1 c√°i b·ªã l·ªói.
    

---

üëâ Em g·ª£i √Ω: anh n√™n **d√πng C√°ch 2 cho production**, v√¨ n√≥ ‚Äúch·ªãu l·ªói t·ª´ng ph·∫ßn‚Äù, kh√¥ng s·ª£ user nh·∫≠p linh tinh l√†m fail h·∫øt.

Anh c√≥ mu·ªën em vi·∫øt th√™m m·ªôt **wrapper utility** ki·ªÉu `safeTextToSpeech(text, type)` ƒë·ªÉ code C√°ch 2 g·ªçn l·∫°i (ƒë·ª° l·∫∑p `.then/.catch`) kh√¥ng?


