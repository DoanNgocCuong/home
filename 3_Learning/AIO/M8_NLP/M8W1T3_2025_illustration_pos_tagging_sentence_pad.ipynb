{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oJfB0l9di5D0",
      "metadata": {
        "id": "oJfB0l9di5D0",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# !pip install -U torchtext==0.17.0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7efe5b00-cda0-4c3f-9cbc-6fd590ebb4a6",
      "metadata": {
        "id": "7efe5b00-cda0-4c3f-9cbc-6fd590ebb4a6"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22382432-34a8-474b-9519-af1168597ea1",
      "metadata": {
        "id": "22382432-34a8-474b-9519-af1168597ea1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "corpus = [\n",
        "    \"AI is growing fast\",\n",
        "    \"Models are large\"\n",
        "]\n",
        "\n",
        "data_size = len(corpus)\n",
        "\n",
        "# 0: noun/pronoun - 1: verb - others - 2\n",
        "labels = [[0, 1, 1, 2],\n",
        "          [0, 1, 2]]\n",
        "\n",
        "# Define the max vocabulary size and sequence length\n",
        "vocab_size = 9\n",
        "sequence_length = 4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "sample1 = corpus[0]\n",
        "sample2 = corpus[1]\n",
        "\n",
        "# Define tokenizer\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "# Tokenize sample 1\n",
        "sample1_tokens = tokenizer(sample1)\n",
        "print(sample1_tokens)\n",
        "\n",
        "# Tokenize sample 2\n",
        "sample2_tokens = tokenizer(sample2)\n",
        "print(sample2_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEDiiLiXu8m9",
        "outputId": "858374bf-0293-418d-dba5-e10bf939563b"
      },
      "id": "hEDiiLiXu8m9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ai', 'is', 'growing', 'fast']\n",
            "['models', 'are', 'large']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2726650a-52ef-4150-9b09-0071d0ce2a31",
      "metadata": {
        "id": "2726650a-52ef-4150-9b09-0071d0ce2a31"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "# Define tokenizer\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "# Create a function to yield list of tokens\n",
        "def yield_tokens(examples):\n",
        "    for text in examples:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "# Create vocabulary\n",
        "vocab = build_vocab_from_iterator(yield_tokens(corpus),\n",
        "                                  max_tokens=vocab_size,\n",
        "                                  specials=[\"<unk>\", \"<pad>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jLAW07vgsKVD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLAW07vgsKVD",
        "outputId": "e89ca988-a452-4ed8-dcf6-a1ae870f203d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'is': 6,\n",
              " 'growing': 5,\n",
              " 'models': 8,\n",
              " 'are': 3,\n",
              " 'ai': 2,\n",
              " 'fast': 4,\n",
              " '<pad>': 1,\n",
              " 'large': 7,\n",
              " '<unk>': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 305
        }
      ],
      "source": [
        "vocab.get_stoi()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3192fcd6-d411-4312-afcd-88fe4e64a8b9",
      "metadata": {
        "id": "3192fcd6-d411-4312-afcd-88fe4e64a8b9"
      },
      "outputs": [],
      "source": [
        "# Tokenize and numericalize your samples\n",
        "def vectorize(text, vocab, sequence_length, sequence_label):\n",
        "    tokens = tokenizer(text)\n",
        "\n",
        "    token_ids = [vocab[token] for token in tokens]\n",
        "    token_ids = token_ids + [vocab[\"<pad>\"]] * (sequence_length - len(tokens))\n",
        "    sequence_label = sequence_label + [3] * (sequence_length - len(tokens))\n",
        "\n",
        "    return torch.tensor(token_ids, dtype=torch.long), torch.tensor(sequence_label, dtype=torch.long)\n",
        "\n",
        "# Vectorize the samples\n",
        "sentence_vecs = []\n",
        "label_vecs = []\n",
        "for sentence, labels in zip(corpus, labels):\n",
        "    sentence_vec, labels_vec = vectorize(sentence, vocab, sequence_length, labels)\n",
        "    sentence_vecs.append(sentence_vec)\n",
        "    label_vecs.append(labels_vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1189966-b5d0-4bbe-9805-712e206b533c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1189966-b5d0-4bbe-9805-712e206b533c",
        "outputId": "f2be4eb9-1fd4-4b69-ea53-a31c79d96fa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 6, 5, 4])\n",
            "tensor([8, 3, 7, 1])\n"
          ]
        }
      ],
      "source": [
        "for v in sentence_vecs:\n",
        "    print(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3e40856-0cc4-4f25-b704-05e9d4aaeb95",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3e40856-0cc4-4f25-b704-05e9d4aaeb95",
        "outputId": "eff16af9-52a3-4413-ce5d-c5ea33f1e595"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 1, 2])\n",
            "tensor([0, 1, 2, 3])\n"
          ]
        }
      ],
      "source": [
        "for v in label_vecs:\n",
        "    print(v)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd4c5571-1104-44a2-a066-2118f4861e9a",
      "metadata": {
        "id": "cd4c5571-1104-44a2-a066-2118f4861e9a"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c8843b2-83e1-408f-b9d1-0f7983cd7c59",
      "metadata": {
        "id": "2c8843b2-83e1-408f-b9d1-0f7983cd7c59"
      },
      "outputs": [],
      "source": [
        "class POS_Model(nn.Module):\n",
        "    def __init__(self, vocab_size, num_classes):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, 4)\n",
        "        self.fc = nn.Linear(4, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.fc(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        return x\n",
        "\n",
        "model = POS_Model(vocab_size, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff4aa45e-658b-4ecc-ac1c-2e12d06440ba",
      "metadata": {
        "id": "ff4aa45e-658b-4ecc-ac1c-2e12d06440ba"
      },
      "outputs": [],
      "source": [
        "# Embedding weight\n",
        "custom_weights = torch.tensor( [[ 0.7321, -1.2503,  0.8154, -0.4987],\n",
        "                                [-0.2165,  1.7823, -0.6892,  0.9476],\n",
        "                                [ 1.1043,  0.3289, -1.5284,  0.6520],\n",
        "                                [-0.8116,  0.5672,  0.2031, -0.9725],\n",
        "                                [ 0.4528, -0.1476,  1.2930,  0.7842],\n",
        "                                [-1.3459,  0.6791, -0.8853,  1.1207],\n",
        "                                [ 0.9823, -0.5504,  0.4389, -1.2396],\n",
        "                                [ 0.7415,  1.1048, -0.3207, -0.4871],\n",
        "                                [-0.2158, -1.3749,  0.9036,  0.6724]]).float()\n",
        "model.embedding.weight = nn.Parameter(custom_weights)\n",
        "\n",
        "# FC weight\n",
        "fc_weights = torch.tensor( [[ 0.3748, -0.1062,  0.5347,  0.0573],\n",
        "                            [-0.1189,  0.0972, -0.4471,  0.5312],\n",
        "                            [ 0.2925,  0.6210, -0.6989, -0.0523],\n",
        "                            [-0.0912,  0.1413,  0.3324,  0.3857]]).float()\n",
        "model.fc.weight = nn.Parameter(fc_weights)\n",
        "\n",
        "# FC bias\n",
        "fc_bias = torch.tensor([ 0.1987, -0.3745,  0.5632, -0.1256]).float()\n",
        "model.fc.bias = nn.Parameter(fc_bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21a09076-bc00-4a43-a22c-f805fe3120ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21a09076-bc00-4a43-a22c-f805fe3120ba",
        "outputId": "b69e4735-51fa-42db-8d0c-83ba7de549ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 1])\n"
          ]
        }
      ],
      "source": [
        "input_1 = torch.tensor([[8]], dtype=torch.long)\n",
        "output = model(input_1)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5bbb7ee-2c78-4a17-b758-fdcc05723098",
      "metadata": {
        "id": "c5bbb7ee-2c78-4a17-b758-fdcc05723098"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06a6c262-ad54-491e-8b9d-1a1f6f0a2f61",
      "metadata": {
        "id": "06a6c262-ad54-491e-8b9d-1a1f6f0a2f61"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=3)\n",
        "optimizer = torch.optim.Adam(model.parameters(),\n",
        "                             lr=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d97173d0-9c87-4724-919c-7a5a564bc002",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d97173d0-9c87-4724-919c-7a5a564bc002",
        "outputId": "996931ce-c272-4886-d90a-fbf140dd6214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4941, 0.1327, 0.0812, 0.2920], grad_fn=<SelectBackward0>)\n",
            "tensor([0.2300, 0.1122, 0.4630, 0.1948], grad_fn=<SelectBackward0>)\n",
            "tensor([0.1453, 0.0773, 0.6885, 0.0889], grad_fn=<SelectBackward0>)\n",
            "tensor([0.0587, 0.1632, 0.6635, 0.1146], grad_fn=<SelectBackward0>)\n",
            "torch.Size([1, 4, 4])\n",
            "torch.Size([1, 4])\n"
          ]
        }
      ],
      "source": [
        "# 2nd sample\n",
        "input_1 = torch.tensor([[8, 3, 7, 1]], dtype=torch.long)\n",
        "label_1 = torch.tensor([[0, 1, 2, 3]], dtype=torch.long)\n",
        "\n",
        "optimizer.zero_grad()\n",
        "outputs = model(input_1)\n",
        "o_softmax = torch.softmax(outputs, axis=1)\n",
        "print(o_softmax[0, :, 0])\n",
        "print(o_softmax[0, :, 1])\n",
        "print(o_softmax[0, :, 2])\n",
        "print(o_softmax[0, :, 3])\n",
        "\n",
        "print(outputs.shape)\n",
        "print(label_1.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = criterion(outputs, label_1)\n",
        "print(loss)\n",
        "\n",
        "loss.backward()\n",
        "optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEZya4L9K0mU",
        "outputId": "8bbf6631-b8d2-4994-949f-33be3b713784"
      },
      "id": "PEZya4L9K0mU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.0885, grad_fn=<NllLoss2DBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07be65d8-0378-4498-8c4c-134158a94a1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07be65d8-0378-4498-8c4c-134158a94a1f",
        "outputId": "601ccbd5-6cd7-4146-9087-f6d53bfd6615"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " embedding.weight \n",
            "\n",
            "Parameter containing:\n",
            "tensor([[ 0.7321, -1.2503,  0.8154, -0.4987],\n",
            "        [-0.2165,  1.7823, -0.6892,  0.9476],\n",
            "        [ 1.1043,  0.3289, -1.5284,  0.6520],\n",
            "        [-0.9116,  0.4672,  0.1031, -0.8725],\n",
            "        [ 0.4528, -0.1476,  1.2930,  0.7842],\n",
            "        [-1.3459,  0.6791, -0.8853,  1.1207],\n",
            "        [ 0.9823, -0.5504,  0.4389, -1.2396],\n",
            "        [ 0.8415,  1.2048, -0.4207, -0.5871],\n",
            "        [-0.1158, -1.4749,  1.0036,  0.5724]], requires_grad=True)\n",
            "\n",
            " fc.weight \n",
            "\n",
            "Parameter containing:\n",
            "tensor([[ 0.2748, -0.2062,  0.6347,  0.1573],\n",
            "        [-0.2189,  0.1972, -0.3471,  0.4312],\n",
            "        [ 0.3925,  0.7210, -0.7989,  0.0477],\n",
            "        [ 0.0088,  0.2413,  0.2324,  0.4857]], requires_grad=True)\n",
            "\n",
            " fc.bias \n",
            "\n",
            "Parameter containing:\n",
            "tensor([ 0.2987, -0.2745,  0.4632, -0.2256], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n embedding.weight \\n\")\n",
        "print(model.embedding.weight)\n",
        "\n",
        "print(\"\\n fc.weight \\n\")\n",
        "print(model.fc.weight)\n",
        "\n",
        "print(\"\\n fc.bias \\n\")\n",
        "print(model.fc.bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "721dc7f3-d9cc-4021-a355-d5fa01ae9437",
      "metadata": {
        "id": "721dc7f3-d9cc-4021-a355-d5fa01ae9437",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "654f14f4-3833-43a4-fa3c-8d58880d79b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[8, 3, 7, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 317
        }
      ],
      "source": [
        "input_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21495a2d-ebc1-437f-981e-23fe6857060a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21495a2d-ebc1-437f-981e-23fe6857060a",
        "outputId": "8bf2296f-8e7e-4f10-db7f-433e65331ce9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.6830, 0.0982, 0.0451, 0.1737], grad_fn=<SelectBackward0>)\n",
            "tensor([0.2513, 0.1909, 0.3895, 0.1683], grad_fn=<SelectBackward0>)\n",
            "tensor([0.0969, 0.0754, 0.7510, 0.0768], grad_fn=<SelectBackward0>)\n",
            "tensor([0.0469, 0.1540, 0.6814, 0.1176], grad_fn=<SelectBackward0>)\n",
            "tensor(0.7745, grad_fn=<NllLoss2DBackward0>)\n"
          ]
        }
      ],
      "source": [
        "optimizer.zero_grad()\n",
        "outputs = model(input_1)\n",
        "o_softmax = torch.softmax(outputs, axis=1)\n",
        "print(o_softmax[0, :, 0])\n",
        "print(o_softmax[0, :, 1])\n",
        "print(o_softmax[0, :, 2])\n",
        "print(o_softmax[0, :, 3])\n",
        "\n",
        "loss = criterion(outputs, label_1)\n",
        "print(loss)\n",
        "\n",
        "loss.backward()\n",
        "optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8338e51c-143f-45ec-bc81-b05166ba32f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8338e51c-143f-45ec-bc81-b05166ba32f0",
        "outputId": "6f554119-bfd5-40d4-bf19-8e45dc6515e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " embedding.weight \n",
            "\n",
            "Parameter containing:\n",
            "tensor([[ 0.7321, -1.2503,  0.8154, -0.4987],\n",
            "        [-0.2165,  1.7823, -0.6892,  0.9476],\n",
            "        [ 1.1043,  0.3289, -1.5284,  0.6520],\n",
            "        [-1.0115,  0.3729,  0.0065, -0.7789],\n",
            "        [ 0.4528, -0.1476,  1.2930,  0.7842],\n",
            "        [-1.3459,  0.6791, -0.8853,  1.1207],\n",
            "        [ 0.9823, -0.5504,  0.4389, -1.2396],\n",
            "        [ 0.9401,  1.3043, -0.5201, -0.6851],\n",
            "        [-0.0249, -1.5749,  1.1024,  0.4784]], requires_grad=True)\n",
            "\n",
            " fc.weight \n",
            "\n",
            "Parameter containing:\n",
            "tensor([[ 0.3290, -0.3039,  0.7327,  0.2552],\n",
            "        [-0.3190,  0.2951, -0.2671,  0.3325],\n",
            "        [ 0.4922,  0.8209, -0.8966,  0.1451],\n",
            "        [ 0.1064,  0.3326,  0.1371,  0.5795]], requires_grad=True)\n",
            "\n",
            " fc.bias \n",
            "\n",
            "Parameter containing:\n",
            "tensor([ 0.3466, -0.1747,  0.3644, -0.3236], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n embedding.weight \\n\")\n",
        "print(model.embedding.weight)\n",
        "\n",
        "print(\"\\n fc.weight \\n\")\n",
        "print(model.fc.weight)\n",
        "\n",
        "print(\"\\n fc.bias \\n\")\n",
        "print(model.fc.bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "937300b4-3a3e-4de2-a367-8fda588daab3",
      "metadata": {
        "id": "937300b4-3a3e-4de2-a367-8fda588daab3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b547154b-2223-4e4f-a875-119ec33f9812",
      "metadata": {
        "id": "b547154b-2223-4e4f-a875-119ec33f9812"
      },
      "source": [
        "## Train with full data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb26d7d5-81e3-4cf3-90ff-99b3bfa5524d",
      "metadata": {
        "id": "bb26d7d5-81e3-4cf3-90ff-99b3bfa5524d"
      },
      "outputs": [],
      "source": [
        "custom_weights = torch.tensor( [[ 0.7321, -1.2503,  0.8154, -0.4987],\n",
        "                                [-0.2165,  1.7823, -0.6892,  0.9476],\n",
        "                                [ 1.1043,  0.3289, -1.5284,  0.6520],\n",
        "                                [-0.8116,  0.5672,  0.2031, -0.9725],\n",
        "                                [ 0.4528, -0.1476,  1.2930,  0.7842],\n",
        "                                [-1.3459,  0.6791, -0.8853,  1.1207],\n",
        "                                [ 0.9823, -0.5504,  0.4389, -1.2396],\n",
        "                                [ 0.7415,  1.1048, -0.3207, -0.4871],\n",
        "                                [-0.2158, -1.3749,  0.9036,  0.6724]]).float()\n",
        "model.embedding.weight = nn.Parameter(custom_weights)\n",
        "\n",
        "fc_weights = torch.tensor( [[ 0.3748, -0.1062,  0.5347,  0.0573],\n",
        "                            [-0.1189,  0.0972, -0.4471,  0.5312],\n",
        "                            [ 0.2925,  0.6210, -0.6989, -0.0523],\n",
        "                            [-0.0912,  0.1413,  0.3324,  0.3857]]).float()\n",
        "model.fc.weight = nn.Parameter(fc_weights)\n",
        "\n",
        "fc_bias = torch.tensor([ 0.1987, -0.3745,  0.5632, -0.1256]).float()\n",
        "model.fc.bias = nn.Parameter(fc_bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32ed2deb-b3e3-4a70-8b85-c575001fc213",
      "metadata": {
        "id": "32ed2deb-b3e3-4a70-8b85-c575001fc213"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=3)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "910680f9-acb5-493e-a194-a3f18f4788f0",
      "metadata": {
        "id": "910680f9-acb5-493e-a194-a3f18f4788f0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbee29f3-5988-4f5f-a9f1-fb13f137a91d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbee29f3-5988-4f5f-a9f1-fb13f137a91d",
        "outputId": "4804e456-c965-4d4e-b5d5-7420a721ecf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.5842945575714111\n",
            "1.5465704202651978\n",
            "1.5097811222076416\n",
            "1.4739363193511963\n",
            "1.439034104347229\n",
            "1.4050570726394653\n",
            "1.3719760179519653\n",
            "1.3397586345672607\n",
            "1.3083724975585938\n",
            "1.2777864933013916\n",
            "1.2479702234268188\n",
            "1.2188959121704102\n",
            "1.1905386447906494\n",
            "1.1628729104995728\n",
            "1.1358730792999268\n",
            "1.1095119714736938\n",
            "1.0837604999542236\n",
            "1.0585891008377075\n",
            "1.0339672565460205\n",
            "1.009865403175354\n",
            "0.9862543940544128\n",
            "0.9631068110466003\n",
            "0.9403967261314392\n",
            "0.9181000590324402\n",
            "0.8961944580078125\n",
            "0.8746592402458191\n",
            "0.8534750938415527\n",
            "0.8326242566108704\n",
            "0.8120900988578796\n",
            "0.7918574213981628\n"
          ]
        }
      ],
      "source": [
        "input_data = torch.tensor( [[7, 8, 2, 5],\n",
        "                            [4, 3, 6, 1]], dtype=torch.long)\n",
        "label_data = torch.tensor([[0, 1, 2, 0],\n",
        "                           [0, 1, 2, 3]], dtype=torch.long)\n",
        "\n",
        "for _ in range(30):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(input_data)\n",
        "    loss = criterion(outputs, label_data)\n",
        "    print(loss.item())\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b562b790-b1f8-4e0c-a1cc-2453ee3f3a1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b562b790-b1f8-4e0c-a1cc-2453ee3f3a1a",
        "outputId": "8197a212-47ba-48cc-9f50-76933b58353c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3137, 0.0822, 0.4638, 0.1403], grad_fn=<SelectBackward0>)\n",
            "tensor([0.4286, 0.4155, 0.0556, 0.1002], grad_fn=<SelectBackward0>)\n",
            "tensor([0.0899, 0.0387, 0.8241, 0.0473], grad_fn=<SelectBackward0>)\n",
            "tensor([0.3242, 0.3565, 0.1743, 0.1450], grad_fn=<SelectBackward0>)\n",
            "\n",
            "tensor([0.6592, 0.1276, 0.0717, 0.1415], grad_fn=<SelectBackward0>)\n",
            "tensor([0.2796, 0.3052, 0.2586, 0.1566], grad_fn=<SelectBackward0>)\n",
            "tensor([0.2048, 0.0612, 0.6425, 0.0915], grad_fn=<SelectBackward0>)\n",
            "tensor([0.3258, 0.1349, 0.3661, 0.1732], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "outputs = model(input_data)\n",
        "o_softmax = torch.softmax(outputs, axis=1)\n",
        "\n",
        "print(o_softmax[0, :, 0])\n",
        "print(o_softmax[0, :, 1])\n",
        "print(o_softmax[0, :, 2])\n",
        "print(o_softmax[0, :, 3])\n",
        "\n",
        "print()\n",
        "print(o_softmax[1, :, 0])\n",
        "print(o_softmax[1, :, 1])\n",
        "print(o_softmax[1, :, 2])\n",
        "print(o_softmax[1, :, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cd76225-a340-42ea-8352-81cdf3c56e99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cd76225-a340-42ea-8352-81cdf3c56e99",
        "outputId": "83e6d784-ac95-43ce-c56d-e77345bdd93b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 1, 2, 0], [0, 1, 2, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 324
        }
      ],
      "source": [
        "[[0, 1, 2, 0],\n",
        " [0, 1, 2, 3]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "051f948f-3123-43f0-8e9d-ec8315314d17",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "051f948f-3123-43f0-8e9d-ec8315314d17",
        "outputId": "81aa73b7-13e1-40ff-846f-55f9e2a7e78b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " embedding.weight \n",
            "\n",
            "Parameter containing:\n",
            "tensor([[ 0.7321, -1.2503,  0.8154, -0.4987],\n",
            "        [-0.2165,  1.7823, -0.6892,  0.9476],\n",
            "        [ 1.4126,  0.5986, -1.8277,  0.3537],\n",
            "        [-1.1242,  0.2551, -0.0507, -0.6943],\n",
            "        [ 0.7029, -0.3955,  1.5791,  0.6880],\n",
            "        [-1.0716,  0.4592, -0.6084,  1.0576],\n",
            "        [ 1.3065, -0.2989,  0.1638, -1.5513],\n",
            "        [ 0.7718,  0.8467, -0.0353, -0.1614],\n",
            "        [-0.5230, -1.5754,  0.6373,  0.9254]], requires_grad=True)\n",
            "\n",
            " fc.weight \n",
            "\n",
            "Parameter containing:\n",
            "tensor([[ 0.1816,  0.1791,  0.2891,  0.3403],\n",
            "        [-0.4253, -0.2016, -0.1751,  0.2594],\n",
            "        [ 0.5775,  0.3558, -0.8107, -0.3518],\n",
            "        [ 0.0713,  0.3504,  0.0741,  0.1267]], requires_grad=True)\n",
            "\n",
            " fc.bias \n",
            "\n",
            "Parameter containing:\n",
            "tensor([ 0.4903, -0.0872,  0.2756, -0.4163], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n embedding.weight \\n\")\n",
        "print(model.embedding.weight)\n",
        "\n",
        "print(\"\\n fc.weight \\n\")\n",
        "print(model.fc.weight)\n",
        "\n",
        "print(\"\\n fc.bias \\n\")\n",
        "print(model.fc.bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e351ef5-c01e-47b9-8f2e-fbae9d0f2fa7",
      "metadata": {
        "id": "7e351ef5-c01e-47b9-8f2e-fbae9d0f2fa7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}