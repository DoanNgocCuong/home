

Để so sánh rõ hơn giữa **Precision (Độ chính xác)** và **Recall (Độ thu hồi)**, ta có thể phân tích theo các tiêu chí sau: **Ý nghĩa**, **Ví dụ**, **Ưu điểm**, và **Hạn chế**.

### **1. Ý nghĩa**

- **Precision (Độ chính xác)**:
    
    - Đo lường tỷ lệ câu trả lời **đúng** trong tổng số câu trả lời mà mô hình trả về.
    - **Precision** giúp bạn biết được khi mô hình trả về câu trả lời, tỷ lệ phần trăm câu trả lời đó là đúng.
- **Recall (Độ thu hồi)**:
    
    - Đo lường tỷ lệ câu trả lời **đúng** mà mô hình đã **phát hiện** trong tổng số câu trả lời đúng có sẵn trong dữ liệu.
    - **Recall** giúp bạn biết mô hình có bỏ sót bao nhiêu câu trả lời đúng trong tổng số câu trả lời đúng có trong tập dữ liệu.

### **2. Ví dụ**

Giả sử chúng ta có một hệ thống trả lời câu hỏi với dữ liệu gồm 10 câu trả lời đúng và mô hình trả về 8 câu trả lời (trong đó có 6 câu đúng và 2 câu sai).

- **Precision**:
    
    - Mô hình trả về 8 câu, trong đó 6 câu đúng và 2 câu sai.
    - **Precision** = Soˆˊ caˆu đuˊngSoˆˊ caˆu trả veˆˋ=68=75%\frac{\text{Số câu đúng}}{\text{Số câu trả về}} = \frac{6}{8} = 75\%
- **Recall**:
    
    - Trong dữ liệu có 10 câu trả lời đúng, và mô hình trả về 6 câu đúng.
    - **Recall** = Soˆˊ caˆu đuˊng trả veˆˋSoˆˊ caˆu đuˊng trong dữ liệu=610=60%\frac{\text{Số câu đúng trả về}}{\text{Số câu đúng trong dữ liệu}} = \frac{6}{10} = 60\%

### **3. Ưu điểm**

- **Precision (Độ chính xác)**:
    
    - Đo lường **chất lượng** của các câu trả lời mà mô hình đưa ra.
    - Khi **Precision cao**, điều đó có nghĩa là mô hình trả về ít câu trả lời sai, tức là mô hình khá chính xác trong việc trả lời đúng câu hỏi.
- **Recall (Độ thu hồi)**:
    
    - Đo lường **khả năng phát hiện** tất cả câu trả lời đúng.
    - Khi **Recall cao**, điều đó có nghĩa là mô hình không bỏ sót câu trả lời nào, tức là mô hình có khả năng phát hiện hầu hết các câu trả lời đúng từ dữ liệu.

### **4. Hạn chế**

- **Precision (Độ chính xác)**:
    
    - **Hạn chế**: Không quan tâm đến việc có bao nhiêu câu trả lời **đúng mà mô hình bỏ qua**.
    - Ví dụ: Nếu mô hình chỉ trả về 1 câu và câu đó đúng, Precision sẽ rất cao (100%), nhưng mô hình có thể bỏ sót các câu trả lời khác, dẫn đến **Recall thấp**.
- **Recall (Độ thu hồi)**:
    
    - **Hạn chế**: Không quan tâm đến việc mô hình có trả về câu trả lời **sai hay không**. Một mô hình có Recall cao có thể trả về nhiều câu trả lời sai, làm giảm độ chính xác của mô hình.
    - Ví dụ: Mô hình có thể trả về 20 câu trả lời, trong đó có 15 câu đúng và 5 câu sai. Điều này giúp Recall cao (75%), nhưng Precision lại thấp (15/20 = 75%).

### **So sánh tổng quát**:

|**Tiêu chí**|**Precision (Độ chính xác)**|**Recall (Độ thu hồi)**|
|---|---|---|
|**Ý nghĩa**|Đo tỷ lệ câu trả lời đúng trong tổng số câu trả lời mô hình trả về.|Đo tỷ lệ câu trả lời đúng mà mô hình phát hiện trong tổng số câu trả lời đúng có sẵn trong dữ liệu.|
|**Công thức**|Precision=Soˆˊ caˆu trả lời đuˊngSoˆˊ caˆu trả lời trả veˆˋ\text{Precision} = \frac{\text{Số câu trả lời đúng}}{\text{Số câu trả lời trả về}}|Recall=Soˆˊ caˆu trả lời đuˊng trả veˆˋTổng soˆˊ caˆu trả lời đuˊng\text{Recall} = \frac{\text{Số câu trả lời đúng trả về}}{\text{Tổng số câu trả lời đúng}}|
|**Ví dụ**|Mô hình trả về 8 câu, trong đó có 6 câu đúng. Precision = 75%.|Mô hình trả về 6 câu đúng trong tổng số 10 câu đúng. Recall = 60%.|
|**Ưu điểm**|Đo lường chất lượng các câu trả lời mô hình đưa ra.|Đo lường khả năng phát hiện tất cả câu trả lời đúng.|
|**Hạn chế**|Không quan tâm đến câu trả lời đúng mà mô hình bỏ qua.|Không quan tâm đến câu trả lời sai mà mô hình trả về.|

### **Khi nào sử dụng Precision và Recall?**

- **Precision** là quan trọng khi bạn cần đảm bảo rằng các câu trả lời mô hình đưa ra là chính xác, không sai. Ví dụ, trong hệ thống tìm kiếm, bạn muốn tìm ra các tài liệu phù hợp nhất mà không đưa ra tài liệu không liên quan.
- **Recall** quan trọng khi bạn không muốn bỏ sót câu trả lời đúng, ngay cả khi mô hình trả về một số câu trả lời không chính xác. Ví dụ, trong các hệ thống kiểm tra y tế, bạn muốn phát hiện tất cả các trường hợp bệnh (tất cả câu trả lời đúng), dù có thể có một số kết quả không chính xác.

### **F1 Score (Điểm F1)**:

Nếu bạn muốn cân bằng giữa Precision và Recall, bạn có thể sử dụng **F1 Score**, vì nó là trung bình điều hòa của Precision và Recall, giúp tránh tình trạng chỉ tối ưu hóa một trong hai mà bỏ qua yếu tố còn lại.


-------------



### MA TRẬN NHẦM LẪN

Trong các bài toán phân loại, các **True Positive (TP)**, **True Negative (TN)**, **False Positive (FP)** và **False Negative (FN)** là các khái niệm quan trọng để đánh giá hiệu quả mô hình. Dưới đây là các công thức và định nghĩa cho **TP** và **TN**:
### **Tóm tắt về các khái niệm liên quan**:

- **TP (True Positive)**: Mô hình dự đoán đúng là dương tính (true positives).
- **TN (True Negative)**: Mô hình dự đoán đúng là âm tính (true negatives).
- **FP (False Positive)**: Mô hình dự đoán sai là dương tính (false positives).
- **FN (False Negative)**: Mô hình dự đoán sai là âm tính (false negatives).

### **Cách sử dụng trong các metric**:

- **Precision** (Độ chính xác): Đo lường tỷ lệ giữa các câu trả lời đúng trong tổng số câu trả lời mà mô hình đưa ra:
    
	    $Precision=TPTP+FP\text{Precision} = \frac{TP}{TP + FP}$
- **Recall** (Độ thu hồi): Đo lường tỷ lệ giữa các câu trả lời đúng mà mô hình phát hiện được trong tổng số câu trả lời đúng thực tế:
    
	    $Recall=TPTP+FN\text{Recall} = \frac{TP}{TP + FN}$
- **F1 Score**: Trung hòa giữa Precision và Recall:
    
     $F1=2×Precision×RecallPrecision+RecallF1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$

Các công thức này giúp bạn hiểu cách mô hình hoạt động và đánh giá độ chính xác, độ thu hồi, và khả năng cân bằng giữa hai yếu tố đó.


---
# Ôn tập và trao đổi ngày : 10/08/2025 - GS25 - with a Nam 

![[Pasted image 20250810203632.png]]

1. Precision = Tổng số dự đoán Positive đúng / Tổng số Positive dự đoán. = TP/ (TP+FP) 
Recall = Tổng số dự đoán Positive đúng / Tổng số Positive đúng thực tế = TP/(TP+FN) 

Ví dụ bài toán dự đoán ung thư. 
+, Ung thư -> dự đoán là ung thư: TP 
+, Ko ung thư -> dự đoán là ung thư: FP 
+, Không ung thư -> dự đoán là ung thư: FN
+, Không ung thư -> dự đoán là ko ung thư: TN 

=> Ưu tiên cái nào hơn? Ưu tiên FN hơn FP => ưu tiên Recall hơn Precision (a Hải Nam support). 


2. Accuracy = TP + TN / Tổng toàn bộ. 
   Chẳng hạn: TP = TN = FP = FN = 10 => Acc = 50% 
3. Thread hold của 