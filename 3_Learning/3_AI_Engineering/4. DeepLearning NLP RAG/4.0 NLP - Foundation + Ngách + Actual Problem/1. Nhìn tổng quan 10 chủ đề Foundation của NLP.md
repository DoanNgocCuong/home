

|**Số Thứ Tự**|**Chủ Đề**|**Giải Thích Đơn Giản**|**Ứng Dụng Thực Tế**|
|---|---|---|---|
|**1**|**Tokenization**|Cắt nhỏ câu thành từng từ hoặc cụm từ để máy tính hiểu và xử lý.|Phân tách tin nhắn thành từ để dịch hoặc tìm ý chính.|
|**2**|**Preprocessing**|Làm sạch dữ liệu, như xóa từ thừa, chỉnh lỗi chính tả hoặc chuyển tất cả về chữ thường.|Làm sạch văn bản trước khi phân tích nội dung trên mạng xã hội.|
|**3**|**Bag of Words và Similarity**|Biến văn bản thành một túi từ và so sánh để tìm ra độ giống nhau giữa các văn bản.|Gợi ý phim hoặc bài viết tương tự bạn đã thích.|
|**4**|**TF-IDF và Document Search**|Tìm từ quan trọng nhất trong văn bản và dùng nó để tìm kiếm nội dung liên quan.|Tìm thông tin nhanh từ sách điện tử hoặc website.|
|**5**|**Naive Bayes Text Classification**|Một cách máy học đơn giản để phân loại văn bản vào các nhóm, như "vui" hoặc "buồn".|Lọc email rác hoặc phân tích cảm xúc trong bài viết.|
|**6**|**LDA Topic Modelling**|Tìm ra các chủ đề chính trong một tập hợp văn bản lớn.|Phân loại tin tức thành các chủ đề như thể thao, chính trị.|
|**7**|**Word Embeddings**|Biến từ thành các con số giúp máy tính hiểu được nghĩa và mối quan hệ giữa các từ.|Gợi ý từ khi bạn gõ tin nhắn hoặc viết văn bản.|
|**8**|**Recurrent Neural Networks (RNNs)**|Mô hình AI dùng để dự đoán từ tiếp theo hoặc hiểu ngữ cảnh trong câu dài.|Dự đoán từ trong ứng dụng gõ phím hoặc viết lời bài hát.|
|**9**|**Machine Translation và Attention**|Dịch ngôn ngữ bằng cách tập trung vào những từ quan trọng trong câu.|Google Dịch hoặc các app dịch ngôn ngữ trực tuyến.|
|**10**|**Transformers**|Công nghệ tiên tiến giúp AI hiểu và xử lý văn bản nhanh, chính xác hơn.|Chatbot, tìm kiếm trên Google, hoặc trợ lý ảo như Siri.|

Bảng này giúp học sinh dễ hình dung và kết nối lý thuyết với ứng dụng thực tế trong cuộc sống.


# BM25 
so sánh **BM25** với các phương pháp khác (như TF-IDF và Bag of Words), trình bày đơn giản và dễ hiểu:

### Ứng dụng của BM25:

- **Công cụ tìm kiếm**: Google, ElasticSearch, hoặc các hệ thống tìm kiếm trên website.

| **Tiêu Chí**           | **Bag of Words**                                  | **TF-IDF**                                                                       | **BM25**                                                                       |
| ---------------------- | ------------------------------------------------- | -------------------------------------------------------------------------------- | ------------------------------------------------------------------------------ |
| **Cách hoạt động**     | Đếm số lần một từ xuất hiện trong văn bản.        | Tính độ quan trọng của từ dựa trên tần suất (TF) và số văn bản chứa từ đó (IDF). | Tương tự TF-IDF nhưng điều chỉnh thêm để cân bằng độ dài tài liệu và truy vấn. |
| **Độ chính xác**       | Thấp, vì không phân biệt từ quan trọng hay không. | Cao hơn Bag of Words, ưu tiên các từ hiếm nhưng quan trọng.                      | Cao nhất, vì thêm yếu tố tối ưu về độ dài và truy vấn.                         |
| **Xét độ dài văn bản** | Không quan tâm.                                   | Không quan tâm.                                                                  | Có cân nhắc để tránh ưu tiên tài liệu dài quá mức.                             |
| **Tốc độ xử lý**       | Nhanh.                                            | Trung bình.                                                                      | Chậm hơn TF-IDF do tính toán phức tạp hơn.                                     |
| **Ứng dụng thực tế**   | Phân loại cơ bản hoặc phân tích tần suất từ.      | Tìm kiếm nội dung hoặc đánh giá mức độ quan trọng của từ.                        | Xếp hạng kết quả tìm kiếm trên Google, ElasticSearch.                          |
| **Ưu điểm nổi bật**    | Đơn giản, dễ thực hiện.                           | Đánh giá từ quan trọng tốt hơn Bag of Words.                                     | Xếp hạng tài liệu hiệu quả và phù hợp hơn với các truy vấn thực tế.            |
| **Nhược điểm**         | Không phân biệt từ phổ biến và từ quan trọng.     | Không tối ưu khi văn bản có độ dài khác nhau.                                    | Tính toán phức tạp hơn, yêu cầu nhiều tài nguyên hơn.                          |

Dưới đây là bảng chi tiết với cột **Cách hoạt động mã hóa** được giải thích dễ hiểu hơn cho học sinh cấp 2, cùng ví dụ minh họa cụ thể:

| **Cách hoạt động mã hóa**                                                                                                                                                                                                                                                                                                                                              | **Ứng dụng trong mô hình ML/DL (dựa vào cách hoạt động mã hóa)**                                                                                                                                                                                                                                                                               |
| ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Bag of Words (BoW):** Chuyển câu thành một danh sách các từ và đếm số lần mỗi từ xuất hiện. <br><br>**Không quan tâm thứ tự hoặc ngữ cảnh.** Ví dụ: Câu "I like apples, I like bananas" có từ điển `["I", "like", "apples", "bananas"]` sẽ được mã hóa thành `[2, 2, 1, 1]` (mỗi từ xuất hiện bao nhiêu lần).                                                        | - **Naive Bayes, SVM, Logistic Regression:** Dùng để phân loại văn bản, ví dụ: xác định email spam hoặc không. <br>- **DL cơ bản (LSTM, RNN):** BoW dùng làm dữ liệu đầu vào, nhưng không tốt khi văn bản cần hiểu ngữ cảnh hoặc ý nghĩa từ.                                                                                                   |
| **TF-IDF:** Giống BoW, nhưng mỗi từ được tính thêm **trọng số quan trọng**. <br><br>Từ xuất hiện nhiều trong tài liệu nhưng ít phổ biến trong các tài liệu khác sẽ có trọng số cao hơn. Ví dụ: Trong bài viết về táo, từ "apple" có trọng số cao hơn từ phổ biến như "the". Mã hóa câu "I like apples, I like bananas" thành `[0.3, 0.3, 0.5, 0.4]` (trọng số mỗi từ). | - **Random Forest, KNN, Logistic Regression:** Tạo đặc trưng tốt hơn BoW để phân loại văn bản, ví dụ: Phân tích cảm xúc trong bài đánh giá phim. <br>- **DL (LSTM, GRU):** Tăng hiệu quả trong xử lý chuỗi văn bản, ví dụ: Xây dựng hệ thống gợi ý nội dung liên quan hoặc phân tích dữ liệu khách hàng.                                       |
| **BM25:** Xếp hạng tài liệu dựa trên **độ liên quan với truy vấn**. <br><br>Ngoài trọng số từ (TF-IDF), BM25 còn xét **độ dài tài liệu** để không ưu tiên tài liệu dài một cách không hợp lý. Ví dụ: Với truy vấn "apple banana", tài liệu chứa "apple banana" 3 lần sẽ được ưu tiên hơn tài liệu chứa "apple" 10 lần nhưng không chứa "banana".                       | - **Search Engine:** Xếp hạng tài liệu trước khi đưa vào mô hình DL như BERT, ví dụ: Khi tìm kiếm "best restaurants", tài liệu phù hợp nhất sẽ được ưu tiên. <br>- **Transformer-based Models (BERT, GPT):** BM25 chọn lọc tài liệu liên quan trước, giúp mô hình tập trung xử lý hiệu quả hơn, ví dụ: Tìm kiếm câu trả lời nhanh trên Google. |

### Cách giải thích đơn giản:

- **Bag of Words:** Giống như đếm số lần các từ xuất hiện trong một bài văn. **Không quan tâm câu nói về điều gì.**
- **TF-IDF:** Không chỉ đếm mà còn đánh giá từ nào **quan trọng** hơn trong bài viết. **Nhấn mạnh từ độc đáo.**
- **BM25:** So sánh mức độ liên quan giữa bài viết và **truy vấn tìm kiếm**. **Tập trung vào các từ khớp nhiều và loại bỏ các từ không quan trọng.**

### Cách giải thích đơn giản:

- **Bag of Words:** Giống như đếm số lần các từ xuất hiện trong một bài văn. **Không quan tâm câu nói về điều gì.**
- **TF-IDF:** Không chỉ đếm mà còn đánh giá từ nào **quan trọng** hơn trong bài viết. **Nhấn mạnh từ độc đáo.**
- **BM25:** So sánh mức độ liên quan giữa bài viết và **truy vấn tìm kiếm**. **Tập trung vào các từ khớp nhiều và loại bỏ các từ không quan trọng.**
