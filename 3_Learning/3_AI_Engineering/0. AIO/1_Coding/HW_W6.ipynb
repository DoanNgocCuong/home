{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAY 30: Calculus in Machine Learning- Derivatives in Artificial Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dưới đây là bản **tóm tắt nội dung tài liệu \"AIO2025 - Warmup: Calculus in Machine Learning – Derivatives in AI\" ngày 8/3/2025 của Hoàng-Nguyên Vũ**:\n",
    "\n",
    "### 🔹 **2. Đạo hàm trong học máy**\n",
    "#### 2.1. Định nghĩa và ý nghĩa:\n",
    "- Đạo hàm đo tốc độ thay đổi của hàm số.\n",
    "- Trong AI, giúp điều chỉnh tham số để **giảm lỗi dự đoán** (Loss Function).\n",
    "\n",
    "#### 2.2. **Gradient Descent**:\n",
    "- Thuật toán cập nhật tham số theo hướng ngược lại với gradient:\n",
    "  \n",
    "  `θ_{t+1} = θ_t - α∇J(θ)`\n",
    "  \n",
    "  Trong đó:\n",
    "  - `α` là **learning rate**.\n",
    "  - `∇J(θ)` là **gradient của hàm mất mát**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../image/Day30_Gradient.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 🟪 **Phân tích chi tiết các thành phần trong ảnh:**\n",
    "\n",
    "| Thành phần | Ý nghĩa |\n",
    "|------------|--------|\n",
    "| **Random initial value** | Giá trị khởi tạo ngẫu nhiên của tham số $ w $ – là nơi bắt đầu hành trình của Gradient Descent. |\n",
    "| **Learning step (mũi tên cong)** | Mỗi mũi tên là **1 bước cập nhật** theo công thức: $\\theta_{t+1} = \\theta_t - \\alpha \\cdot \\nabla J(\\theta)$. |\n",
    "| **Hướng đi xuống (bên phải)** | Do đạo hàm ban đầu **âm**, nên trừ đi đạo hàm âm ⇒ **tham số tăng lên**, đi về bên phải. |\n",
    "| **Tiệm cận điểm Minimum** | Các bước nhỏ dần vì gradient gần điểm cực tiểu sẽ nhỏ → mô hình đang hội tụ. |\n",
    "| **Minimum (vị trí màu vàng)** | Là giá trị tối ưu mà mô hình mong muốn đạt được: **loss thấp nhất**. |\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 **Giải thích ý nghĩa đạo hàm ở từng bước:**\n",
    "- Lúc mới bắt đầu: đường dốc mạnh ⇒ **đạo hàm lớn**, bước nhảy lớn.\n",
    "- Gần cực tiểu: đạo hàm nhỏ ⇒ **bước nhảy ngắn lại**, giúp không vượt quá minimum.\n",
    "- Nếu bước quá lớn (learning rate α lớn): có thể **nhảy qua nhảy lại**, không hội tụ.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 Kết luận:\n",
    "Ảnh này cho thấy:\n",
    "> Gradient Descent giống như bạn đang **đi xuống một thung lũng**, bắt đầu từ một điểm trên sườn dốc, từng bước tiến về **đáy thung lũng (minimum)** – nơi chi phí (Cost) nhỏ nhất."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 👉 **Công thức nhắc lại:**\n",
    "$\n",
    "\\theta_{t+1} = \\theta_t - \\alpha \\cdot \\nabla J(\\theta)\n",
    "$\n",
    "- $\\nabla J(\\theta)$: đạo hàm (gradient) của hàm mất mát tại $\\theta$.\n",
    "- $\\alpha$: tốc độ học (learning rate).\n",
    "\n",
    "---\n",
    "\n",
    "### 📉 Khi **đạo hàm dương** ($\\nabla J(\\theta) > 0$):\n",
    "- Điều này nghĩa là **hàm mất mát đang tăng** khi $\\theta$ tăng.\n",
    "- Ta cần **giảm giá trị của $\\theta$** để làm **giảm mất mát**.\n",
    "- Công thức sẽ trừ đi số dương ⇒ $\\theta_{t+1} < \\theta_t$ ⇒ **di chuyển về bên trái** trên đồ thị.\n",
    "\n",
    "### 📈 Khi **đạo hàm âm** ($\\nabla J(\\theta) < 0$):\n",
    "- Hàm mất mát đang **giảm** khi $\\theta$ tăng.\n",
    "- Ta cần **tăng $\\theta$** để tiếp tục làm mất mát giảm.\n",
    "- Trừ đi một số âm ⇒ $\\theta_{t+1} > \\theta_t$ ⇒ **di chuyển về bên phải** trên đồ thị.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Nói đơn giản:\n",
    "- Gradient cho ta biết **nên đi về hướng nào để giảm lỗi**.\n",
    "- Nếu dốc đi lên (đạo hàm dương) → đi xuống (giảm $\\theta$).\n",
    "- Nếu dốc đi xuống (đạo hàm âm) → đi lên (tăng $\\theta$).\n",
    "\n",
    "---\n",
    "\n",
    "💡 **Hình dung như đang leo núi ngược chiều:**\n",
    "> Gradient giống như độ dốc của núi. Gradient dương → bạn đang dốc lên bên phải, nên bạn phải đi ngược (về trái). Gradient âm → bạn dốc xuống bên phải, nên tiếp tục đi sang phải.\n",
    "\n",
    "---\n",
    "\n",
    "Nếu Quốc muốn mình vẽ hình minh họa hoặc làm ví dụ cụ thể với số, mình sẽ làm luôn nhé!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 🔹 **3. Đạo hàm của hàm hợp và Backpropagation**\n",
    "#### 3.1. **Đạo hàm của hàm hợp**:\n",
    "- Mạng nơ-ron gồm nhiều lớp liên tiếp.\n",
    "- Dùng **Chain Rule** để tính đạo hàm tổng hợp của các lớp:\n",
    "  \n",
    "  `dL/dW = dL/da × da/dz × dz/dW`\n",
    "\n",
    "#### 3.2. **Backpropagation**:\n",
    "- Lan truyền ngược dùng Chain Rule để tính toán gradient theo từng lớp:\n",
    "  \n",
    "  `δ(l) = (W(l))ᵗ δ(l+1) ∘ f′(z(l))`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../image/Day30_Backpropagation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 🔍 **What? – Đây là gì?**\n",
    "\n",
    "Đây là **thuật toán Backpropagation** – hay còn gọi là **Lan truyền ngược**.\n",
    "\n",
    "Cụ thể:\n",
    "- Là một phương pháp tính **gradient** (đạo hàm riêng) của hàm mất mát theo từng **trọng số** trong mạng nơ-ron.\n",
    "- Mục tiêu: **Cập nhật trọng số** của mạng nơ-ron sao cho đầu ra (output) càng gần nhãn thật càng tốt.\n",
    "\n",
    "### Trong hình:\n",
    "- **Inputs**: các đầu vào a, b, c, d.\n",
    "- **Hidden layers**: hai lớp ẩn với các node h₁, h₂, h₃, ...\n",
    "- **Output**: một node đầu ra \"o\".\n",
    "- Các **mũi tên cong ngược** đại diện cho **lan truyền gradient ngược** từ output về lại hidden layers để cập nhật trọng số (weights).\n",
    "\n",
    "---\n",
    "\n",
    "## 🤔 **Why? – Tại sao cần Backpropagation?**\n",
    "\n",
    "Trước đây, khi mạng nơ-ron còn mới, người ta **không biết cách huấn luyện hiệu quả** vì không có cách nào lan truyền lỗi từ output về lại các lớp trước.\n",
    "\n",
    "**Backpropagation ra đời** (được phát triển mạnh từ năm 1986 bởi Rumelhart et al.) để:\n",
    "- **Tối ưu hóa** mô hình bằng cách tính toán chính xác các đạo hàm riêng của hàm mất mát với từng trọng số.\n",
    "- Giúp **huấn luyện mạng nơ-ron nhiều lớp** (deep learning) trở nên khả thi và hiệu quả.\n",
    "\n",
    "Nếu không có backpropagation, việc huấn luyện mạng nhiều lớp sẽ rất tốn thời gian hoặc không khả thi.\n",
    "\n",
    "---\n",
    "![](../image/Day30_Backpropagation.png)\n",
    "---\n",
    "\n",
    "## ⚙️ **How? – Cách hoạt động của Backpropagation**\n",
    "\n",
    "Thuật toán gồm 2 giai đoạn chính:\n",
    "\n",
    "### 1. **Forward pass**:\n",
    "- Tính toán đầu ra của mạng dựa trên input và trọng số hiện tại.\n",
    "- Tính **hàm mất mát** giữa output mô hình và giá trị thực tế (ground truth).\n",
    "\n",
    "### 2. **Backward pass (Backpropagation)**:\n",
    "- Tính **đạo hàm của hàm mất mát** theo từng trọng số, sử dụng **Chain Rule**:\n",
    "  \n",
    "  $\n",
    "  \\delta^{(l)} = (W^{(l)})^T \\delta^{(l+1)} \\circ f'(z^{(l)})\n",
    "  $\n",
    "  Trong đó:\n",
    "  - $\\delta^{(l)}$ là gradient ở lớp $l$.\n",
    "  - $W^{(l)}$ là ma trận trọng số từ lớp $l$.\n",
    "  - $f'(z^{(l)})$ là đạo hàm của hàm kích hoạt tại lớp $l$.\n",
    "  - $\\circ$ là phép nhân từng phần tử (Hadamard product).\n",
    "\n",
    "- Dùng gradient đó để **cập nhật trọng số** theo công thức:\n",
    "  \n",
    "  $\n",
    "  W := W - \\alpha \\cdot \\frac{\\partial L}{\\partial W}\n",
    "  $\n",
    "\n",
    "---\n",
    "\n",
    "## 💡 Tóm lại:\n",
    "\n",
    "| Mục | Nội dung |\n",
    "|-----|----------|\n",
    "| **What** | Backpropagation – thuật toán tính gradient lan truyền từ output về các lớp trước. |\n",
    "| **Why** | Giúp mạng nơ-ron học được bằng cách cập nhật chính xác các trọng số. |\n",
    "| **How** | Sử dụng Chain Rule để lan truyền gradient và cập nhật trọng số trong quá trình học. |\n",
    "\n",
    "---\n",
    "\n",
    "Nếu Quốc muốn mình viết một đoạn **minh họa bằng Python**, hoặc giải thích với **ngôn ngữ đơn giản như đang dạy học sinh A2–B1**, mình rất sẵn sàng nhé!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 🔹 **4. Bài tập thực hành Python (ứng dụng đạo hàm)**\n",
    "\n",
    "#### 🔸 **Bài 1. Sigmoid và đạo hàm**\n",
    "- Hàm: `σ(x) = 1 / (1 + e^(-x))`\n",
    "- Đạo hàm: `σ′(x) = σ(x) * (1 - σ(x))`\n",
    "- Tính cho `x = [-2, -1, 0, 1, 2]`\n",
    "\n",
    "#### 🔸 **Bài 2. MSE và đạo hàm**\n",
    "- Loss: `L = 1/n ∑(y_i - ŷ_i)^2`\n",
    "- Gradient: `∂L/∂ŷ_i = -2/n * (y_i - ŷ_i)`\n",
    "- Tính với:  \n",
    "  `y = [3, 5, 2, 8]`, `ŷ = [2.5, 4.8, 2.1, 7.5]`\n",
    "\n",
    "#### 🔸 **Bài 3. ReLU và đạo hàm**\n",
    "- Hàm: `ReLU(x) = max(0, x)`\n",
    "- Đạo hàm:\n",
    "  - `1` nếu `x > 0`\n",
    "  - `0` nếu `x ≤ 0`\n",
    "\n",
    "#### 🔸 **Bài 4. Softmax và đạo hàm**\n",
    "- Hàm: `σ(z)_i = e^{z_i} / ∑ e^{z_j}`\n",
    "- Đạo hàm:\n",
    "  - Nếu `i = j`: `σ_i(1 - σ_i)`\n",
    "  - Nếu `i ≠ j`: `-σ_i * σ_j`\n",
    "- Tính với: `z = [2.0, 1.0, 0.1]`\n",
    "\n",
    "#### 🔸 **Bài 5. Tanh và đạo hàm**\n",
    "- Hàm: `tanh(x) = (e^x - e^{-x}) / (e^x + e^{-x})`\n",
    "- Đạo hàm: `1 - tanh^2(x)`\n",
    "- Tính với: `x = [-2, -1, 0, 1, 2]`\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **Tổng kết**\n",
    "Tài liệu giúp người học nắm vững **ứng dụng đạo hàm trong AI**, từ lý thuyết đến thực hành với Python. Đây là kiến thức nền tảng để hiểu cách **huấn luyện và tối ưu mô hình học máy**, đặc biệt trong **Deep Learning**.\n",
    "\n",
    "---\n",
    "\n",
    "Nếu bạn cần **mã hoàn chỉnh các bài Python**, mình có thể bổ sung luôn nhé!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rất sẵn lòng Quốc ơi! Dưới đây là **bảng chi tiết hơn** nội dung các bài thực hành đạo hàm trong AI, theo đúng format **What – Why – How**, với lời giải thích cụ thể, thực tế, dễ hiểu – rất thích hợp cho học viên mới hoặc dùng để giảng dạy:\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **Bảng chi tiết – 5 bài thực hành đạo hàm trong AI**\n",
    "\n",
    "| **Bài** | **What – Đây là gì?** | **Why – Tại sao cần?** | **How – Dùng ra sao?** |\n",
    "|--------|-------------------------|--------------------------|--------------------------|\n",
    "| **1. Sigmoid** | Là hàm kích hoạt đưa mọi giá trị thực về khoảng (0, 1), hình dạng cong hình chữ S. | - Giúp chuyển output thành xác suất, dùng nhiều trong phân loại nhị phân (như: có bị bệnh không, email có phải spam không).<br>- Làm cho output có thể so sánh được với nhãn thật (label = 0 hoặc 1). | - Với mỗi giá trị đầu vào x, áp dụng sigmoid để ra xác suất.<br>- Đạo hàm giúp tính xem cần điều chỉnh đầu vào bao nhiêu để output tiến gần đúng hơn.<br>- Dùng đạo hàm trong quá trình cập nhật trọng số (backpropagation). |\n",
    "| **2. MSE (Mean Squared Error)** | Hàm mất mát đo độ lệch trung bình bình phương giữa giá trị dự đoán và giá trị thực tế. | - Giúp biết mô hình dự đoán tốt đến đâu (dùng trong hồi quy).<br>- Càng gần giá trị thực tế, MSE càng nhỏ → mô hình càng tốt. | - Tính MSE để đánh giá mô hình.<br>- Dùng đạo hàm để biết mỗi dự đoán sai bao nhiêu và nên điều chỉnh theo hướng nào.<br>- Giá trị dự đoán thấp hơn thực tế → tăng; ngược lại → giảm. |\n",
    "| **3. ReLU (Rectified Linear Unit)** | Hàm kích hoạt giữ giá trị dương, còn giá trị âm thì trả về 0. Rất đơn giản nhưng hiệu quả. | - Làm mạng học nhanh hơn và tránh tình trạng gradient quá nhỏ.<br>- Khi output âm → \"tắt\" neuron đó, giúp mạng đơn giản và ổn định hơn. | - Với mỗi giá trị đầu vào: nếu > 0 thì giữ nguyên, nếu <= 0 thì thành 0.<br>- Đạo hàm giúp xác định neuron nào sẽ được cập nhật (chỉ neuron dương).<br>- Dùng phổ biến trong hidden layers của deep learning. |\n",
    "| **4. Softmax** | Hàm biến vector thành phân phối xác suất: mỗi phần tử là một xác suất, tổng bằng 1. | - Dùng trong bài toán phân loại đa lớp (ví dụ: nhận diện ảnh – chó, mèo, vịt...).<br>- Giúp mô hình nói “tôi tin ảnh này là con mèo với 90%” thay vì chỉ ra số điểm. | - Với vector đầu vào (logits), dùng softmax để biến thành xác suất cho từng lớp.<br>- Đạo hàm của softmax dùng trong kết hợp với cross-entropy để điều chỉnh trọng số sao cho mô hình dự đoán xác suất đúng cao hơn. |\n",
    "| **5. Tanh (Hyperbolic Tangent)** | Hàm kích hoạt đầu ra nằm trong khoảng (-1, 1), giống sigmoid nhưng có tính đối xứng. | - Phù hợp hơn sigmoid trong nhiều trường hợp vì đầu ra có thể âm (dữ liệu đã chuẩn hóa có giá trị âm).<br>- Giúp trung tâm hóa dữ liệu quanh 0 → học nhanh hơn. | - Mỗi đầu vào được đưa qua hàm tanh để tạo ra đầu ra nằm trong (-1, 1).<br>- Đạo hàm tanh dùng để điều chỉnh trọng số như các hàm kích hoạt khác.<br>- Dùng trong hidden layer khi muốn giữ thông tin âm và dương. |\n",
    "\n",
    "---\n",
    "\n",
    "👉 Nếu Quốc muốn mình làm bảng này thành **file Excel, Google Sheet, Markdown hay PDF** để tiện in hoặc chia sẻ với đồng đội, mình cũng làm nhanh cho nhé!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
