- CÃ³ cÃ¡ch nÃ o Ä‘á»ƒ ko cáº§n dÃ¹ng nhiá»u time Ä‘á»ƒ train 

![[Pasted image 20250808202145.png]]


# 1. Motivation: 
- Lazy Learning. Gáº§n thi má»›i há»c vÃ  báº¡n cá»© quyá»ƒn sÃ¡ch 1 vÃ  quyá»ƒn sÃ¡ch 2. 
- New Data point => Biáº¿t Ä‘Æ°á»£c nÃ³ nÃªn náº±m á»Ÿ cuá»‘n 1 hay cuá»‘n 2. 


![[Pasted image 20250808205712.png]]

Dá»° ÃN THáº¬T + CHIA Sáºº + ÄÆ¯á»¢C COACHING + NETWORKIN\

k = 4, 2 Ä‘á», 2 xanh, 

Precision = Sá»‘ dá»± Ä‘oÃ¡n lÃ  ung thÆ° Ä‘Ãºng / tá»•ng sá»‘ dá»± Ä‘oÃ¡n  
Recall = Sá»‘ dá»± Ä‘oÃ¡n lÃ  ung thÆ° Ä‘Ãºng / tá»•ng sá»‘ ung thÆ° thá»±c táº¿


```
nhÆ° vÃ­ dá»¥ cÃ¡i auto ra khÃ´ng bá»‹ cancer á»Ÿ data bá»‹ biased tÃ­nh precision mÃ  máº«u sá»‘ = 0 thÃ¬ output tá»« skikit learn lÃ  gÃ¬ áº¡  
  
**You** 9:33 PM  
@Hieu Ngo ChÆ°a hiá»ƒu cÃ¢u há»i cá»§a báº¡n láº¯m áº¡  
  
**Hieu Ngo** 9:34 PM  
nhÆ° vÃ­ dá»¥ auto ra â€œkhÃ´ng bá»‹ cancerâ€ á»Ÿ data bá»‹ biased vá»«a nÃ£y, lÃºc tÃ­nh precision mÃ  máº«u sá»‘ = 0 thÃ¬ output tá»« skikit learn lÃ  gÃ¬ áº¡  
  
**Äá»©c Nguyá»…n** 9:37 PM  
= 0 háº¿t thÃ¬ nÃ³ rÆ¡i vÃ o máº¥y cÃ¡i trÆ°á»ng há»£p False Negative rá»“i váº«n cá»™ng á»Ÿ máº«u Ã¡ báº¡n, nÃªn máº«u kbh = 0 dc  
  
**You** 9:39 PM (Edited)  
Precision = tá»•ng sá»‘ ung thÆ° Ä‘Ãºng / tá»•ng sá»‘ dá»± Ä‘oÃ¡n ung thÆ°  
+, Vá»›i bÃ i vá»«a nÃ£y khi F(x): y = 0 (tá»©c vá»›i má»i x, dá»± Ä‘oÃ¡n luÃ´n lÃ  0)  
thÃ¬ tá»•ng sá»‘ dá»± Ä‘oÃ¡n ung thÆ° = 0  
  
Ã báº¡n lÃ  váº­y áº¡
```


---



# 1. SÃ¡ng chá»§ nháº­t: 
## 1.1 Code cháº¡y bÃ i cÃ´ng ty done. 11h30
## 1.2. KNN

- KNN thÆ°á»ng sá»­ dá»¥ng loáº¡i khoáº£ng cÃ¡ch nÃ o máº·c Ä‘á»‹nh. Táº¡i sao??? 
=> 

---

# **KNN = K-Nearest Neighbors** 
>  - To know what group you are in, you look at the **k closest people** to you.  
>  - You see what group most of them are in.  
>  - Then you join that group.

> 
Weighted Voting: 
Suppose k = 3
- Neighbor 1 (distance = 1, class = Cat) â†’ weight = 1/1 = 1.0
- Neighbor 2 (distance = 2, class = Dog) â†’ weight = 1/2 = 0.5
- Neighbor 3 (distance = 3, class = Dog) â†’ weight = 1/3 â‰ˆ 0.33

Votes:

- Cat = 1.0
- Dog = 0.5 + 0.33 = 0.83
    

Winner = **Cat** ğŸ±

$w = \frac{1}{d}$  hoáº·c  $w = \frac{1}{d^2}$




---
# Bruce Force and KDTree

```bash
            [P2: x=5]
           /           \
   [P7: y=4]         [P6: y=2]
   /      \           /      \
P1(z=4)  P4(z=9)   P5(z=5)  P3(z=7)

```

+, Difference between. 
+, 
+, 

```
1 sá»‘ cÃ¢u há»i:

1. Vá»›i K = 1 thÃ¬ cÃ¡ch quÃ©t Ä‘i qua háº¿t tá»« node root Ä‘áº¿n cÃ¡c node lÃ¡. Sau Ä‘Ã³ chá»n best, right??

2. Vá»›i K = 2, 3 <= log_2_(6) +1 => ???

3. Vá»›i K > log_2_(6) + 1 ???
```

https://www.geeksforgeeks.org/cpp/kd-trees-in-cpp/
https://viblo.asia/p/gioi-thieu-thuat-toan-kd-trees-nearest-neighbour-search-RQqKLvjzl7z
[2004.04523](https://arxiv.org/pdf/2004.04523)


---

![[Pasted image 20250810154215.png]]



---
## **A) Bag-of-Words (BoW)**

- **What it does:** Counts how many times each word appears in a document.
- **Output:** A vector of raw counts.
> Vocabulary = [â€œcatâ€, â€œdogâ€, â€œeatâ€]  
> Document: â€œcat eat catâ€ â†’ BoW vector = [2, 0, 1]

---

## **B) TF-IDF**

We need a small corpus to compute IDF. Suppose we have 3 documents:

1. `"cat eat cat"`
    
2. `"dog eat dog"`
    
3. `"cat dog eat"`
    

**Step 1 â€“ Term Frequency (TF)** for document 1:

- cat: 2/3 â‰ˆ 0.6667
    
- dog: 0/3 = 0
    
- eat: 1/3 â‰ˆ 0.3333
    

**Step 2 â€“ Inverse Document Frequency (IDF)**:

IDF(t)=logâ¡(TotalÂ docsDocsÂ containingÂ t)\text{IDF}(t) = \log\left(\frac{\text{Total docs}}{\text{Docs containing t}}\right)

- cat: log(3/2) â‰ˆ 0.1761
    
- dog: log(3/2) â‰ˆ 0.1761
    
- eat: log(3/3) = 0
    

**Step 3 â€“ TF-IDF** (TF Ã— IDF):

- cat: 0.6667 Ã— 0.1761 â‰ˆ 0.1174
    
- dog: 0 Ã— 0.1761 = 0
    
- eat: 0.3333 Ã— 0 = 0
    

**TF-IDF vector** â†’ 0.1174,0,00.1174, 0, 0

---
![[Pasted image 20250810162330.png]]

> Ban Ä‘áº§u mÃ¬nh tÆ°á»Ÿng ráº±ng: Khi cáº­p nháº­t centroids lÃ  má»›i cáº­p nháº­t 1 vÃ i nodes, cÃ²n cÃ¡c nodes khÃ¡c ná»¯a. 
> => CÆ¡ mÃ : Ä‘Ãºng ra lÃ : sau khi chá»n 1 centroids thÃ¬ ta cáº§n tÃ­nh toÃ¡n táº¥t cáº£ khoáº£ng cÃ¡ch cÃ¡c Ä‘iá»ƒm cÃ²n láº¡i vá»›i cÃ¡c centroids rá»“i => Sau khi tÃ­nh toÃ¡n chá»‰ cáº§n 1 láº§n centroids khÃ´ng Ä‘á»•i thÃ¬ ta dá»«ng láº¡i ngay . 


