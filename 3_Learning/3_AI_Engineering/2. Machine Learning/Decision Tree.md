
Many Algorithms: 

Bแปฉc แบฃnh nรณi vแป **Decision Tree Induction** (Quรก trรฌnh xรขy dแปฑng cรขy quyแบฟt ฤแปnh), vร liแปt kรช cรกc thuแบญt toรกn phแป biแบฟn dรนng ฤแป tแบกo cรขy. Dฦฐแปi ฤรขy lร giแบฃi thรญch siรชu ฤฦกn giแบฃn:

1. **Hunt's Algorithm**: Mแปt trong nhแปฏng thuแบญt toรกn sแปm nhแบฅt, nhฦฐ "รดng tแป" cแปงa cรกc thuแบญt toรกn cรขy.
    
2. **CART** (Classification and Regression Trees): Mแปt thuแบญt toรกn giรบp tแบกo cรขy ฤแป phรขn loแบกi (phรขn nhรณm) hoแบทc dแปฑ ฤoรกn (dแปฑ bรกo).
    
3. **ID3, C4.5**: Hai phiรชn bแบฃn thuแบญt toรกn nรขng cแบฅp dแบงn. ID3 giแปng nhฦฐ "ngฦฐแปi anh", cรฒn C4.5 lร "ngฦฐแปi em thรดng minh hฦกn".
    
4. **SLIQ, SPRINT**: Hai thuแบญt toรกn nhanh vร phรน hแปฃp vแปi dแปฏ liแปu lแปn. Hรฃy tฦฐแปng tฦฐแปฃng chรบng giแปng nhฦฐ xe ฤua xแปญ lรฝ siรชu tแปc!
    

Tแบฅt cแบฃ cรกc thuแบญt toรกn nรy ฤแปu cรณ mแปฅc tiรชu chung: tแบกo ra cรขy quyแบฟt ฤแปnh giรบp chรบng ta ฤฦฐa ra lแปฑa chแปn hoแบทc dแปฑ ฤoรกn tแปt nhแบฅt tแปซ dแปฏ liแปu.



Dฦฐแปi ฤรขy lร bแบฃng so sรกnh chi tiแบฟt nhฦฐng dแป hiแปu giแปฏa cรกc thuแบญt toรกn trong **Decision Tree Induction**:

|**Thuแบญt toรกn**|**ฤแบทc ฤiแปm nแปi bแบญt**|**ฦฏu ฤiแปm**|**Nhฦฐแปฃc ฤiแปm**|**แปจng dแปฅng phแป biแบฟn**|
|---|---|---|---|---|
|**Hunt's Algorithm**|Thuแบญt toรกn ฤแบงu tiรชn, rแบฅt cฦก bแบฃn|Dแป hiแปu, ฤแบทt nแปn tแบฃng cho cรกc thuแบญt toรกn sau nรy|Khรดng tแปi ฦฐu cho dแปฏ liแปu lแปn, cแบงn cแบฃi tiแบฟn|Nghiรชn cแปฉu lแปch sแปญ, nแปn tแบฃng lรฝ thuyแบฟt|
|**CART**|Phรขn loแบกi vร hแปi quy (chia nhแป nhรกnh dแปฑa vรo dแปฏ liแปu sแป)|Hแป trแปฃ cแบฃ bรi toรกn phรขn loแบกi vร dแปฑ ฤoรกn, dแป triแปn khai|Dแป bแป quรก khแปp (overfitting) nแบฟu khรดng kiแปm soรกt tแปt|Xแปญ lรฝ dแปฏ liแปu sแป vร phรขn loแบกi|
|**ID3**|Dรนng thรดng tin (Entropy) ฤแป chia nhรกnh|Dแป triแปn khai, nhanh vแปi dแปฏ liแปu nhแป|Khรดng xแปญ lรฝ tแปt dแปฏ liแปu thiแบฟu hoแบทc liรชn tแปฅc (chแป dรนng dแปฏ liแปu phรขn loแบกi)|Phรขn loแบกi cฦก bแบฃn, hแปc mรกy trong giรกo dแปฅc|
|**C4.5**|Phiรชn bแบฃn nรขng cแบฅp cแปงa ID3|Xแปญ lรฝ dแปฏ liแปu thiแบฟu, liรชn tแปฅc tแปt hฦกn ID3|Tแปn thแปi gian hฦกn ID3, thuแบญt toรกn phแปฉc tแบกp hฦกn|แปจng dแปฅng hแปc mรกy thแปฑc tแบฟ, dแปฏ liแปu phแปฉc tแบกp|
|**SLIQ**|Tแปi ฦฐu cho dแปฏ liแปu lแปn, dรนng bแบฃng ฤแป chia dแปฏ liแปu hiแปu quแบฃ|Xแปญ lรฝ dแปฏ liแปu lแปn rแบฅt nhanh|Hแบกn chแบฟ khi dแปฏ liแปu phแปฉc tแบกp hoแบทc cรณ nhiแปu thuแปc tรญnh khรดng quan trแปng|Hแป thแปng lแปn nhฦฐ viแปn thรดng|
|**SPRINT**|Tฦฐฦกng tแปฑ SLIQ, nhฦฐng khรดng giแปi hแบกn bแป nhแป|Linh hoแบกt, xแปญ lรฝ dแปฏ liแปu lแปn mร khรดng giแปi hแบกn bแป nhแป|Tแปn tรi nguyรชn khi triแปn khai|Phรขn tรญch dแปฏ liแปu khแปng lแป, Big Data|

### **Giแบฃi thรญch cรกc thuแบญt ngแปฏ chรญnh:**

1. **Phรขn loแบกi**: Gรกn dแปฏ liแปu vรo cรกc nhรณm cแปฅ thแป, vรญ dแปฅ: "email spam hay khรดng spam".
2. **Hแปi quy**: Dแปฑ ฤoรกn giรก trแป sแป, vรญ dแปฅ: "dแปฑ ฤoรกn giรก nhร".
3. **Entropy**: ฤo ฤแป hแปn loแบกn cแปงa dแปฏ liแปu ฤแป tรฌm cรกch chia nhรกnh hiแปu quแบฃ nhแบฅt.
4. **Quรก khแปp (Overfitting)**: Khi cรขy hแปc quรก kแปน dแปฏ liแปu, nhฦฐng khรดng dแปฑ ฤoรกn tแปt dแปฏ liแปu mแปi.

### Tรณm lแบกi:

- Nแบฟu bแบกn xแปญ lรฝ dแปฏ liแปu nhแป vร muแปn ฤฦกn giแบฃn: **ID3, C4.5** lร tแปt nhแบฅt.
- Nแบฟu dแปฏ liแปu lแปn: **SLIQ, SPRINT** sแบฝ nhanh vร hiแปu quแบฃ hฦกn.
- Nแบฟu muแปn cแบฃ phรขn loแบกi vร dแปฑ ฤoรกn: chแปn **CART**



```
Chi tiแบฟt thuแบญt toรกn Hunt's Algorithm - Nhu cแบงu gรฌ mร hแป lแบกi nghฤฉ ra thuแบญt toรกn - Cรกch thแปฉc tฦฐ duy nรo ฤแป hแป nghฤฉ ra thuแบญt toรกn - Thuแบญt toรกn lร gรฌ? -------- Giแบฃi thรญch 1 cรกch siรชu dแป hiแปu
```
### **Hunt's Algorithm โ Giแบฃi thรญch siรชu dแป hiแปu**

#### **1. Nhu cแบงu gรฌ mร hแป nghฤฉ ra thuแบญt toรกn nรy?**

- **Nhu cแบงu:**
    - Vรo thแปi kแปณ ฤแบงu, khi ngฦฐแปi ta cแบงn mแปt cรกch ฤแป **ra quyแบฟt ฤแปnh** tแปซ dแปฏ liแปu, ฤแบทc biแปt lร ฤแป phรขn loแบกi cรกc nhรณm ฤแปi tฦฐแปฃng (vรญ dแปฅ: xรกc ฤแปnh mแปt khรกch hรng cรณ nรชn ฤฦฐแปฃc cแบฅp thแบป tรญn dแปฅng hay khรดng).
    - Hแป muแปn mแปt cรกch **tแปฑ ฤแปng, rรต rรng vร dแป hiแปu** ฤแป giรบp mรกy tรญnh ฤฦฐa ra cรกc quyแบฟt ฤแปnh dแปฑa trรชn dแปฏ liแปu.

**Vรญ dแปฅ:** Mแปt bรกc sฤฉ muแปn chแบฉn ฤoรกn bแปnh dแปฑa trรชn triแปu chแปฉng. Hunt's Algorithm sแบฝ giรบp tแบกo ra mแปt "cรขy quyแบฟt ฤแปnh", nฦกi mแปi cรขu hแปi (triแปu chแปฉng) sแบฝ dแบซn ฤแบฟn cรขu trแบฃ lแปi (chแบฉn ฤoรกn).

---

#### **2. Cรกch thแปฉc tฦฐ duy nรo ฤแป hแป nghฤฉ ra thuแบญt toรกn?**

- **Quan sรกt thแปฑc tแบฟ:**
    
    - Khi con ngฦฐแปi ra quyแบฟt ฤแปnh, hแป thฦฐแปng chia nhแป vแบฅn ฤแป thรnh cรกc bฦฐแปc.
    - Vรญ dแปฅ: "Nแบฟu sแปt cao โ Cรณ thแป lร cรบm. Nแบฟu khรดng sแปt โ Kiแปm tra triแปu chแปฉng khรกc."
- **ร tฦฐแปng chรญnh:**
    
    - Tแบกo ra mแปt cแบฅu trรบc giแปng nhฦฐ **cรขy**:
        - **Gแปc cรขy**: Bแบฏt ฤแบงu tแปซ cรขu hแปi ฤแบงu tiรชn.
        - **Nhรกnh cรขy**: Cรกc lแปฑa chแปn dแปฑa trรชn cรขu trแบฃ lแปi ("Cรณ" hoแบทc "Khรดng").
        - **Lรก cรขy**: Kแบฟt quแบฃ cuแปi cรนng (phรขn loแบกi nhรณm hoแบทc chแบฉn ฤoรกn).

---

#### **3. Thuแบญt toรกn lร gรฌ?**

Hunt's Algorithm hoแบกt ฤแปng theo nguyรชn tแบฏc **ฤแป quy** (giแบฃi quyแบฟt tแปซng phแบงn nhแป cho ฤแบฟn khi xong):

1. **Bแบฏt ฤแบงu tแปซ toรn bแป dแปฏ liแปu**:
    
    - Kiแปm tra xem dแปฏ liแปu cรณ thuแปc cรนng mแปt nhรณm khรดng:
        - Nแบฟu **cรนng nhรณm**: Dแปซng lแบกi, tแบกo mแปt lรก (kแบฟt quแบฃ).
        - Nแบฟu **khรกc nhรณm**: Chia nhแป dแปฏ liแปu thรnh cรกc nhรณm con.
2. **Lแบทp lแบกi vแปi nhรณm con**:
    
    - Xรกc ฤแปnh cรขu hแปi tแปt nhแบฅt (thuแปc tรญnh) ฤแป chia nhรณm con thรnh hai nhรกnh.
3. **Dแปซng lแบกi khi**:
    
    - Nhรณm con ฤรฃ thuแปc cรนng mแปt nhรณm, hoแบทc khรดng cรฒn thuแปc tรญnh nรo ฤแป chia.

---

#### **Vรญ dแปฅ thแปฑc tแบฟ (Siรชu dแป hiแปu):**

**Bรi toรกn:** Dแปฑ ฤoรกn xem ai thรญch xem phim hรnh ฤแปng.

- **Bฦฐแปc 1 (Gแปc cรขy):** Hแปi "Ngฦฐแปi nรy cรณ dฦฐแปi 30 tuแปi khรดng?"
    
    - Nแบฟu **Cรณ**: Hแป thรญch phim hรnh ฤแปng. (Kแบฟt quแบฃ 1)
    - Nแบฟu **Khรดng**: Tiแบฟp tแปฅc hแปi.
- **Bฦฐแปc 2 (Nhรกnh):** Hแปi "Ngฦฐแปi nรy cรณ thรญch thแป thao khรดng?"
    
    - Nแบฟu **Cรณ**: Hแป thรญch phim hรnh ฤแปng. (Kแบฟt quแบฃ 2)
    - Nแบฟu **Khรดng**: Hแป khรดng thรญch phim hรnh ฤแปng. (Kแบฟt quแบฃ 3)

Kแบฟt quแบฃ: Tแบกo ra mแปt cรขy quyแบฟt ฤแปnh ฤฦกn giแบฃn tแปซ cรกc cรขu hแปi.

---

#### **Tรณm gแปn thuแบญt toรกn Hunt's Algorithm:**

- **Nhu cแบงu:** Ra quyแบฟt ฤแปnh tแปฑ ฤแปng tแปซ dแปฏ liแปu.
- **Tฦฐ duy:** Chia nhแป vแบฅn ฤแป giแปng cรกch con ngฦฐแปi tฦฐ duy.
- **Hoแบกt ฤแปng:** Chia nhแป dแปฏ liแปu bแบฑng cรกc cรขu hแปi ฤแบฟn khi ฤแบกt kแบฟt quแบฃ rรต rรng.

Cรขy quyแบฟt ฤแปnh tแปซ thuแบญt toรกn Hunt's giแปng nhฦฐ mแปt "trแปฃ lรฝ แบฃo" giรบp bแบกn ฤฦฐa ra quyแบฟt ฤแปnh dแป dรng tแปซ thรดng tin cรณ sแบตn!


## Trest Condition for Continous Attribute 

## Measute of 

Bแปฉc แบฃnh nรณi vแป cรกc cรกch ฤo "ฤแป khรดng thuแบงn khiแบฟt" (Node Impurity) cแปงa mแปt nรบt trong cรขy quyแบฟt ฤแปnh. ฤรขy lร cรกch ฤแป ฤรกnh giรก xem dแปฏ liแปu tแบกi nรบt cรณ ฤฦฐแปฃc phรขn chia tแปt chฦฐa.

### **1. Gini Index**

- **Cรดng thแปฉc:** Gini=1โโpi2Gini = 1 - \sum p_i^2
- **ร nghฤฉa:** Nแบฟu cรกc lแปp (nhรณm) trong dแปฏ liแปu chia ฤแปu, Gini sแบฝ cao. Nแบฟu chแป cรณ 1 lแปp, Gini sแบฝ thแบฅp.
- **Vรญ dแปฅ dแป hiแปu:** Nแบฟu cรณ 2 lแปp, mแปi lแปp 50%, Gini = 0.5. Nแบฟu chแป 1 lแปp chiแบฟm 100%, Gini = 0.

---

### **2. Entropy**

- **Cรดng thแปฉc:** Entropy=โโpilogโก2(pi)Entropy = - \sum p_i \log_2(p_i)
- **ร nghฤฉa:** ฤo "ฤแป hแปn loแบกn". Nแบฟu cรกc lแปp chia ฤแปu, entropy sแบฝ cao (hแปn loแบกn). Nแบฟu chแป cรณ 1 lแปp, entropy = 0.
- **Vรญ dแปฅ dแป hiแปu:** 50% - 50% giแปฏa 2 lแปp, entropy = 1 (cao). Nแบฟu chแป cรณ 1 lแปp 100%, entropy = 0 (รญt hแปn loแบกn).

---

### **3. Misclassification Error**

- **Cรดng thแปฉc:** Error=1โmaxโก(pi)Error = 1 - \max(p_i)
- **ร nghฤฉa:** Tแปท lแป dแปฏ liแปu bแป phรขn loแบกi sai tแบกi nรบt. Nแบฟu mแปt lแปp chiแบฟm phแบงn lแปn, lแปi sแบฝ thแบฅp.
- **Vรญ dแปฅ dแป hiแปu:** Nแบฟu lแปp lแปn nhแบฅt chiแบฟm 70%, lแปi = 1 - 0.7 = 0.3.

---

### **Tรณm lแบกi:**

- **Gini** vร **Entropy** dรนng ฤแป ฤo ฤแป khรดng thuแบงn vร quyแบฟt ฤแปnh nรชn chia nhรกnh tiแบฟp hay dแปซng lแบกi.
- **Misclassification Error** ฤฦกn giแบฃn hรณa ฤแป xem tแปท lแป sai lร bao nhiรชu.

Chแปn cรกch nรo tรนy vรo yรชu cแบงu thuแบญt toรกn (nhanh, chรญnh xรกc hay dแป tรญnh).



![[Pasted image 20241127102159.png]]


### **Bแปฉc แบฃnh trรชn nรณi vแป gรฌ vร ฤang lรm gรฌ?**

#### **Bแปฉc แบฃnh nรณi vแป:**

- **Cรกch tรญnh Gini Index**: ฤรขy lร mแปt chแป sแป ฤฦฐแปฃc dรนng ฤแป ฤo "ฤแป lแปn xแปn" (impurity) cแปงa dแปฏ liแปu trong mแปt nรบt (node) cแปงa cรขy quyแบฟt ฤแปnh (Decision Tree).
- **Mแปฅc tiรชu:** Giรบp chแปn thuแปc tรญnh nรo sแบฝ ฤฦฐแปฃc dรนng ฤแป chia dแปฏ liแปu tiแบฟp theo.

---

#### **Bแปฉc แบฃnh ฤang lรm task gรฌ?**

- **Task:** **Tรญnh Gini Index** cho cรกc nรบt khรกc nhau, dแปฑa trรชn tแบงn suแบฅt dแปฏ liแปu thuแปc tแปซng lแปp (C1 vร C2) trong nรบt ฤรณ.
- **Mแปฅc ฤรญch:** So sรกnh Gini Index cแปงa cรกc nรบt ฤแป biแบฟt nรบt nรo "sแบกch" hฦกn (รญt lแปn xแปn hฦกn). ฤiแปu nรy giรบp cรขy quyแบฟt ฤแปnh biแบฟt nรชn dแปซng hay tiแบฟp tแปฅc chia dแปฏ liแปu.

---

### **Cรกch dแป hiแปu hฦกn:**

1. **Hiแปu Gini Index nhฦฐ "ฤแป lแปn xแปn":**
    
    - Gini Index = 0: Dแปฏ liแปu sแบกch, tแปฉc tแบฅt cแบฃ ฤแปu thuแปc vแป mแปt lแปp duy nhแบฅt. (Vรญ dแปฅ: Tแบฅt cแบฃ ฤแปu lร C2, khรดng cรณ C1).
    - Gini Index cรng cao: Dแปฏ liแปu lแปn xแปn hฦกn, nhiแปu lแปp pha trแปn lแบซn nhau.
2. **Task ฤang thแปฑc hiแปn:**
    
    - Bฦฐแปc 1: ฤแบฟm sแป lฦฐแปฃng dแปฏ liแปu trong mแปi lแปp C1,C2C1, C2 cแปงa tแปซng nรบt.
    - Bฦฐแปc 2: Tรญnh Gini Index cho tแปซng nรบt theo cรดng thแปฉc.
    - Bฦฐแปc 3: So sรกnh cรกc Gini Index ฤแป biแบฟt nรบt nรo tแปt hฦกn (รญt lแปn xแปn hฦกn).

---

### **Vรญ dแปฅ giแบฃi thรญch tแปซ bแปฉc แบฃnh:**

- **Nรบt 1 (C1 = 0, C2 = 6):**
    - Tแบฅt cแบฃ dแปฏ liแปu ฤแปu thuแปc lแปp C2 โ Khรดng lแปn xแปn โ Gini = 0 (hoรn hแบฃo).
- **Nรบt 2 (C1 = 1, C2 = 5):**
    - Mแปt chรบt lแปn xแปn: Cรณ 1 dแปฏ liแปu thuแปc lแปp C1, 5 dแปฏ liแปu thuแปc lแปp C2 โ Gini = 0.278.
- **Nรบt 3 (C1 = 2, C2 = 4):**
    - Lแปn xแปn hฦกn: Cรณ 2 dแปฏ liแปu thuแปc lแปp C1 vร 4 dแปฏ liแปu thuแปc lแปp C2 โ Gini = 0.444.

**Kแบฟt luแบญn:** Nรบt 1 sแบกch nhแบฅt (Gini = 0), nรบt 3 lแปn xแปn nhแบฅt (Gini = 0.444).

---

#### **Mแปฅc ฤรญch cuแปi cรนng:**

- **Dรนng Gini Index** ฤแป quyแบฟt ฤแปnh xem nรชn chia nรบt nhฦฐ thแบฟ nรo sao cho cรขy quyแบฟt ฤแปnh "thรดng minh" nhแบฅt, tแปฉc lร cรกc nhรณm sau khi chia cรng ฤแปng nhแบฅt (รญt lแปn xแปn) cรng tแปt.


==========

### **Bแปฉc แบฃnh trรชn nรณi vแป viแปc tรญnh Gini Index cho dแปฏ liแปu liรชn tแปฅc**

#### **1. ร chรญnh cแปงa bแปฉc แบฃnh:**

- Khi cรณ **dแปฏ liแปu liรชn tแปฅc** (vรญ dแปฅ: Thu nhแบญp hรng nฤm), ta phแบฃi tรฌm giรก trแป tแปi ฦฐu ฤแป chia dแปฏ liแปu thรnh hai nhรณm (nhรกnh) dแปฑa trรชn **Gini Index**.
- Task: Tรฌm giรก trแป vv tแปt nhแบฅt ฤแป chia dแปฏ liแปu sao cho Gini Index nhแป nhแบฅt (nhรณm cรng "sแบกch" cรng tแปt).

---

#### **2. Dแปฏ liแปu liรชn tแปฅc xแปญ lรฝ nhฦฐ thแบฟ nรo?**

- **Dแปฏ liแปu liรชn tแปฅc** khรดng thแป chia thแบณng thรnh nhรณm rแปi rแบกc, nรชn cแบงn tแบกo ngฦฐแปกng (threshold) vv.
- Mแปi giรก trแป vv sแบฝ tแบกo hai nhรณm:
    - Nhรณm 1: AโคvA \leq v
    - Nhรณm 2: A>vA > v
- Vรญ dแปฅ: **Annual Income (Thu nhแบญp hรng nฤm)** vแปi ngฦฐแปกng v=80v = 80:
    - Nhรณm 1: Thu nhแบญp โค80\leq 80
    - Nhรณm 2: Thu nhแบญp >80> 80

---

#### **3. Task cแปฅ thแป trong แบฃnh:**

- Bแปฉc แบฃnh ฤang xรฉt **thu nhแบญp hรng nฤm** vร chia nhรณm theo giรก trแป v=80v = 80.
    
- **Bแบฃng dแปฏ liแปu vรญ dแปฅ:**
    
    - Cรกc cแปt: ID, Thu nhแบญp, ฤรฃ vแปก nแปฃ (Defaulted: Yes/No).
    - Hรng 7-10 ฤฦฐแปฃc chia lรm 2 nhรณm:
        - Aโค80A \leq 80: 0 ngฦฐแปi vแปก nแปฃ, 3 ngฦฐแปi khรดng vแปก nแปฃ.
        - A>80A > 80: 3 ngฦฐแปi vแปก nแปฃ, 4 ngฦฐแปi khรดng vแปก nแปฃ.
- **Gini Index** ฤฦฐแปฃc tรญnh cho tแปซng cรกch chia vv, sau ฤรณ chแปn vv sao cho Gini Index nhแป nhแบฅt.
    

---

#### **4. Cรกc รฝ quan trแปng:**

1. **Sแป lฦฐแปฃng giรก trแป vv:** Sแป giรก trแป chia cรณ thแป = sแป giรก trแป duy nhแบฅt cแปงa thuแปc tรญnh.
2. **Quรฉt toรn bแป dแปฏ liแปu:** Vแปi mแปi vv, tรญnh Gini Index, rแปi chแปn vv tแปt nhแบฅt (Gini nhแป nhแบฅt).
3. **Nhฦฐแปฃc ฤiแปm:**
    - Cแบงn nhiแปu phรฉp tรญnh (scan qua tแบฅt cแบฃ giรก trแป vv).
    - Tแปn thแปi gian nแบฟu dแปฏ liแปu lแปn hoแบทc nhiแปu thuแปc tรญnh.

---

#### **5. Kแบฟt luแบญn dแป hiแปu:**

- Bแปฉc แบฃnh minh hแปa cรกch **xแปญ lรฝ thuแปc tรญnh liรชn tแปฅc** trong cรขy quyแบฟt ฤแปnh:
    - Chia dแปฏ liแปu thรnh hai nhรณm dแปฑa trรชn ngฦฐแปกng vv.
    - Tรญnh Gini Index cho mแปi cรกch chia.
    - Chแปn ngฦฐแปกng tแปt nhแบฅt (nhรณm cรng "sแบกch" cรng tแปt).
- ฤรขy lร mแปt bฦฐแปc trong thuแบญt toรกn ฤแป tแบกo ra cรขy quyแบฟt ฤแปnh hiแปu quแบฃ!

### **Cรขu hแปi: Nแบฟu ฤรฃ cรณ Gini, tแบกi sao cแบงn Entropy?**

Cแบฃ **Gini Index** vร **Entropy** ฤแปu dรนng ฤแป ฤo "ฤแป lแปn xแปn" (impurity) trong dแปฏ liแปu, giรบp cรขy quyแบฟt ฤแปnh (Decision Tree) biแบฟt cรกch chia dแปฏ liแปu sao cho cรกc nhรณm trแป nรชn "sแบกch" nhแบฅt. Nhฦฐng hai phฦฐฦกng phรกp nรy cรณ **sแปฑ khรกc biแปt** trong cรกch tรญnh toรกn vร แปฉng dแปฅng. Dฦฐแปi ฤรขy lร lรฝ do tแบกi sao chรบng ta vแบซn cแบงn Entropy:

---

### **1. Khรกc biแปt chรญnh giแปฏa Gini vร Entropy**

|**ฤแบทc ฤiแปm**|**Gini Index**|**Entropy**|
|---|---|---|
|**Cรกch tรญnh**|Dแป tรญnh hฦกn, cรดng thแปฉc ฤฦกn giแบฃn hฦกn|Phแปฉc tแบกp hฦกn, dรนng logarit|
|**ร nghฤฉa**|ฤo lฦฐแปng sแปฑ khรดng ฤแปng nhแบฅt trแปฑc tiแบฟp|ฤo lฦฐแปng mแปฉc ฤแป "hแปn loแบกn" trong dแปฏ liแปu|
|**Phแบกm vi giรก trแป**|Luรดn tแปซ 0 ฤแบฟn 0.5 (vแปi 2 lแปp cรขn bแบฑng)|Luรดn tแปซ 0 ฤแบฟn 1|
|**Tแปc ฤแป tรญnh toรกn**|Nhanh hฦกn|Chแบญm hฦกn do sแปญ dแปฅng logarit|

---

### **2. Tแบกi sao vแบซn cแบงn Entropy?**

#### **a) Trong mแปt sแป bรi toรกn, Entropy cรณ รฝ nghฤฉa logic hฦกn:**

- Entropy khรดng chแป ฤo mแปฉc ฤแป lแปn xแปn mร cรฒn thแป hiแปn lฦฐแปฃng thรดng tin cแบงn ฤแป giแบฃm sแปฑ hแปn loแบกn ฤรณ.
- **Vรญ dแปฅ:** Trong truyแปn thรดng (Information Theory), Entropy ฤฦฐแปฃc dรนng ฤแป ฤo lฦฐแปฃng thรดng tin trong mแปt hแป thแปng. Nแบฟu bรi toรกn cรณ liรชn quan ฤแบฟn viแปc **giแบฃm bแปt sแปฑ khรดng chแบฏc chแบฏn** (uncertainty), Entropy phรน hแปฃp hฦกn.

#### **b) Tรนy vรo thuแบญt toรกn hแปc mรกy:**

- **C4.5** (mแปt thuแบญt toรกn cรขy quyแบฟt ฤแปnh phแป biแบฟn) sแปญ dแปฅng Entropy thay vรฌ Gini Index ฤแป chแปn thuแปc tรญnh, vรฌ nรณ muแปn tแปi ฤa hรณa "thรดng tin ฤแบกt ฤฦฐแปฃc" (Information Gain), vแปn ฤฦฐแปฃc tรญnh tแปซ Entropy.

#### **c) Gini vร Entropy cรณ kแบฟt quแบฃ khรกc nhau trong mแปt sแป trฦฐแปng hแปฃp:**

- **Gini Index** tแปi ฦฐu hรณa viแปc phรขn loแบกi ngay lแบญp tแปฉc (quick split), phรน hแปฃp khi bแบกn cแบงn tแปc ฤแป.
- **Entropy** lแบกi quan tรขm nhiแปu hฦกn ฤแบฟn chแบฅt lฦฐแปฃng cแปงa thรดng tin, phรน hแปฃp trong cรกc bรi toรกn phแปฉc tแบกp.

---

### **3. Khi nรo nรชn dรนng Gini? Khi nรo nรชn dรนng Entropy?**

#### **Dรนng Gini khi:**

- Cแบงn thuแบญt toรกn nhanh, รญt tรญnh toรกn (nhฦฐ trong **CART**).
- Khรดng cแบงn giแบฃi thรญch sรขu vแป lฦฐแปฃng thรดng tin, chแป quan tรขm ฤแบฟn viแปc giแบฃm ฤแป lแปn xแปn.

#### **Dรนng Entropy khi:**

- Cแบงn ฤรกnh giรก kแปน lฦฐแปกng mแปฉc ฤแป "thรดng tin ฤแบกt ฤฦฐแปฃc" cแปงa tแปซng bฦฐแปc chia.
- Thuแบญt toรกn cแปฅ thแป yรชu cแบงu (nhฦฐ **ID3**, **C4.5**).
- Bรi toรกn liรชn quan ฤแบฟn giแบฃm sแปฑ khรดng chแบฏc chแบฏn, cแบงn sแปฑ chรญnh xรกc cao hฦกn vแป logic thรดng tin.

---

### **4. Kแบฟt luแบญn**

Gini Index thฦฐแปng **nhanh hฦกn vร dแป tรญnh toรกn**, nhฦฐng Entropy cรณ รฝ nghฤฉa **toรกn hแปc sรขu sแบฏc hฦกn** trong cรกc bรi toรกn vแป thรดng tin. Vรฌ vแบญy, tรนy vรo bรi toรกn vร thuแบญt toรกn, chรบng ta cรณ thแป chแปn cรกi phรน hแปฃp. **Cแบฃ hai ฤแปu khรดng thay thแบฟ nhau hoรn toรn, mร hแป trแปฃ nhau trong cรกc ngแปฏ cแบฃnh khรกc nhau.**



Decision Tree Based
Classification
!Advantages:
โ Relatively inexpensive to construct
โ Extremely fast at classifying unknown records
โ Easy to interpret for small-sized trees
โ Robust to noise (especially when methods to avoid overfitting are
employed)
โ Can easily handle redundant attributes
โ Can easily handle irrelevant attributes (unless the attributes are interacting)
!Disadvantages: .
โ Due to the greedy nature of splitting criterion, interacting attributes (that
can distinguish between classes together but not individually) may be
passed over in favor of other attributed that are less discriminating.
โ Each decision boundary involves only a single attribute



### **Decision Tree Based Classification: Advantages and Disadvantages**

#### **Advantages (ฤiแปm mแบกnh):**

1. **Relatively inexpensive to construct:**
    
    - Xรขy dแปฑng cรขy quyแบฟt ฤแปnh khรดng tแปn quรก nhiแปu tรi nguyรชn hoแบทc thแปi gian.
    - **Lแปฃi รญch:** Nhanh chรณng triแปn khai, ฤแบทc biแปt vแปi dแปฏ liแปu vแปซa vร nhแป.
2. **Extremely fast at classifying unknown records:**
    
    - Khi ฤรฃ xรขy xong cรขy, viแปc phรขn loแบกi (classification) rแบฅt nhanh vรฌ chแป cแบงn ฤi theo cรกc nhรกnh.
    - **Lแปฃi รญch:** Lรฝ tฦฐแปng cho แปฉng dแปฅng thแปi gian thแปฑc.
3. **Easy to interpret for small-sized trees:**
    
    - Cรขy nhแป dแป hiแปu, giแปng nhฦฐ mแปt loแบกt cรกc cรขu hแปi โcรณ/khรดngโ giรบp giแบฃi thรญch quyแบฟt ฤแปnh.
    - **Lแปฃi รญch:** Phรน hแปฃp khi cแบงn giแบฃi thรญch rรต rรng cho con ngฦฐแปi (giรกo dแปฅc, kinh doanh).
4. **Robust to noise (khi cรณ kแปน thuแบญt chแปng overfitting):**
    
    - Cรขy quyแบฟt ฤแปnh cรณ thแป chแปu ฤฦฐแปฃc dแปฏ liแปu nhiแปu, ฤแบทc biแปt khi sแปญ dแปฅng cรกc biแปn phรกp giแบฃm overfitting (nhฦฐ pruning - tแปa cรขy).
    - **Lแปฃi รญch:** Tฤng ฤแป tin cแบญy khi dแปฏ liแปu khรดng hoรn hแบฃo.
5. **Can easily handle redundant attributes:**
    
    - Nแบฟu cรณ thuแปc tรญnh dฦฐ thแปซa (lแบทp lแบกi), cรขy vแบซn hoแบกt ฤแปng tแปt vร tแปฑ ฤแปng loแบกi bแป nhแปฏng thuแปc tรญnh khรดng cแบงn thiแบฟt.
    - **Lแปฃi รญch:** Khรดng cแบงn xแปญ lรฝ trฦฐแปc quรก nhiแปu.
6. **Can easily handle irrelevant attributes:**
    
    - Cรกc thuแปc tรญnh khรดng liรชn quan (irrelevant attributes) thฦฐแปng khรดng แบฃnh hฦฐแปng nhiแปu vรฌ cรขy chแป chแปn nhแปฏng thuแปc tรญnh hแปฏu รญch nhแบฅt.

---

#### **Disadvantages (ฤiแปm yแบฟu):**

1. **Greedy nature of splitting criterion:**
    
    - Do thuแบญt toรกn chia nhรกnh (splitting) theo phฦฐฦกng phรกp "tham lam" (greedy), cรขy cรณ thแป **bแป qua cรกc thuแปc tรญnh tฦฐฦกng tรกc**.
        - Vรญ dแปฅ: Hai thuแปc tรญnh AA vร BB khรดng phรขn loแบกi tแปt khi xem riรชng lแบป, nhฦฐng kแบฟt hแปฃp lแบกi thรฌ mแบกnh mแบฝ. Cรขy cรณ thแป khรดng chแปn chรบng.
2. **Each decision boundary involves only a single attribute:**
    
    - Cรกc quyแบฟt ฤแปnh phรขn chia chแป dแปฑa trรชn **mแปt thuแปc tรญnh tแบกi mแปt thแปi ฤiแปm** (mแปi ฤฦฐแปng biรชn lร 1 chiแปu).
    - **Hแบกn chแบฟ:** Vแปi dแปฏ liแปu phแปฉc tแบกp (ฤa chiแปu, cแบงn kแบฟt hแปฃp nhiแปu thuแปc tรญnh cรนng lรบc), cรขy cรณ thแป khรดng ฤแปง mแบกnh ฤแป phรขn biแปt cรกc lแปp.

---

### **Khi nรo nรชn dรนng Decision Trees?**

- **Dรนng khi:**
    
    - Dแปฏ liแปu ฤฦกn giแบฃn hoแบทc trung bรฌnh.
    - Cแบงn giแบฃi thรญch rรต rรng cรกch ฤฦฐa ra quyแบฟt ฤแปnh.
    - Cรณ nhiแปu thuแปc tรญnh dฦฐ thแปซa hoแบทc khรดng liรชn quan.
- **Khรดng nรชn dรนng khi:**
    
    - Dแปฏ liแปu cรณ mแปi quan hแป phแปฉc tแบกp giแปฏa cรกc thuแปc tรญnh (nhฦฐ tฦฐฦกng tรกc giแปฏa cรกc chiแปu).
    - Muแปn mแปt mรด hรฌnh phแปฉc tแบกp hฦกn vแปi ฤแป chรญnh xรกc cao hฦกn (khi ฤรณ cรณ thแป dรนng Random Forest, XGBoost).

---

### **Tรณm gแปn:**

- **ฦฏu ฤiแปm:** Dแป dรนng, nhanh, thรขn thiแปn vแปi dแปฏ liแปu khรดng hoรn hแบฃo.
- **Nhฦฐแปฃc ฤiแปm:** Hแบกn chแบฟ trong viแปc xแปญ lรฝ thuแปc tรญnh phแปฉc tแบกp vร tฦฐฦกng tรกc.



### **Giแบฃi thรญch siรชu ฤฦกn giแบฃn vแป hai hรฌnh แบฃnh**

#### **Hรฌnh แบฃnh ฤแบงu tiรชn: "Handling Interactions"**

1. **ร chรญnh:**
    
    - Hai thuแปc tรญnh XX vร YY **tฦฐฦกng tรกc vแปi nhau** ฤแป phรขn biแปt giแปฏa cรกc ฤiแปm xanh (+) vร ฤแป (o).
    - Nhฦฐng nแบฟu xรฉt riรชng XX hoแบทc YY, chรบng ฤแปu cรณ entropy cao (0.99) โ Khรดng giรบp phรขn biแปt rรต giแปฏa hai lแปp.
2. **Vแบฅn ฤแป:**
    
    - Quyแบฟt ฤแปnh dแปฑa trรชn tแปซng thuแปc tรญnh riรชng lแบป (XX hoแบทc YY) khรดng hiแปu quแบฃ vรฌ chรบng chแป cรณ รฝ nghฤฉa khi kแบฟt hแปฃp vแปi nhau.
3. **Kแบฟt luแบญn:**
    
    - Decision Tree gแบทp khรณ khฤn trong viแปc xแปญ lรฝ cรกc thuแปc tรญnh cรณ sแปฑ tฦฐฦกng tรกc phแปฉc tแบกp mร khรดng phรขn biแปt tแปt nแบฟu xรฉt riรชng rแบฝ.

---

#### **Hรฌnh แบฃnh thแปฉ hai: "Handling Interactions Given Irrelevant Attributes"**

1. **ร chรญnh:**
    
    - Mแปt thuแปc tรญnh mแปi ZZ ฤฦฐแปฃc thรชm vรo (ngแบซu nhiรชn vร khรดng liรชn quan).
    - ZZ cรณ entropy thแบฅp hฦกn (0.980.98) so vแปi XX vร YY (0.990.99).
    - Do ฤรณ, thuแบญt toรกn cรขy quyแบฟt ฤแปnh sแบฝ chแปn ZZ lรm thuแปc tรญnh ฤแป chia, dรน nรณ **khรดng liรชn quan ฤแบฟn bรi toรกn**.
2. **Vแบฅn ฤแป:**
    
    - Cรขy quyแบฟt ฤแปnh bแป "lแปซa" bแปi ZZ, chแปn thuแปc tรญnh kรฉm liรชn quan hฦกn chแป vรฌ entropy cแปงa ZZ thแบฅp hฦกn.
3. **Kแบฟt luแบญn:**
    
    - Thuแบญt toรกn cรขy quyแบฟt ฤแปnh cรณ thแป **chแปn sai thuแปc tรญnh** khi cรณ thuแปc tรญnh nhiแปu (khรดng liรชn quan).

---

### **Tรณm lแบกi:**

- Hรฌnh 1: Cรขy quyแบฟt ฤแปnh khรณ xแปญ lรฝ cรกc thuแปc tรญnh cรณ tฦฐฦกng tรกc phแปฉc tแบกp (X,YX, Y).
- Hรฌnh 2: Cรขy quyแบฟt ฤแปnh dแป bแป แบฃnh hฦฐแปng bแปi thuแปc tรญnh nhiแปu (ZZ) vรฌ khรดng phรขn biแปt ฤฦฐแปฃc thuแปc tรญnh thแปฑc sแปฑ hแปฏu รญch.

ฤรขy lร hแบกn chแบฟ cแปงa Decision Trees khi xแปญ lรฝ cรกc bรi toรกn phแปฉc tแบกp hoแบทc cรณ nhiแปu dแปฏ liแปu khรดng liรชn quan.


===========


### **Giแบฃi phรกp cho vแบฅn ฤแป cแปงa Decision Tree**

#### **1. Sแปญ dแปฅng Ensemble Methods (Phฦฐฦกng phรกp tแบญp hแปฃp nhiแปu cรขy)**

Thay vรฌ dแปฑa vรo **mแปt cรขy quyแบฟt ฤแปnh duy nhแบฅt**, cรกc phฦฐฦกng phรกp **ensemble** kแบฟt hแปฃp nhiแปu cรขy ฤแป cแบฃi thiแปn hiแปu suแบฅt vร giแบฃm cรกc vแบฅn ฤแป liรชn quan ฤแบฟn nhiแปu hoแบทc tฦฐฦกng tรกc thuแปc tรญnh.

- **Random Forest:**
    
    - Kแบฟt hแปฃp nhiแปu cรขy quyแบฟt ฤแปnh bแบฑng cรกch huแบฅn luyแปn chรบng trรชn cรกc tแบญp dแปฏ liแปu ngแบซu nhiรชn.
    - Mแปi cรขy chแป xem xรฉt mแปt tแบญp con cแปงa cรกc thuแปc tรญnh โ giแบฃm tรกc ฤแปng cแปงa thuแปc tรญnh nhiแปu.
    - Kแบฟt quแบฃ cuแปi cรนng ฤฦฐแปฃc lแบฅy trung bรฌnh (cho hแปi quy) hoแบทc dแปฑa trรชn sแป phiแบฟu (cho phรขn loแบกi).
- **Gradient Boosting (e.g., XGBoost, LightGBM):**
    
    - Xรขy dแปฑng cรกc cรขy liรชn tiแบฟp, mแปi cรขy tแบญp trung sแปญa lแปi tแปซ cรขy trฦฐแปc ฤรณ.
    - Hiแปu quแบฃ cao khi xแปญ lรฝ thuแปc tรญnh nhiแปu vร tฦฐฦกng tรกc phแปฉc tแบกp.

---

#### **2. Feature Engineering (Xแปญ lรฝ thuแปc tรญnh thแปง cรดng trฦฐแปc khi dรนng cรขy)**

- **Tแบกo thuแปc tรญnh kแบฟt hแปฃp:**
    
    - Nแบฟu XX vร YY tฦฐฦกng tรกc vแปi nhau, hรฃy tแบกo mแปt thuแปc tรญnh mแปi, vรญ dแปฅ: XรYX \times Y hoแบทc X+YX + Y. ฤiแปu nรy giรบp cรขy hiแปu ฤฦฐแปฃc tฦฐฦกng tรกc giแปฏa cรกc thuแปc tรญnh.
- **Loแบกi bแป thuแปc tรญnh nhiแปu:**
    
    - Sแปญ dแปฅng cรกc kแปน thuแบญt lแปc thuแปc tรญnh (feature selection) ฤแป loแบกi bแป ZZ hoแบทc cรกc thuแปc tรญnh khรดng liรชn quan trฦฐแปc khi xรขy dแปฑng cรขy.

---

#### **3. Regularization (Phรขn nhรกnh hแปฃp lรฝ hฦกn)**

- **Giแบฃm overfitting bแบฑng pruning (tแปa cรขy):**
    
    - Loแบกi bแป cรกc nhรกnh dฦฐ thแปซa hoแบทc kรฉm quan trแปng sau khi cรขy ฤฦฐแปฃc xรขy dแปฑng.
    - Vรญ dแปฅ: Tแปa nhแปฏng nhรกnh mร thuแปc tรญnh nhฦฐ ZZ ฤฦฐแปฃc chแปn nhฦฐng khรดng ฤรณng gรณp nhiแปu vรo viแปc giแบฃm lแปi.
- **Giแปi hแบกn ฤแป sรขu cแปงa cรขy (max depth):**
    
    - ฤแบทt giแปi hแบกn cho sแป lฦฐแปฃng cแบฅp cแปงa cรขy ฤแป giแบฃm tรกc ฤแปng cแปงa cรกc thuแปc tรญnh nhiแปu.

---

#### **4. Chแปn Splitting Criteria Tแปt Hฦกn**

- **Use CART (Classification and Regression Trees):**
    
    - CART khรดng chแป sแปญ dแปฅng Gini Index mร cรฒn tแปi ฦฐu cรกch chia dแปฏ liแปu ฤแป giแบฃm ฤแป lแปn xแปn vร tฤng tรญnh hแปฏu รญch cแปงa thuแปc tรญnh.
- **Consider Feature Importance Metrics:**
    
    - Sแปญ dแปฅng cรกc chแป sแป nhฦฐ **Information Gain Ratio** (tแปซ C4.5) ฤแป cรขn nhแบฏc thuแปc tรญnh nรo thแปฑc sแปฑ hแปฏu รญch hฦกn.

---

#### **5. Dรนng Phฦฐฦกng phรกp khรกc thay cho Decision Tree**

Trong cรกc bรi toรกn phแปฉc tแบกp hoแบทc cรณ nhiแปu thuแปc tรญnh tฦฐฦกng tรกc, bแบกn cรณ thแป thay thแบฟ Decision Tree bแบฑng cรกc mรด hรฌnh phแปฉc tแบกp hฦกn:

- **Support Vector Machines (SVM):**
    - Xแปญ lรฝ tแปt cรกc thuแปc tรญnh tฦฐฦกng tรกc nhแป siรชu phแบณng (hyperplane) phi tuyแบฟn.
- **Neural Networks:**
    - ฤแบทc biแปt hiแปu quแบฃ khi cรณ nhiแปu thuแปc tรญnh phแปฉc tแบกp vร nhiแปu.

---

### **Kแบฟt luแบญn:**

Vแบฅn ฤแป cแปงa Decision Tree liรชn quan ฤแบฟn nhiแปu hoแบทc thuแปc tรญnh tฦฐฦกng tรกc cรณ thแป ฤฦฐแปฃc giแบฃi quyแบฟt bแบฑng:

1. Kแบฟt hแปฃp nhiแปu cรขy vแปi Random Forest hoแบทc Boosting.
2. Tแบกo thuแปc tรญnh mแปi vร loแบกi bแป thuแปc tรญnh nhiแปu.
3. Dรนng cรกc phฦฐฦกng phรกp tแปa cรขy hoแบทc ฤiแปu chแปnh ฤแป sรขu.
4. Chuyแปn sang cรกc mรด hรฌnh mแบกnh mแบฝ hฦกn nhฦฐ SVM hoแบทc Neural Networks.

Cรกch chแปn giแบฃi phรกp tรนy thuแปc vรo bรi toรกn, dแปฏ liแปu vร ฤแป phแปฉc tแบกp bแบกn muแปn xแปญ lรฝ.


![[Pasted image 20241127104908.png]]



---

Trong machine learing, decision tree cรณ 3-4 nhรกnh khรดng hay chแป 2 nhรกnh


![[Pasted image 20250812203541.png]]



---
Khi chแปn viแปc biแบฟn Engineering, Tรi chรญnh thรnh con ngฦฐแปi mรฌnh, giแปng nhฦฐ viแปc lรกi xe 
=> Mรฌnh ko cรฒn ngแบกi toรกn, biแบฟn toรกn thรnh con ngฦฐแปi mรฌnh. 
=> Ko cรฒn kiแปu hแปc nhanh chแปp dแบญt nhฦฐ lร dรนng tool nhiแปu, cรกi gรฌ liรชn quan ฤแบฟn tiแปn mแปi hแปc 
Thay vรo ฤรณ mรฌnh dรnh thแปi gian HแปC SรU NHแปฎNG THแปจ RA TIแปN TRONG DรI HแบN, LIรN TแปคC. 

+, Hแปc sรขu lแบญp trรฌnh, giแบฃi thuแบญt, toรกn. Thay vรฌ chแป hแปc bแป nแปi vร AI code. 


![[Pasted image 20250812210550.png]]


![[Pasted image 20250812210842.png]]




1.0 = Entropy => Khรณ dแปฑ ฤoรกn cแปฅc gแบกch hay vรng. 
0.46 = Entropy thแบฅp => Dแป dแปฑ ฤoรกn. Thรดng tin chแบฏc chแบฏn hฦกn, รญt bแป nhiแปu  loแบกn thรดng tin. Giรก trแป mang lแบกi รญt hฦกn vรฌ thรดng tin รญt bแบฅt ngแป hฦกn. 

tแบกi sao lแบกi lร: tแปng xรญch ma cแปงa P(x) * log(1/P(x)) แบก


---

Ok, mรฌnh sแบฝ giแบฃi thรญch tแปซ **gแปc** hฦกn โ tแปฉc lร ฤi tแปซ viแปc "ฤo lฦฐแปng thรดng tin" trong ฤแปi thฦฐแปng โ ra cรดng thแปฉc Shannon.  
Bแบกn sแบฝ thแบฅy vรฌ sao lแบกi cรณ dแบกng **logโก(1/p)\log(1/p)** chแปฉ khรดng phแบฃi cรดng thแปฉc khรกc.

---

## 1. Bรi toรกn gแปc: ฤo โlฦฐแปฃng thรดng tinโ cแปงa mแปt sแปฑ kiแปn

Claude Shannon (1948) ฤแบทt ra cรขu hแปi:

> Nแบฟu mแปt sแปฑ kiแปn xแบฃy ra, lรm sao ฤo ฤฦฐแปฃc nรณ mang bao nhiรชu **thรดng tin**?

รng ฤฦฐa ra 3 tiรชu chรญ cho mแปt hรm ฤo thรดng tin I(p)I(p):

1. **Xรกc suแบฅt cรng nhแป โ thรดng tin cรng nhiแปu**
    
    - Vรญ dแปฅ: Trรบng sแป ฤแปc ฤแบฏc (xรกc suแบฅt 1/1,000,000) gรขy "bแบฅt ngแป" hฦกn nhiแปu so vแปi trแปi mฦฐa แป Hร Nแปi thรกng 8.
        
    - Nghฤฉa lร pp โ โ I(p)I(p) โ.
        
2. **Hai sแปฑ kiแปn ฤแปc lแบญp โ thรดng tin cแปng lแบกi**
    
    - Nแบฟu A vร B ฤแปc lแบญp, lฦฐแปฃng thรดng tin cแปงa โA **vร** Bโ = I(pAโpB)=I(pA)+I(pB)I(p_A \cdot p_B) = I(p_A) + I(p_B).
        
    - ฤรขy lร **tรญnh cแปng** cแปงa thรดng tin.
        
3. **Liรชn tแปฅc vร hแปฃp lรฝ**
    
    - Hรm ฤo thรดng tin phแบฃi trฦกn tru, khรดng nhแบฃy ฤแปt ngแปt, vร logic vแปi trแปฑc giรกc.
        

---

## 2. Giแบฃi phฦฐฦกng trรฌnh โ ra cรดng thแปฉc log

Nแบฟu bแบกn yรชu cแบงu mแปt hรm I(p)I(p) thแปa mรฃn:

I(pAโpB)=I(pA)+I(pB)I(p_A \cdot p_B) = I(p_A) + I(p_B)

thรฌ **duy nhแบฅt** hรm dแบกng:

I(p)=kโlogโก1pI(p) = k \cdot \log\frac{1}{p}

thแปa mรฃn (theo toรกn hแปc, ฤรขy lร nghiแปm duy nhแบฅt cแปงa phฦฐฦกng trรฌnh hรm Cauchy trong miแปn dฦฐฦกng).

- kk lร hแบฑng sแป quy ฤแปi ฤฦกn vแป:
    
    - k=1k=1 vร log cฦก sแป 2 โ ฤฦกn vแป **bit**.
        
    - k=1k=1 vร log cฦก sแป e โ ฤฦกn vแป **nat**.
        

---

## 3. Tแปซ thรดng tin cแปงa mแปt sแปฑ kiแปn โ entropy

- I(p)I(p) lร **thรดng tin** khi biแบฟt mแปt sแปฑ kiแปn cแปฅ thแป xแบฃy ra.
    
- Nhฦฐng trong thแปฑc tแบฟ, ta khรดng biแบฟt trฦฐแปc sแปฑ kiแปn nรo xแบฃy ra โ ta cแบงn **giรก trแป kแปณ vแปng**:
    

H(X)=โxp(x)โI(p(x))=โxp(x)โlogโก1p(x)H(X) = \sum_{x} p(x) \cdot I(p(x)) = \sum_{x} p(x) \cdot \log\frac{1}{p(x)}

- ฤรขy chรญnh lร **entropy**: thรดng tin trung bรฌnh cแบงn ฤแป mรด tแบฃ mแปt biแบฟn ngแบซu nhiรชn.
    

---

## 4. Trแปฑc giรกc rแบฅt ฤแปi thฦฐแปng

- Nแบฟu sแปฑ kiแปn **chแบฏc chแบฏn** (p=1), logโก(1/p)=0\log(1/p)=0 โ khรดng cแบงn thรดng tin gรฌ nแปฏa.
    
- Nแบฟu sแปฑ kiแปn **hiแบฟm** (p rแบฅt nhแป), logโก(1/p)\log(1/p) lแปn โ cแบงn nhiแปu โbitโ ฤแป mรด tแบฃ nรณ.
    
- Nแบฟu cรณ nhiแปu khแบฃ nฤng ngang nhau, entropy cao โ khรณ ฤoรกn, cแบงn nhiแปu thรดng tin trung bรฌnh hฦกn.
    

---

Nแบฟu bแบกn muแปn, mรฌnh cรณ thแป lรm **mแปt vรญ dแปฅ trแปฑc quan bแบฑng trรฒ chฦกi 20 cรขu hแปi** ฤแป bแบกn thแบฅy vรฌ sao lฦฐแปฃng thรดng tin phแบฃi dรนng log vร cแปng dแปn.  
Bแบกn cรณ muแปn mรฌnh lรm vรญ dแปฅ ฤรณ khรดng?


---
Entropy khi theo ฤuแปi 1 ngฦฐแปi nhiแปu khi = 0 mร nhiแปu ace vแบซn cแป gแบฏng ๐



- **Entropy = 0** โ kแบฟt quแบฃ ฤรฃ chแบฏc chแบฏn 100% (ngฦฐแปi ta khรดng thรญch mรฌnh hoแบทc ฤรฃ cรณ ngฦฐแปi yรชu) โ vแป lรฝ thuyแบฟt thรฌ khรดng cแบงn tแปn thรชm โbitโ nรo ฤแป giแบฃi mรฃ thรดng tin.
    
- Nhฦฐng trong **tรฌnh cแบฃm**, โngฦฐแปi chฦกi hแป niแปm tinโ lแบกi override lรฝ thuyแบฟt, coi xรกc suแบฅt 0 nhฦฐ vแบซn cรฒn โmแปt chรบt hy vแปng lฦฐแปฃng tแปญโ ๐คญ.
    

---

๐ **Biแปu ฤแป cแบฃm xรบc vs. Entropy trong tรฌnh yรชu**:

- Entropy cao โ hแปi hแปp, ฤoรกn giร ฤoรกn non, mแปi tรญn hiแปu ฤแปu cรณ thแป ฤแบฃo ngฦฐแปฃc.
    
- Entropy thแบฅp (gแบงn 0) โ khoa hแปc bแบฃo โbแป ฤiโ, trรกi tim bแบฃo โcแป lรชnโ.

---
- **Entropy = 0** nghฤฉa lร **khรดng cรฒn bแบฅt ฤแปnh**:
    
    - 100% chแบฏc chแบฏn ngฦฐแปi ta thรญch mรฌnh โ
        
    - hoแบทc 100% chแบฏc chแบฏn ngฦฐแปi ta _khรดng_ thรญch mรฌnh โ
        

Vแบฅn ฤแป lรโฆ trong ฤแปi thแบญt, nhiแปu ngฦฐแปi khi **Entropy = 0 (khรดng thรญch)** vแบซn behave nhฦฐ **Entropy cao** ๐  
โ tแปฉc lร bแป qua tรญn hiแปu chแบฏc chแบฏn, vแบซn โexploreโ nhฦฐ ฤang แป giai ฤoแบกn mฦก hแป.


---
![[Pasted image 20250812212327.png]]


![[Pasted image 20250812212537.png]]

---
Tรญnh chแบฏc chแบฏn vแป quyแบฟt ฤแปnh ฤฦฐแปฃng lฦฐแปฃng hoรก bro แบก.  
--  
Kiแปu ban ฤแบงu 5 bi ฤแป, 5 bi xanh thรฌ Entropy ban ฤแบงu = 1 (vรฌ 50-50)


```
แบญy lร entropy trong bรi decision tree lแบงn nรy giรบp xem lร viแปc lแปฑa chแปn cรกc ifs hรฃm ฤฦฐแปฃc lแบกi sแปฑ bแบฅt ngแป tแปi ฤรขu ฤแป rแปi ฤรชn leaf sแบฝ lร kแบฟt quแบฃ mรฌnh ฤoรกn ฤk dแป nhแบฅt ohair ko ad แบก  
  
**Hแปc Vแบนt** 9:20 PM  
@343_ฤinh Nam Khรกnh รฝ tฦฐแปng cแปงa Decision Tree lร ฤแบทt cรกc cรขu hแปi โhแปฃp lรฝโ ฤแป chia ฤรดi tแบญp hแปฃp mแบซu. Cรขu hแปi hแปฃp lรฝ lร cรขu hแปi lรm giแบฃm entropy (ฤแป bแบฅt ฤแปnh) cho ฤแบฟn khi chia ra thรnh cรกc tแบญp hแปฃp gแปm 1 giรก trแป nhรฃn (thuแบงn nhแบฅt = purity), ฤรณ chรญnh lร leaf node
```


Lรฝ do tแบกi sao khi cรกc giรก trแป cรณ xรกc suแบฅt bแบฑng nhau lแบกi cรณ Entropy lแปn nhแบฅt lร vรฌ -log(x) lร hรm sแป lรตm khi x > 0, vร รกp dแปฅng bแบฅt ฤแบณng thแปฉc Jensen trong Toรกn vแปi hรm lรตm thรฌ thu ฤฦฐแปฃc Entropy lแปn nhแบฅt khi tแบฅt cแบฃ cรกc giรก trแป xรกc suแบฅt p_i bแบฑng nhau.  
  
Khi n giรก trแป cรณ xรกc suแบฅt bแบฑng nhau, ฤแป hแปn loแบกn/bแบฅt ฤแปnh (Entropy) lร lแปn nhแบฅt.


---
Ok, mรฌnh sแบฝ viแบฟt thรชm phแบงn **Parent Entropy** (E(S)) theo ฤรบng dแปฏ liแปu trong bแบฃng.

---

### 1. Xรกc ฤแปnh sแป lฦฐแปฃng Yes / No toรn bแป bแบฃng

Tแปซ cแปt **Play Tennis**:

- **Yes** = 9 mแบซu
    
- **No** = 5 mแบซu  
    โ Tแปng = 14 mแบซu
    

---

### 2. Cรดng thแปฉc entropy cแปงa parent (E(S))

E(S)=โ914logโก2914โ514logโก2514E(S) = - \frac{9}{14} \log_2 \frac{9}{14} - \frac{5}{14} \log_2 \frac{5}{14}

---

### 3. Tรญnh giรก trแป

- 914โ0.6429\frac{9}{14} \approx 0.6429
    
- 514โ0.3571\frac{5}{14} \approx 0.3571
    

E(S)=โ0.6429โlogโก2(0.6429)โ0.3571โlogโก2(0.3571)E(S) = - 0.6429 \cdot \log_2(0.6429) - 0.3571 \cdot \log_2(0.3571) E(S)โโ0.6429โ(โ0.6439)โ0.3571โ(โ1.4854)E(S) \approx - 0.6429 \cdot (-0.6439) - 0.3571 \cdot (-1.4854) E(S)โ0.413+0.530โ0.943E(S) \approx 0.413 + 0.530 \approx 0.943

---

โ **Parent Entropy (E(S)) โ 0.94** โ ฤรบng vแปi con sแป แป slide cแปงa bแบกn.

---

Nแบฟu bแบกn muแปn, mรฌnh cรณ thแป viแบฟt lแบกi **cแบฃ quy trรฌnh IG(Wind)** แป slide nรy, bao gแปm:

1. Tรญnh Parent Entropy.
    
2. Tรญnh Entropy cแปงa Weak & Strong.
    
3. Tรญnh IG.  
    Bแบกn cรณ muแปn mรฌnh lรm trแปn vแบนn luรดn khรดng?

---
```
Anh **@Hแปc Vแบนt**  
  
Em vแปซa check lแบกi:  
  
Vแปi f(x)=โxlogx vแปi x > 0 thรฌ cรณ ฤแบกo hรm bแบญc 2 nhแป hฦกn 0 nรชn lรตm  
  
Nhฦฐng hรm f(x) = -log(x) vแปi x > 0 cรณ ฤแบกo hรm bแบญc 2 lแปn hฦกn 0 nรชn lแปi  
  
  
---  
  
Vรญ dแปฅ x^2 lร hรm lแปi  
+, (tรญnh tแปซ ngoรi vรo) (parabol)  
+, ฤแบกo hรm bแบญc 2 cแปงa nรณ bแบฑng 2 >0 nรชn hรm lแปi
```