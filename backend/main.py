#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
================================================================================
                    DOMAIN PROGRESS TRACKER BACKEND - FASTAPI
================================================================================

M√î T·∫¢ T·ªîNG QUAN:
    ·ª®ng d·ª•ng backend ƒë∆∞·ª£c x√¢y d·ª±ng b·∫±ng FastAPI ƒë·ªÉ theo d√µi ti·∫øn ƒë·ªô h·ªçc t·∫≠p 
    th√¥ng qua h·ªá th·ªëng XP/Level gi·ªëng nh∆∞ game. H·ªá th·ªëng s·∫Ω qu√©t c√°c th∆∞ m·ª•c 
    domain h·ªçc t·∫≠p v√† t√≠nh to√°n ƒëi·ªÉm kinh nghi·ªám (XP) d·ª±a tr√™n s·ªë l∆∞·ª£ng b√†i vi·∫øt 
    v√† n·ªôi dung h·ªçc t·∫≠p.

CH·ª®C NƒÇNG CH√çNH:
    1. Qu√©t v√† ph√¢n t√≠ch c√°c th∆∞ m·ª•c domain h·ªçc t·∫≠p
    2. T√≠nh to√°n XP v√† Level d·ª±a tr√™n s·ªë b√†i vi·∫øt v√† t·ª´ ng·ªØ
    3. Theo d√µi streak days (s·ªë ng√†y li√™n ti·∫øp h·ªçc t·∫≠p)
    4. Cung c·∫•p API RESTful ƒë·ªÉ frontend c√≥ th·ªÉ truy c·∫≠p d·ªØ li·ªáu
    5. Th·ªëng k√™ t·ªïng quan v·ªÅ ti·∫øn ƒë·ªô h·ªçc t·∫≠p

C·∫§U TR√öC H·ªÜ TH·ªêNG:
    - Domain 1: Mathematical & Statistical Foundation (M√†u Indigo)
    - Domain 2: Programming & Software Engineering (M√†u Emerald)
    - Domain 3: Machine Learning Fundamentals (M√†u Amber)
    - Domain 4: Deep Learning & Neural Networks (M√†u Pink)
    - Domain 5: Data Engineering & Processing (M√†u Blue)
    - Domain 6: Production Systems & MLOps (M√†u Violet)
    - Domain 7: Cloud & Infrastructure (M√†u Red)
    - Domain 8: Advanced AI Applications (M√†u Teal)
    - Domain 9: Research & Innovation (M√†u Orange)
    - Domain 10: Business & Entrepreneurship (M√†u Lime)

C√îNG TH·ª®C T√çNH XP:
    - Base XP: 100 ƒëi·ªÉm cho m·ªói b√†i vi·∫øt
    - Bonus XP: 1 ƒëi·ªÉm cho m·ªói 10 t·ª´ trong n·ªôi dung
    - T·ªïng XP = (S·ªë b√†i vi·∫øt √ó 100) + (T·ªïng t·ª´ √∑ 10)

C√îNG TH·ª®C T√çNH LEVEL:
    - Level 1: C·∫ßn 1000 XP
    - Level 2: C·∫ßn 1500 XP (1000 √ó 1.5)
    - Level 3: C·∫ßn 2250 XP (1500 √ó 1.5)
    - Level n: C·∫ßn 1000 √ó (1.5^(n-1)) XP

API ENDPOINTS:
    - GET /: Th√¥ng tin c∆° b·∫£n v·ªÅ API
    - GET /api/domains: L·∫•y danh s√°ch t·∫•t c·∫£ domains v·ªõi XP/Level
    - POST /api/domains/refresh: L√†m m·ªõi d·ªØ li·ªáu domains
    - GET /api/domains/stats: L·∫•y th·ªëng k√™ t·ªïng quan

T√ÅC GI·∫¢: H·ªá th·ªëng theo d√µi ti·∫øn ƒë·ªô h·ªçc t·∫≠p
NG√ÄY T·∫†O: 2024
PHI√äN B·∫¢N: 1.0.0
================================================================================
"""

import os
import json
from datetime import datetime, timedelta
from pathlib import Path
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Dict, Any, Optional
import re

app = FastAPI(
    title="Domain Progress Tracker API",
    description="API ƒë·ªÉ scan v√† t√≠nh to√°n XP/Level cho c√°c domain h·ªçc t·∫≠p",
    version="1.0.0"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# C·∫•u h√¨nh
DATA_SCIENCE_PATH = r"D:\vip_DOCUMENTS_OBS\home\DATA SCIENCE AND AI"
SUPPORTED_EXTENSIONS = {'.txt', '.md', '.docx', '.doc', '.html', '.rtf'}

# Pydantic Models
class DomainData(BaseModel):
    xp: int
    level: int
    color: str
    taskCount: int
    streakDays: int
    maxStreakDays: int
    totalDays: int
    lastTaskDate: str

class DomainsResponse(BaseModel):
    success: bool
    domains: Dict[str, DomainData]
    count: int
    last_scan: str

class StatsResponse(BaseModel):
    success: bool
    stats: Dict[str, Any]
    last_scan: str

class ErrorResponse(BaseModel):
    success: bool
    error: str

# Domain colors mapping
DOMAIN_COLORS = {
    'Domain 1': '#4F46E5',  # Indigo - Mathematical Foundation
    'Domain 2': '#10B981',  # Emerald - Programming & Software Engineering  
    'Domain 3': '#F59E0B',  # Amber - Machine Learning Fundamentals
    'Domain 4': '#EC4899',  # Pink - Deep Learning & Neural Networks
    'Domain 5': '#3B82F6',  # Blue - Data Engineering & Processing
    'Domain 6': '#8B5CF6',  # Violet - Production Systems & MLOps
    'Domain 7': '#EF4444',  # Red - Cloud & Infrastructure
    'Domain 8': '#14B8A6',  # Teal - Advanced AI Applications
    'Domain 9': '#F97316',  # Orange - Research & Innovation
    'Domain 10': '#84CC16', # Lime - Business & Entrepreneurship
    'default': '#6B7280'    # Gray
}

def get_domain_color(domain_name):
    """
    L·∫•y m√†u s·∫Øc t∆∞∆°ng ·ª©ng cho domain d·ª±a tr√™n t√™n domain
    
    Args:
        domain_name (str): T√™n c·ªßa domain (v√≠ d·ª•: "Domain 1 Mathematical Foundation")
        
    Returns:
        str: M√£ m√†u hex t∆∞∆°ng ·ª©ng v·ªõi domain, m·∫∑c ƒë·ªãnh l√† m√†u x√°m n·∫øu kh√¥ng t√¨m th·∫•y
        
    V√≠ d·ª•:
        get_domain_color("Domain 1 Mathematical") -> "#4F46E5" (Indigo)
        get_domain_color("Domain 2 Programming") -> "#10B981" (Emerald)
        get_domain_color("Unknown Domain") -> "#6B7280" (Gray)
    """
    for key, color in DOMAIN_COLORS.items():
        if key in domain_name:
            return color
    return DOMAIN_COLORS['default']

def calculate_xp_from_articles(articles_count, total_words):
    """
    T√≠nh to√°n ƒëi·ªÉm kinh nghi·ªám (XP) d·ª±a tr√™n s·ªë l∆∞·ª£ng b√†i vi·∫øt v√† t·ªïng s·ªë t·ª´
    
    C√¥ng th·ª©c t√≠nh XP:
    - Base XP: 100 ƒëi·ªÉm cho m·ªói b√†i vi·∫øt
    - Bonus XP: 1 ƒëi·ªÉm cho m·ªói 10 t·ª´ trong n·ªôi dung
    - T·ªïng XP = Base XP + Bonus XP
    
    Args:
        articles_count (int): S·ªë l∆∞·ª£ng b√†i vi·∫øt/t√†i li·ªáu trong domain
        total_words (int): T·ªïng s·ªë t·ª´ trong t·∫•t c·∫£ b√†i vi·∫øt
        
    Returns:
        int: T·ªïng ƒëi·ªÉm XP ƒë∆∞·ª£c t√≠nh to√°n
        
    V√≠ d·ª•:
        calculate_xp_from_articles(5, 2500) -> 750 XP
        # Base: 5 √ó 100 = 500 XP
        # Bonus: 2500 √∑ 10 = 250 XP
        # T·ªïng: 500 + 250 = 750 XP
    """
    # Base XP: 100 XP per article
    base_xp = articles_count * 100
    
    # Bonus XP: 1 XP per 10 words
    word_bonus = total_words // 10
    
    return base_xp + word_bonus

def calculate_level_from_xp(xp):
    """
    T√≠nh to√°n level d·ª±a tr√™n t·ªïng ƒëi·ªÉm XP (h·ªá th·ªëng t∆∞∆°ng t·ª± game)
    
    C√¥ng th·ª©c t√≠nh level:
    - Level 1: C·∫ßn 1000 XP
    - Level 2: C·∫ßn 1500 XP (1000 √ó 1.5)
    - Level 3: C·∫ßn 2250 XP (1500 √ó 1.5)
    - Level n: C·∫ßn 1000 √ó (1.5^(n-1)) XP
    
    Args:
        xp (int): T·ªïng ƒëi·ªÉm XP hi·ªán t·∫°i
        
    Returns:
        int: Level t∆∞∆°ng ·ª©ng v·ªõi s·ªë XP
        
    V√≠ d·ª•:
        calculate_level_from_xp(800) -> 0 (ch∆∞a ƒë·ªß XP cho level 1)
        calculate_level_from_xp(1200) -> 1 (ƒë·ªß XP cho level 1, c√≤n 200 XP)
        calculate_level_from_xp(2500) -> 2 (ƒë·ªß XP cho level 1 v√† 2)
    """
    level = 0
    required_xp = 1000  # Base XP required for level 1
    LEVEL_XP_MULTIPLIER = 1.5
    
    current_xp = xp
    while current_xp >= required_xp:
        level += 1
        current_xp -= required_xp
        required_xp = int(1000 * (LEVEL_XP_MULTIPLIER ** level))
    
    return level

def estimate_word_count(file_path, file_ext):
    """
    ∆Ø·ªõc t√≠nh s·ªë t·ª´ trong file d·ª±a tr√™n lo·∫°i file v√† n·ªôi dung
    
    H·ªó tr·ª£ c√°c lo·∫°i file:
    - .txt, .md: ƒê·∫øm t·ª´ tr·ª±c ti·∫øp t·ª´ n·ªôi dung text
    - .html: Lo·∫°i b·ªè HTML tags r·ªìi ƒë·∫øm t·ª´
    - C√°c lo·∫°i kh√°c: ∆Ø·ªõc t√≠nh d·ª±a tr√™n k√≠ch th∆∞·ªõc file
    
    Args:
        file_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file c·∫ßn ƒë·∫øm t·ª´
        file_ext (str): Ph·∫ßn m·ªü r·ªông c·ªßa file (v√≠ d·ª•: '.md', '.txt')
        
    Returns:
        int: S·ªë t·ª´ ∆∞·ªõc t√≠nh trong file
        
    V√≠ d·ª•:
        estimate_word_count("note.md", ".md") -> 150 (ƒë·∫øm t·ª´ th·ª±c t·∫ø)
        estimate_word_count("doc.docx", ".docx") -> 200 (∆∞·ªõc t√≠nh t·ª´ k√≠ch th∆∞·ªõc)
    """
    try:
        if file_ext in ['.txt', '.md']:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                words = len(content.split())
                return words
        elif file_ext == '.html':
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                clean_text = re.sub(r'<[^>]+>', ' ', content)
                words = len(clean_text.split())
                return words
        else:
            # ∆Ø·ªõc t√≠nh d·ª±a tr√™n k√≠ch th∆∞·ªõc file
            file_size = os.path.getsize(file_path)
            estimated_words = file_size // 5
            return max(100, estimated_words)
    except:
        return 500  # Gi√° tr·ªã m·∫∑c ƒë·ªãnh

def calculate_streak_days(article_dates):
    """
    ================================================================================
                            T√çNH TO√ÅN WRITING STREAK HI·ªÜN T·∫†I
    ================================================================================
    
    M·ª§C ƒê√çCH:
        T√≠nh to√°n s·ªë ng√†y li√™n ti·∫øp (kh√¥ng gi√°n ƒëo·∫°n) c√≥ ho·∫°t ƒë·ªông vi·∫øt b√†i,
        ƒë·∫øm t·ª´ ng√†y g·∫ßn nh·∫•t c√≥ b√†i vi·∫øt tr·ªü v·ªÅ qu√° kh·ª© cho ƒë·∫øn khi g·∫∑p kho·∫£ng tr·ªëng.
    
    ƒê·ªäNH NGHƒ®A STREAK:
        - Streak = Chu·ªói ng√†y li√™n ti·∫øp c√≥ b√†i vi·∫øt
        - Li√™n ti·∫øp = Kh√¥ng ƒë∆∞·ª£c thi·∫øu ng√†y n√†o gi·ªØa ch·ª´ng  
        - D·ª´ng ngay khi g·∫∑p gap (ng√†y kh√¥ng c√≥ b√†i vi·∫øt)
        - Flexible mode: Kh√¥ng b·∫Øt bu·ªôc ph·∫£i vi·∫øt h√¥m nay
    
    THU·∫¨T TO√ÅN T·ªêI ∆ØU:
        1. üìä DATA PROCESSING: Chuy·ªÉn th√†nh set ƒë·ªÉ lookup O(1)
        2. üéØ FLEXIBLE MODE: T√¨m ng√†y g·∫ßn nh·∫•t c√≥ b√†i vi·∫øt l√†m ƒëi·ªÉm b·∫Øt ƒë·∫ßu
        3. ‚ö° DYNAMIC LIMIT: T√≠nh to√°n gi·ªõi h·∫°n d·ª±a tr√™n d·ªØ li·ªáu th·ª±c t·∫ø
        4. üîÑ BACKWARD COUNTING: ƒê·∫øm ng∆∞·ª£c t·ª´ ƒëi·ªÉm b·∫Øt ƒë·∫ßu v·ªÅ qu√° kh·ª©
        5. üõë STOP ON GAP: D·ª´ng ngay khi g·∫∑p ng√†y ƒë·∫ßu ti√™n kh√¥ng c√≥ b√†i vi·∫øt
    
    PERFORMANCE:
        - Time Complexity: O(n + k) v·ªõi n=s·ªë b√†i vi·∫øt, k=streak length
        - Space Complexity: O(d) v·ªõi d=s·ªë ng√†y unique
        - Optimizations: Set comprehension, generator expression, dynamic limits
    
    Args:
        article_dates (list): Danh s√°ch c√°c datetime object c·ªßa ng√†y t·∫°o b√†i vi·∫øt
                             C√≥ th·ªÉ ch·ª©a nhi·ªÅu b√†i vi·∫øt c√πng ng√†y (s·∫Ω ƒë∆∞·ª£c deduplicate)
        
    Returns:
        int: S·ªë ng√†y li√™n ti·∫øp h·ªçc t·∫≠p (streak days)
             - 0 n·∫øu kh√¥ng c√≥ b√†i vi·∫øt ho·∫∑c kh√¥ng c√≥ b√†i vi·∫øt tr∆∞·ªõc h√¥m nay
             - 1+ n·∫øu c√≥ streak (bao g·ªìm c·∫£ streak ƒë·ªôc l·∫≠p kh√¥ng k·∫øt th√∫c h√¥m nay)
        
    V√≠ d·ª• th·ª±c t·∫ø:
        Input: [2025-09-06, 2025-09-05, 2025-09-03, 2025-09-01]
        H√¥m nay: 2025-09-07
        
        Qu√° tr√¨nh:
        1. H√¥m nay (07) kh√¥ng c√≥ b√†i vi·∫øt ‚Üí B·∫Øt ƒë·∫ßu t·ª´ 06
        2. Ng√†y 06: ‚úÖ c√≥ ‚Üí streak = 1
        3. Ng√†y 05: ‚úÖ c√≥ ‚Üí streak = 2  
        4. Ng√†y 04: ‚ùå kh√¥ng c√≥ ‚Üí D·ª™NG
        
        K·∫øt qu·∫£: streak = 2
    """
    # ============================================================================
    # B∆Ø·ªöC 1: VALIDATION & INPUT PROCESSING
    # ============================================================================
    
    # Ki·ªÉm tra input r·ªóng - edge case c∆° b·∫£n nh·∫•t
    if not article_dates:
        print("üî• STREAK DEBUG: Kh√¥ng c√≥ article_dates")
        return 0
    
    # ‚úÖ OPTIMIZATION: Set comprehension thay v√¨ loop th·ªß c√¥ng
    # - Chuy·ªÉn datetime object th√†nh date object (b·ªè time component)
    # - T·ª± ƒë·ªông deduplicate nhi·ªÅu b√†i vi·∫øt c√πng ng√†y
    # - Time complexity: O(n) thay v√¨ O(n log n) n·∫øu d√πng sort
    article_date_set = {
        d.date() if isinstance(d, datetime) else d 
        for d in article_dates
    }
    
    # Ki·ªÉm tra sau khi convert - c√≥ th·ªÉ t·∫•t c·∫£ dates ƒë·ªÅu invalid
    if not article_date_set:
        print("üî• STREAK DEBUG: Kh√¥ng c√≥ ng√†y h·ª£p l·ªá")
        return 0
    
    # Debug info: So s√°nh s·ªë b√†i vi·∫øt raw vs unique dates
    print(f"üî• STREAK DEBUG: S·ªë b√†i vi·∫øt: {len(article_dates)}")
    print(f"üìä STREAK DEBUG: Unique dates: {len(article_date_set)} t·ª´ {len(article_dates)} articles")
    print(f"üî• STREAK DEBUG: Ng√†y b√†i vi·∫øt: {sorted(article_date_set, reverse=True)[:10]}")
    
    # ============================================================================
    # B∆Ø·ªöC 2: FLEXIBLE MODE - T√åM ƒêI·ªÇM B·∫ÆT ƒê·∫¶U
    # ============================================================================
    
    current_date = datetime.now().date()
    print(f"üî• STREAK DEBUG: Ng√†y hi·ªán t·∫°i: {current_date}")
    
    # ‚úÖ FLEXIBLE MODE: Kh√¥ng b·∫Øt bu·ªôc ph·∫£i vi·∫øt h√¥m nay
    # N·∫øu h√¥m nay ch∆∞a vi·∫øt, b·∫Øt ƒë·∫ßu t·ª´ ng√†y g·∫ßn nh·∫•t c√≥ b√†i vi·∫øt
    if current_date not in article_date_set:
        try:
            # ‚úÖ OPTIMIZATION: Generator expression thay v√¨ list comprehension
            # - Kh√¥ng t·∫°o list trung gian, ti·∫øt ki·ªám memory
            # - max() v·ªõi generator ch·ªâ iterate m·ªôt l·∫ßn
            current_date = max(d for d in article_date_set if d <= current_date)
            print(f"üî• STREAK DEBUG: H√¥m nay ch∆∞a vi·∫øt, b·∫Øt ƒë·∫ßu t·ª´: {current_date}")
        except ValueError:
            # Tr∆∞·ªùng h·ª£p t·∫•t c·∫£ b√†i vi·∫øt ƒë·ªÅu trong t∆∞∆°ng lai
            print(f"üî• STREAK DEBUG: Kh√¥ng c√≥ b√†i vi·∫øt tr∆∞·ªõc h√¥m nay ‚Üí streak = 0")
            return 0
    
    # ============================================================================
    # B∆Ø·ªöC 3: DYNAMIC LIMIT CALCULATION
    # ============================================================================
    
    # ‚úÖ OPTIMIZATION: T√≠nh to√°n gi·ªõi h·∫°n th√¥ng minh d·ª±a tr√™n d·ªØ li·ªáu
    # Thay v√¨ fixed limit 365, ch·ªâ check ƒë·∫øn ng√†y ƒë·∫ßu ti√™n c√≥ b√†i vi·∫øt
    min_date = min(article_date_set)
    max_possible_days = (current_date - min_date).days + 1
    max_days = min(365, max_possible_days)  # Safety cap t·∫°i 365 ng√†y
    
    print(f"üî• STREAK DEBUG: Dynamic limit: {max_days} ng√†y (t·ª´ {min_date} ƒë·∫øn {current_date})")
    
    # ============================================================================
    # B∆Ø·ªöC 4: BACKWARD COUNTING ALGORITHM
    # ============================================================================
    
    # Kh·ªüi t·∫°o counters
    streak = 0          # K·∫øt qu·∫£ streak cu·ªëi c√πng
    day_counter = 0     # ƒê·∫øm s·ªë ng√†y ƒë√£ check (ƒë·ªÉ debug)
    
    # Main loop: ƒê·∫øm ng∆∞·ª£c t·ª´ current_date v·ªÅ qu√° kh·ª©
    while day_counter < max_days and current_date >= min_date:
        print(f"üî• STREAK DEBUG: Ki·ªÉm tra ng√†y {day_counter + 1}: {current_date}")
        
        # ‚úÖ CORE LOGIC: Set lookup O(1) complexity
        if current_date in article_date_set:
            # C√≥ b√†i vi·∫øt trong ng√†y n√†y
            streak += 1
            print(f"üî• STREAK DEBUG: ‚úÖ C√≥ b√†i vi·∫øt ng√†y {current_date} ‚Üí streak = {streak}")
            
            # Di chuy·ªÉn v·ªÅ ng√†y tr∆∞·ªõc ƒë√≥ ƒë·ªÉ ti·∫øp t·ª•c check
            current_date = current_date - timedelta(days=1)
        else:
            # ‚ùå CRITICAL: G·∫∑p gap ƒë·∫ßu ti√™n ‚Üí D·ª´ng streak ngay l·∫≠p t·ª©c
            # ƒê√¢y l√† ƒëi·ªÉm kh√°c bi·ªát quan tr·ªçng v·ªõi thu·∫≠t to√°n t√≠nh t·ªïng s·ªë ng√†y
            print(f"üî• STREAK DEBUG: ‚ùå Kh√¥ng c√≥ b√†i vi·∫øt ng√†y {current_date} ‚Üí D·ª™NG")
            break
        
        # Increment counter cho debugging v√† safety check
        day_counter += 1
    
    # ============================================================================
    # B∆Ø·ªöC 5: RETURN RESULT
    # ============================================================================
    
    print(f"üî• STREAK DEBUG: K·∫øt qu·∫£ cu·ªëi c√πng: streak = {streak}")
    return streak

def calculate_max_historical_streak(article_dates):
    """
    ================================================================================
                        T√çNH TO√ÅN WRITING STREAK T·ªêI ƒêA TRONG L·ªäCH S·ª¨
    ================================================================================
    
    M·ª§C ƒê√çCH:
        T√¨m chu·ªói ng√†y li√™n ti·∫øp d√†i nh·∫•t t·ª´ng c√≥ trong to√†n b·ªô l·ªãch s·ª≠ vi·∫øt b√†i,
        kh√¥ng nh·∫•t thi·∫øt ph·∫£i k·∫øt th√∫c ·ªü th·ªùi ƒëi·ªÉm hi·ªán t·∫°i. ƒê√¢y l√† "k·ª∑ l·ª•c" streak.
    
    KH√ÅC BI·ªÜT V·ªöI CURRENT STREAK:
        - Current streak: Ch·ªâ t√≠nh t·ª´ g·∫ßn ƒë√¢y nh·∫•t v·ªÅ qu√° kh·ª©, d·ª´ng khi g·∫∑p gap
        - Max historical: Qu√©t to√†n b·ªô timeline, t√¨m ƒëo·∫°n li√™n ti·∫øp d√†i nh·∫•t
        
    THU·∫¨T TO√ÅN SLIDING WINDOW:
        1. üìÖ CHRONOLOGICAL SORT: S·∫Øp x·∫øp t·∫•t c·∫£ ng√†y theo th·ª© t·ª± th·ªùi gian
        2. üîÑ SEQUENTIAL SCAN: Duy·ªát qua t·ª´ng c·∫∑p ng√†y li√™n ti·∫øp  
        3. üìè CONSECUTIVE CHECK: Ki·ªÉm tra kho·∫£ng c√°ch ƒë√∫ng 1 ng√†y
        4. üìà DYNAMIC TRACKING: Update max ngay khi t√¨m th·∫•y streak d√†i h∆°n
        5. üîÑ RESET ON GAP: Reset current streak khi g·∫∑p kho·∫£ng tr·ªëng
    
    PERFORMANCE OPTIMIZATIONS:
        - Time Complexity: O(n log n) do sorting, O(n) cho scanning  
        - Space Complexity: O(d) v·ªõi d=s·ªë ng√†y unique
        - Single-pass algorithm: Ch·ªâ duy·ªát d·ªØ li·ªáu m·ªôt l·∫ßn sau khi sort
        - In-loop max update: Kh√¥ng c·∫ßn l∆∞u tr·ªØ t·∫•t c·∫£ streaks
    
    Args:
        article_dates (list): Danh s√°ch c√°c datetime object c·ªßa ng√†y t·∫°o b√†i vi·∫øt
                             C√≥ th·ªÉ ch·ª©a nhi·ªÅu b√†i vi·∫øt c√πng ng√†y (s·∫Ω ƒë∆∞·ª£c deduplicate)
        
    Returns:
        int: Streak t·ªëi ƒëa trong l·ªãch s·ª≠
             - 0 n·∫øu kh√¥ng c√≥ b√†i vi·∫øt
             - 1 n·∫øu ch·ªâ c√≥ 1 ng√†y ho·∫∑c kh√¥ng c√≥ ng√†y n√†o li√™n ti·∫øp  
             - 2+ n·∫øu c√≥ √≠t nh·∫•t 1 c·∫∑p ng√†y li√™n ti·∫øp
        
    V√≠ d·ª• th·ª±c t·∫ø:
        Input: [2025-01-01, 2025-01-02, 2025-01-03, 2025-01-10, 2025-01-11]
        Timeline: 01‚Üí02‚Üí03 [gap] 10‚Üí11
        
        Qu√° tr√¨nh:
        1. Sort: [01, 02, 03, 10, 11]
        2. 01‚Üí02: li√™n ti·∫øp ‚Üí current=2, max=2
        3. 02‚Üí03: li√™n ti·∫øp ‚Üí current=3, max=3  
        4. 03‚Üí10: gap 7 ng√†y ‚Üí reset current=1
        5. 10‚Üí11: li√™n ti·∫øp ‚Üí current=2, max=3
        
        K·∫øt qu·∫£: max_streak = 3 (t·ª´ ng√†y 01‚Üí03)
    """
    # ============================================================================
    # B∆Ø·ªöC 1: VALIDATION & INPUT PROCESSING
    # ============================================================================
    
    # Ki·ªÉm tra input r·ªóng
    if not article_dates:
        print("üèÜ MAX STREAK DEBUG: Kh√¥ng c√≥ article_dates")
        return 0
    
    # ‚úÖ OPTIMIZATION: Combine convert + sort + deduplicate trong m·ªôt operation
    # - Set comprehension ƒë·ªÉ deduplicate O(n)
    # - Sorted ƒë·ªÉ s·∫Øp x·∫øp chronological O(n log n)  
    # - Chuy·ªÉn datetime ‚Üí date ƒë·ªÉ normalize time component
    unique_dates = sorted({
        d.date() if isinstance(d, datetime) else d 
        for d in article_dates
    })
    
    # Ki·ªÉm tra sau khi processing
    if not unique_dates:
        print("üèÜ MAX STREAK DEBUG: Kh√¥ng c√≥ ng√†y h·ª£p l·ªá")
        return 0
    
    # ‚úÖ EDGE CASE: Ch·ªâ c√≥ 1 ng√†y duy nh·∫•t
    # Kh√¥ng th·ªÉ t·∫°o streak v·ªõi 1 ng√†y, nh∆∞ng streak c·ªßa 1 ng√†y = 1
    if len(unique_dates) == 1:
        print(f"üèÜ MAX STREAK DEBUG: Ch·ªâ c√≥ 1 ng√†y ({unique_dates[0]}) ‚Üí max_streak = 1")
        return 1
    
    # Debug info: Hi·ªÉn th·ªã timeline overview
    print(f"üèÜ MAX STREAK DEBUG: T·ªïng {len(unique_dates)} ng√†y c√≥ b√†i vi·∫øt")
    print(f"üèÜ MAX STREAK DEBUG: Timeline: {unique_dates[0]} ‚Üí {unique_dates[-1]}")
    print(f"üèÜ MAX STREAK DEBUG: Chi ti·∫øt: {unique_dates[:10]}{'...' if len(unique_dates) > 10 else ''}")
    
    # ============================================================================
    # B∆Ø·ªöC 2: SLIDING WINDOW ALGORITHM
    # ============================================================================
    
    # ‚úÖ OPTIMIZATION: Initialize v·ªõi 1 thay v√¨ 0
    # V√¨ ng√†y ƒë·∫ßu ti√™n lu√¥n l√† streak c√≥ ƒë·ªô d√†i 1
    max_streak = current_streak = 1
    
    # Duy·ªát qua t·∫•t c·∫£ c·∫∑p ng√†y li√™n ti·∫øp trong timeline
    for i in range(1, len(unique_dates)):
        prev_date = unique_dates[i-1]   # Ng√†y tr∆∞·ªõc ƒë√≥
        curr_date = unique_dates[i]     # Ng√†y hi·ªán t·∫°i
        
        # ‚úÖ CORE LOGIC: Ki·ªÉm tra consecutive dates
        # Ch·ªâ nh·ªØng ng√†y c√°ch nhau ƒë√∫ng 1 ng√†y m·ªõi t√≠nh l√† li√™n ti·∫øp
        day_gap = (curr_date - prev_date).days
        
        if day_gap == 1:
            # ‚úÖ CONSECUTIVE: Ng√†y li√™n ti·∫øp
            current_streak += 1
            
            # ‚úÖ OPTIMIZATION: Update max_streak ngay trong loop
            # Thay v√¨ ƒë·ª£i ƒë·∫øn cu·ªëi loop, update ngay khi c√≥ streak m·ªõi
            max_streak = max(max_streak, current_streak)
            
            print(f"üèÜ MAX STREAK DEBUG: {prev_date}‚Üí{curr_date} li√™n ti·∫øp ‚Üí current={current_streak}, max={max_streak}")
            
        else:
            # ‚ùå GAP DETECTED: C√≥ kho·∫£ng tr·ªëng
            print(f"üèÜ MAX STREAK DEBUG: Gap {day_gap} ng√†y t·ª´ {prev_date}‚Üí{curr_date} ‚Üí reset streak")
            
            # Reset current streak v·ªÅ 1 (ng√†y hi·ªán t·∫°i b·∫Øt ƒë·∫ßu streak m·ªõi)
            current_streak = 1
            # L∆∞u √Ω: Kh√¥ng c·∫ßn update max_streak ·ªü ƒë√¢y v√¨ ƒë√£ update trong loop tr√™n
    
    # ============================================================================
    # B∆Ø·ªöC 3: RETURN RESULT
    # ============================================================================
    
    print(f"üèÜ MAX STREAK DEBUG: K·∫øt qu·∫£ cu·ªëi c√πng: max_streak = {max_streak}")
    return max_streak

def calculate_total_days(article_dates):
    """
    T√≠nh to√°n t·ªïng s·ªë ng√†y h·ªçc t·∫≠p t·ª´ ng√†y ƒë·∫ßu ti√™n ƒë·∫øn hi·ªán t·∫°i
    
    Thu·∫≠t to√°n:
    1. T√¨m ng√†y ƒë·∫ßu ti√™n c√≥ b√†i vi·∫øt (ng√†y xa nh·∫•t)
    2. T√≠nh s·ªë ng√†y t·ª´ ng√†y ƒë√≥ ƒë·∫øn hi·ªán t·∫°i
    3. Tr·∫£ v·ªÅ t·ªïng s·ªë ng√†y
    
    Args:
        article_dates (list): Danh s√°ch c√°c datetime object c·ªßa ng√†y t·∫°o b√†i vi·∫øt
        
    Returns:
        int: T·ªïng s·ªë ng√†y t·ª´ ng√†y ƒë·∫ßu ti√™n ƒë·∫øn hi·ªán t·∫°i
        
    V√≠ d·ª•:
        # B√†i vi·∫øt ƒë·∫ßu ti√™n: 1/1/2024, h√¥m nay: 15/1/2024
        dates = [datetime(2024,1,1), datetime(2024,1,15)]
        calculate_total_days(dates) -> 14 ng√†y
    """
    if not article_dates:
        return 0
    
    # T√¨m ng√†y ƒë·∫ßu ti√™n (xa nh·∫•t)
    first_date = min(article_dates).date()
    current_date = datetime.now().date()
    
    # T√≠nh s·ªë ng√†y
    total_days = (current_date - first_date).days + 1  # +1 ƒë·ªÉ bao g·ªìm c·∫£ ng√†y ƒë·∫ßu
    
    return max(1, total_days)  # √çt nh·∫•t l√† 1 ng√†y

def scan_domain_folder(domain_path):
    """Scan m·ªôt domain folder v√† tr·∫£ v·ªÅ th√¥ng tin"""
    if not os.path.exists(domain_path):
        return None
    
    domain_name = os.path.basename(domain_path)
    print(f"üìÅ SCAN DEBUG: ƒêang scan domain: {domain_name}")
    articles_count = 0
    total_words = 0
    article_dates = []
    last_activity = None
    
    # Duy·ªát qua t·∫•t c·∫£ file trong domain
    for root, dirs, files in os.walk(domain_path):
        for file in files:
            file_path = os.path.join(root, file)
            file_ext = Path(file).suffix.lower()
            
            if file_ext in SUPPORTED_EXTENSIONS:
                try:
                    # L·∫•y th√¥ng tin file
                    stat_info = os.stat(file_path)
                    creation_time = datetime.fromtimestamp(stat_info.st_ctime)
                    
                    # ƒê·∫øm t·ª´
                    word_count = estimate_word_count(file_path, file_ext)
                    
                    articles_count += 1
                    total_words += word_count
                    article_dates.append(creation_time)
                    
                    print(f"üìÑ FILE DEBUG: {file} - Ng√†y t·∫°o: {creation_time.date()} - T·ª´: {word_count}")
                    
                    if last_activity is None or creation_time > last_activity:
                        last_activity = creation_time
                        
                except Exception as e:
                    print(f"L·ªói khi ƒë·ªçc file {file}: {e}")
    
    # T√≠nh to√°n metrics
    xp = calculate_xp_from_articles(articles_count, total_words)
    level = calculate_level_from_xp(xp)
    streak_days = calculate_streak_days(article_dates)
    max_streak_days = calculate_max_historical_streak(article_dates)
    total_days = calculate_total_days(article_dates)
    
    return {
        'name': domain_name,
        'xp': xp,
        'level': level,
        'color': get_domain_color(domain_name),
        'taskCount': articles_count,  # S·ªë b√†i vi·∫øt
        'streakDays': streak_days,
        'maxStreakDays': max_streak_days,
        'totalDays': total_days,
        'lastTaskDate': last_activity.isoformat() if last_activity else datetime.now().isoformat(),
        'totalWords': total_words,
        'lastActivity': last_activity.isoformat() if last_activity else None
    }

def scan_all_domains():
    """Scan t·∫•t c·∫£ domain folders"""
    domains = {}
    
    if not os.path.exists(DATA_SCIENCE_PATH):
        return domains
    
    # T√¨m t·∫•t c·∫£ domain folders
    for item in os.listdir(DATA_SCIENCE_PATH):
        item_path = os.path.join(DATA_SCIENCE_PATH, item)
        
        if os.path.isdir(item_path) and item.startswith('Domain'):
            domain_data = scan_domain_folder(item_path)
            if domain_data:
                domains[domain_data['name']] = {
                    'xp': domain_data['xp'],
                    'level': domain_data['level'],
                    'color': domain_data['color'],
                    'taskCount': domain_data['taskCount'],
                    'streakDays': domain_data['streakDays'],
                    'maxStreakDays': domain_data['maxStreakDays'],
                    'totalDays': domain_data['totalDays'],
                    'lastTaskDate': domain_data['lastTaskDate']
                }
    
    return domains

@app.get("/")
async def root():
    """API root endpoint"""
    return {
        "message": "Domain Progress Tracker API",
        "version": "1.0.0",
        "docs": "/docs",
        "endpoints": {
            "domains": "/api/domains",
            "refresh": "/api/domains/refresh", 
            "stats": "/api/domains/stats"
        }
    }

@app.get("/api/domains", response_model=DomainsResponse)
async def get_domains():
    """API endpoint ƒë·ªÉ l·∫•y danh s√°ch domains v·ªõi XP/Level"""
    try:
        domains = scan_all_domains()
        
        return DomainsResponse(
            success=True,
            domains=domains,
            count=len(domains),
            last_scan=datetime.now().isoformat()
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/domains/refresh", response_model=DomainsResponse)
async def refresh_domains():
    """API endpoint ƒë·ªÉ refresh domain data"""
    try:
        domains = scan_all_domains()
        
        return DomainsResponse(
            success=True,
            domains=domains,
            count=len(domains),
            last_scan=datetime.now().isoformat()
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/domains/stats", response_model=StatsResponse)
async def get_domain_stats():
    """API endpoint ƒë·ªÉ l·∫•y th·ªëng k√™ t·ªïng quan"""
    try:
        domains = scan_all_domains()
        
        total_articles = sum(domain['taskCount'] for domain in domains.values())
        total_xp = sum(domain['xp'] for domain in domains.values())
        total_levels = sum(domain['level'] for domain in domains.values())
        
        # Domain c√≥ level cao nh·∫•t
        highest_level_domain = max(domains.items(), key=lambda x: x[1]['level']) if domains else None
        
        # Domain c√≥ nhi·ªÅu b√†i vi·∫øt nh·∫•t
        most_articles_domain = max(domains.items(), key=lambda x: x[1]['taskCount']) if domains else None
        
        return StatsResponse(
            success=True,
            stats={
                'total_domains': len(domains),
                'total_articles': total_articles,
                'total_xp': total_xp,
                'total_levels': total_levels,
                'average_level': total_levels / len(domains) if domains else 0,
                'highest_level_domain': highest_level_domain,
                'most_articles_domain': most_articles_domain
            },
            last_scan=datetime.now().isoformat()
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == '__main__':
    import uvicorn
    
    print("üöÄ Starting Domain Progress Tracker Server (FastAPI)...")
    print(f"üìÅ Scanning path: {DATA_SCIENCE_PATH}")
    print("üåê Server will be available at: http://localhost:8000")
    print("üìñ API Documentation: http://localhost:8000/docs")
    print("üìñ API endpoints:")
    print("  - GET /api/domains - Get all domains with XP/Level")
    print("  - POST /api/domains/refresh - Refresh domain data")
    print("  - GET /api/domains/stats - Get domain statistics")
    
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
