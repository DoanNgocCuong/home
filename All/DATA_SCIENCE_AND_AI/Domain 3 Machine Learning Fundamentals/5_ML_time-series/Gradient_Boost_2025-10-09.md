https://lms.aivietnam.edu.vn/api/files/683184ca519c0e157fb514cd/Documents%2F2025-8%2FM04W02%20-%20Gradient%20Boosting%2FAIO2025_GradientBoosting_v2.pdf

1. T·∫°i sao d√πng gi√° tr·ªã trung b√¨nh?
2. Residual Error?
3. 

![1757513306598](image/Gradient_Boost_2025-10-09/1757513306598.png)

Kh·ªüi t·∫°o Gradient Boost t·∫°i gi√° tr·ªã trung b√¨nh v√¨ t·∫°i ƒë√≥ lost b√© nh·∫•t.

dSSR/d theta = - (...) V√¨ ƒë·ªÉ lost gi·∫£m n√™n ƒë·∫°o hfn

![1757511829580](image/Gradient_Boost_2025-10-09/1757511829580.png)

![1757514765568](image/Gradient_Boost_2025-10-09/1757514765568.png)

---

![1757514465545](image/Gradient_Boost_2025-10-09/1757514465545.png)

```python
from sklearn.model_selection import TimeSeriesSplit, GridSearchCV
from sklearn.ensemble import GradientBoostingRegressor

# XGBoost
cv_split = TimeSeriesSplit(n_splits=4, test_size=100)
model = GradientBoostingRegressor()
parameters = {
    "max_features": [3, 4, 5],
    "learning_rate": [0.01, 0.05],
    "n_estimators": [100, 300]
}

grid_search = GridSearchCV(estimator=model, cv=cv_split, param_grid=parameters)
grid_search.fit(X_train, y_train)

```

---

![1757514975500](image/Gradient_Boost_2025-10-09/1757514975500.png)

---

![1757515897580](image/Gradient_Boost_2025-10-09/1757515897580.png)

---

![1757516512672](image/Gradient_Boost_2025-10-09/1757516512672.png)

![1757516913998](image/Gradient_Boost_2025-10-09/1757516913998.png)

```python

# Import Library
import numpy as np
import pandas as pd
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    confusion_matrix
)

# Load dataset
data = load_breast_cancer()
X = data.data
y = data.target

# Chuy·ªÉn th√†nh DataFrame ƒë·ªÉ d·ªÖ quan s√°t
df = pd.DataFrame(X, columns=data.feature_names)
df['target'] = y
print(df.head())

# Split data to train/test (gi·ªØ t·ª∑ l·ªá l·ªõp b·∫±ng stratify)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print("\nS·ªë l∆∞·ª£ng m·∫´u train:", X_train.shape[0])
print("S·ªë l∆∞·ª£ng m·∫´u test:", X_test.shape[0])

# Kh·ªüi t·∫°o m√¥ h√¨nh c∆° b·∫£n
gb = GradientBoostingClassifier(random_state=42)

# L∆∞·ªõi tham s·ªë
param_grid = {
    'n_estimators': [50, 100, 200],
    'learning_rate': [0.01, 0.05, 0.1],
    'max_depth': [2, 3, 4],
    'subsample': [0.8, 1.0]
}

# GridSearch v·ªõi cross-validation = 5
grid_search = GridSearchCV(
    estimator=gb,
    param_grid=param_grid,
    cv=5,
    n_jobs=-1,
    scoring='accuracy',
    verbose=2
)

# Train GridSearch
grid_search.fit(X_train, y_train)

# Get model with best hyperparameter
print("Best parameters:", grid_search.best_params_)
print("Best cross-validation accuracy:", grid_search.best_score_)

best_gb = grid_search.best_estimator_

# Evaluate on test set
y_pred = best_gb.predict(X_test)

print("Test Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=data.target_names))

```

---

# 14/09/2025

1. H√†m loss c·ªßa n√≥?
2. V√≠ d·ª•:
3. init
   v

```
C√°ch kh·ªüi t·∫°o learning rate?

ƒê·ªÉ √Ω learning rate m·∫∑c ƒë·ªãnh c·ªßa c√°c th∆∞ vi·ªán

Kh·ªüi t·∫°o learning rate theo c√°c gi·∫£i thu·∫≠t ƒë·∫∑c bi·ªát?

```

![1757857978330](image/Gradient_Boost_2025-10-09/1757857978330.png)![1757857737995](image/Gradient_Boost_2025-10-09/1757857737995.png)

- **ƒê·ªãnh nghƒ©a**: `n_estimators` ƒë·∫°i di·ªán cho s·ªë l∆∞·ª£ng c√¢y quy·∫øt ƒë·ªãnh (decision trees) m√† m√¥ h√¨nh s·∫Ω t·∫°o ra. M·ªói c√¢y trong m√¥ h√¨nh s·∫Ω h·ªçc t·ª´ m·ªôt ph·∫ßn c·ªßa d·ªØ li·ªáu v√† ƒë√≥ng g√≥p v√†o d·ª± ƒëo√°n cu·ªëi c√πng.
- `verbose=1`  tham s·ªë verbose n√≥i chung trong CS th∆∞·ªùng mang √Ω nghƒ©a l√† th√¥ng tin chi ti·∫øt: th∆∞·ªùng d√πng trong g·ª° l·ªói, gi√°m s√°t, chi ti·∫øt th√™m th√¥ng tin v·ªÅ 1 qu√° tr√¨nh ƒëang di·ªÖn ra n√†o ƒë·∫•y

![1757859178368](image/Gradient_Boost_2025-10-09/1757859178368.png)

![1757860129488](image/Gradient_Boost_2025-10-09/1757860129488.png)

M√¨nh gi·∫£i th√≠ch chi ti·∫øt h√¨nh XGBoost b·∫°n g·ª≠i nh√©:

---

## 1. Ng·ªØ c·∫£nh v√≠ d·ª•

- D·ªØ li·ªáu c√≥ 4 ƒëi·ªÉm:

  ```
  X   Y
  23  0
  24  0
  26  1
  27  1
  ```
- Tham s·ªë: Œª=0\lambda = 0, ƒë·ªô s√¢u c√¢y = 1 (stump), learning rate (Œ∑) = 0.3.

M·ª•c ti√™u: D·ª± ƒëo√°n cho X=25.8X = 25.8.

---

## 2. B∆∞·ªõc kh·ªüi t·∫°o

- Tr∆∞·ªõc ti√™n, XGBoost kh·ªüi t·∫°o x√°c su·∫•t ban ƒë·∫ßu cho t·∫•t c·∫£ m·∫´u b·∫±ng **t·∫ßn su·∫•t l·ªõp d∆∞∆°ng**.
- ·ªû ƒë√¢y c√≥ 2/4 m·∫´u thu·ªôc l·ªõp 1 ‚Üí x√°c su·∫•t kh·ªüi t·∫°o = 0.5.
- Log-odds kh·ªüi t·∫°o:

  log‚Å°0.51‚àí0.5=0\log\frac{0.5}{1-0.5} = 0

  ‚Üí First prediction = 0 (logit).

---

## 3. X√¢y c√¢y ƒë·∫ßu ti√™n (depth = 1)

- C√¢y chia t·∫°i ng∆∞·ª°ng X<25X < 25.
- N√∫t tr√°i: Output = -2.0 (cho c√°c ƒëi·ªÉm 23, 24).
- N√∫t ph·∫£i: Output = 2.0 (cho c√°c ƒëi·ªÉm 26, 27).

C√°c output n√†y th·ª±c ch·∫•t ƒë·∫øn t·ª´ vi·ªác t√≠nh gradient v√† hessian c·ªßa loss tr√™n residuals.

---

## 4. D·ª± ƒëo√°n cho X=25.8X = 25.8

- V√¨ 25.8>2525.8 > 25 ‚Üí ƒëi nh√°nh ph·∫£i ‚Üí gi√° tr·ªã l√° = +2.0.
- V·ªõi learning rate Œ∑ = 0.3, gi√° tr·ªã c·∫≠p nh·∫≠t = 0.3√ó2.0=0.60.3 \times 2.0 = 0.6.
- Log prediction sau c·∫≠p nh·∫≠t:

  LogPrediction=0+0.6=0.6\text{LogPrediction} = 0 + 0.6 = 0.6

---

## 5. Chuy·ªÉn logit ‚Üí x√°c su·∫•t

- X√°c su·∫•t d·ª± ƒëo√°n:

  P=e0.61+e0.6‚âà0.6457P = \frac{e^{0.6}}{1 + e^{0.6}} \approx 0.6457

---

## 6. √ù nghƒ©a

- Quy tr√¨nh n√†y minh ho·∫° c√°ch XGBoost:

  1. B·∫Øt ƒë·∫ßu b·∫±ng log-odds t·ª´ ph√¢n b·ªë l·ªõp.
  2. C·∫≠p nh·∫≠t log-odds b·∫±ng c√°c c√¢y nh·ªè (weighted by learning rate).
  3. Bi·∫øn ƒë·ªïi log-odds th√†nh x√°c su·∫•t d·ª± ƒëo√°n qua sigmoid.

---

üëâ B·∫°n c√≥ mu·ªën m√¨nh vi·∫øt l·∫°i v√≠ d·ª• n√†y d∆∞·ªõi d·∫°ng **b·∫£ng t·ª´ng b∆∞·ªõc (kh·ªüi t·∫°o ‚Üí ch·ªçn nh√°nh ‚Üí c·∫≠p nh·∫≠t logit ‚Üí x√°c su·∫•t)** ƒë·ªÉ h·ªçc vi√™n d·ªÖ theo d√µi h∆°n kh√¥ng?
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

- [XGBoost Documentation ‚Äî xgboost 0.4 documentation](https://xgboost-clone.readthedocs.io/en/latest/)
- 

![1757861228498](image/Gradient_Boost_2025-10-09/1757861228498.png)

ƒê√∫ng r·ªìi üëå, b·∫°n hi·ªÉu ch√≠nh x√°c:

Trong  **histogram** , **bin** l√† **kho·∫£ng gi√° tr·ªã (interval)** m√† ta d√πng ƒë·ªÉ gom d·ªØ li·ªáu l·∫°i tr∆∞·ªõc khi ƒë·∫øm t·∫ßn su·∫•t.

---

## 1. V√≠ d·ª•

Gi·∫£ s·ª≠ c√≥ ƒëi·ªÉm s·ªë t·ª´ 0 ƒë·∫øn 10:

* N·∫øu ta ch·ªçn bin width = 2 ‚Üí c√°c bin s·∫Ω l√†:

  [0,2),[2,4),[4,6),[6,8),[8,10][0,2), [2,4), [4,6), [6,8), [8,10]
* M·ªôt h·ªçc sinh c√≥ ƒëi·ªÉm 3.6 s·∫Ω r∆°i v√†o bin  **[2,4)** .

---

## 2. √ù nghƒ©a

* **Bin nh·ªè (width h·∫πp):** histogram chi ti·∫øt, d·ªÖ th·∫•y bi·∫øn ƒë·ªông, nh∆∞ng d·ªÖ nhi·ªÖu.
* **Bin l·ªõn (width r·ªông):** histogram m∆∞·ª£t h∆°n, d·ªÖ th·∫•y xu h∆∞·ªõng, nh∆∞ng m·∫•t chi ti·∫øt.

---

## 3. C√¥ng th·ª©c t·ªïng qu√°t

N·∫øu c√≥ nn bin v√† d·ªØ li·ªáu n·∫±m trong kho·∫£ng [xmin,xmax][x_{min}, x_{max}]:

* **ƒê·ªô r·ªông bin (bin width):**

  w=xmax‚àíxminnw = \frac{x_{max} - x_{min}}{n}
* M·ªói bin l√† [xmin+k‚ãÖw,‚ÄÖ‚Ääxmin+(k+1)‚ãÖw)[x_{min} + k \cdot w, \; x_{min} + (k+1) \cdot w) v·ªõi k=0,1,‚Ä¶,n‚àí1k = 0,1,\ldots,n-1.

---

## 4. ·ª®ng d·ª•ng

* Tr·ª±c quan ho√° d·ªØ li·ªáu (EDA).
* L√†m s·∫°ch ho·∫∑c bi·∫øn ƒë·ªïi feature (binning tr∆∞·ªõc khi train).
* Trong boosting (nh∆∞ LightGBM), histogram-based learning d√πng ‚Äúbin‚Äù ƒë·ªÉ tƒÉng t·ªëc t√¨m split.

---

üëâ B·∫°n c√≥ mu·ªën m√¨nh vi·∫øt th√™m m·ªôt **v√≠ d·ª• b·∫±ng Python + matplotlib** ƒë·ªÉ v·∫Ω histogram v√† highlight c√°c bin, ƒë·ªÉ tr·ª±c quan h∆°n kh√¥ng?

---

N·∫øu c√≥ n bin, v√† d·ªØ li·ªáu n·∫±m trong [x_min, x_max]
=> bin_width = w = (x_max - x_min) /n



---

![1758723346397](image/Gradient_Boost_2025-10-09/1758723346397.png)


![1758723663905](image/Gradient_Boost_2025-10-09/1758723663905.png)


![1758723965649](image/Gradient_Boost_2025-10-09/1758723965649.png)


![1758724059541](image/Gradient_Boost_2025-10-09/1758724059541.png)
