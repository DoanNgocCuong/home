# Bagging 


MÃ¬nh giáº£i thÃ­ch ngáº¯n â€“ dá»… nhá»› nhÃ©.

# Bagging lÃ  gÃ¬ (trong Random Forest)?

 **Bagging = Bootstrap Aggregating** . Ã tÆ°á»Ÿng: táº¡o **nhiá»u bá»™ dá»¯ liá»‡u con** báº±ng cÃ¡ch **láº¥y máº«u cÃ³ hoÃ n láº¡i (bootstrap)** tá»« dá»¯ liá»‡u gá»‘c, huáº¥n luyá»‡n **nhiá»u cÃ¢y** Ä‘á»™c láº­p trÃªn cÃ¡c máº«u nÃ y, rá»“i  **gá»™p dá»± Ä‘oÃ¡n** :

* PhÃ¢n loáº¡i: láº¥y  **Ä‘a sá»‘ phiáº¿u** .
* Há»“i quy: láº¥y  **trung bÃ¬nh** .

# VÃ¬ sao lÃ m váº­y?

* CÃ¡c cÃ¢y há»c tá»« nhá»¯ng máº«u khÃ¡c nhau â†’ **Ã­t tÆ°Æ¡ng quan** vá»›i nhau.
* Khi gá»™p láº¡i,  **phÆ°Æ¡ng sai (variance) giáº£m máº¡nh** , dá»± Ä‘oÃ¡n á»•n Ä‘á»‹nh hÆ¡n â†’ mÃ´ hÃ¬nh Ã­t â€œquÃ¡ khá»›pâ€ hÆ¡n so vá»›i má»™t cÃ¢y Ä‘Æ¡n láº».

# CÃ¡c bÆ°á»›c bagging trong Random Forest

1. Láº·p B láº§n (vÃ­ dá»¥ 100 cÃ¢y):
   * Láº¥y 1 máº«u bootstrap (cÃ¹ng kÃ­ch thÆ°á»›c,  **cÃ³ hoÃ n láº¡i** ).
   * Huáº¥n luyá»‡n má»™t cÃ¢y quyáº¿t Ä‘á»‹nh trÃªn máº«u nÃ y.
   * (Äáº·c trÆ°ng RF cÃ²n **random feature** á»Ÿ má»—i nÃºt: chá»‰ xÃ©t k Ä‘áº·c trÆ°ng ngáº«u nhiÃªn khi tÃ¡ch â€“ Ä‘Ã´i khi gá»i lÃ   *feature bagging* .)
2. Khi dá»± Ä‘oÃ¡n: cho Ä‘iá»ƒm má»›i Ä‘i qua **táº¥t cáº£** cÃ¢y â†’ gá»™p káº¿t quáº£.

# Bonus: OOB (Out-of-Bag)

VÃ¬ láº¥y máº«u cÃ³ hoÃ n láº¡i, khoáº£ng **~36%** Ä‘iá»ƒm gá»‘c **khÃ´ng xuáº¥t hiá»‡n** trong má»—i bootstrap. Ta dÃ¹ng chÃ­nh cÃ¡c Ä‘iá»ƒm â€œbá»‹ bá» quÃªnâ€ nÃ y Ä‘á»ƒ **Ä‘Ã¡nh giÃ¡ sai sá»‘ OOB** â€“ gáº§n nhÆ° má»™t phÃ©p cross-validation â€œmiá»…n phÃ­â€.

# So vá»›i boosting thÃ¬ sao?

* **Bagging** : cÃ¡c cÃ¢y  **Ä‘á»™c láº­p** , gá»™p Ä‘á»ƒ  **giáº£m variance** .
* **Boosting** : cÃ¡c cÃ¢y  **tuáº§n tá»±** , cÃ¢y sau sá»­a lá»—i cÃ¢y trÆ°á»›c â†’  **giáº£m bias** , nhÆ°ng dá»… quÃ¡ khá»›p náº¿u khÃ´ng regularize.

---

Má»™t cÃ¢u check nhanh: theo báº¡n,  **bagging chá»§ yáº¿u giáº£m bias hay giáº£m variance** ? (chá»n má»™t)

Náº¿u thÃ­ch, mÃ¬nh lÃ m luÃ´n má»™t vÃ­ dá»¥ sá»‘ nhá» Ä‘á»ƒ báº¡n tháº¥y rÃµ hiá»‡u á»©ng gá»™p.


---



B. ÄÃºng â€” Random Forest dÃ¹ng bootstrap (má»—i cÃ¢y huáº¥n luyá»‡n trÃªn má»™t máº«u dá»¯ liá»‡u khÃ¡c nhau) Ä‘á»ƒ tÄƒng Ä‘a dáº¡ng.

C. ÄÃºng â€” á» má»—i nÃºt chá»‰ xÃ©t má»™t táº­p con Ä‘áº·c trÆ°ng ngáº«u nhiÃªn (feature bagging), tiáº¿p tá»¥c tÄƒng Ä‘a dáº¡ng giá»¯a cÃ¡c cÃ¢y.

Sao C láº¡i Ä‘Ãºng ?

---

C Ä‘Ãºng vÃ¬ Ä‘Ã¢y chÃ­nh lÃ  â€œfeature baggingâ€ â€“ cÆ¡ cháº¿ cá»‘t lÃµi thá»© hai cá»§a Random Forest.

* á»  **má»—i nÃºt tÃ¡ch** , thay vÃ¬ xÃ©t táº¥t cáº£ (p) Ä‘áº·c trÆ°ng, rá»«ng chá»‰ **láº¥y ngáº«u nhiÃªn má»™t táº­p con** (kÃ­ch thÆ°á»›c (m_\text{try})) Ä‘á»ƒ tÃ¬m split tá»‘t nháº¥t.
* Viá»‡c **giá»›i háº¡n & ngáº«u nhiÃªn hoÃ¡ Ä‘áº·c trÆ°ng** lÃ m cÃ¡c cÃ¢y Ã­t dÃ¹ng cÃ¹ng má»™t Ä‘áº·c trÆ°ng/split â‡’ **giáº£m tÆ°Æ¡ng quan giá»¯a cÃ¢y** â‡’ tÄƒng **Ä‘a dáº¡ng** cá»§a rá»«ng, giÃºp tá»•ng há»£p (bá» phiáº¿u/trung bÃ¬nh) giáº£m phÆ°Æ¡ng sai.

Má»™t vÃ i Ä‘iá»ƒm cá»¥ thá»ƒ:

* Náº¿u cÃ³ má»™t Ä‘áº·c trÆ°ng â€œquÃ¡ máº¡nhâ€, xÃ©t toÃ n bá»™ (p) Ä‘áº·c trÆ°ng sáº½ khiáº¿n **má»i cÃ¢y giá»‘ng nhau** (Ä‘á»u chá»n Ä‘áº·c trÆ°ng Ä‘Ã³ á»Ÿ gáº§n gá»‘c). Giáº£m vá» (m_\text{try}) khiáº¿n Ä‘áº·c trÆ°ng máº¡nh  **Ä‘Ã´i khi khÃ´ng Ä‘Æ°á»£c Ä‘Æ°a vÃ o danh sÃ¡ch xÃ©t** , buá»™c cÃ¢y chá»n hÆ°á»›ng khÃ¡c â†’ Ä‘a dáº¡ng hÆ¡n.
* **Äiá»u chá»‰nh (m_\text{try})** lÃ  nÃºt chá»‰nh â€œÄ‘a dáº¡ng â†” sá»©c máº¡nh cÃ¢yâ€:
  * (m_\text{try}) **nhá»** â†’  **Ä‘a dáº¡ngâ†‘** , tÆ°Æ¡ng quanâ†“ (nhÆ°ng má»—i cÃ¢y yáº¿u hÆ¡n chÃºt).
  * (m_\text{try}) **lá»›n** â†’ cÃ¢y máº¡nh hÆ¡n, nhÆ°ng tÆ°Æ¡ng quanâ†‘, Ä‘a dáº¡ngâ†“.
* Thá»±c táº¿ hay dÃ¹ng:  **classification** : (m_\text{try}\approx \sqrt{p});  **regression** : (m_\text{try}\approx p/3) (chá»‰ lÃ  kinh nghiá»‡m, cÃ³ thá»ƒ tune).

LÆ°u Ã½ vá» cÃ¢u chá»¯: â€œ **thay Ä‘á»•i sá»‘ lÆ°á»£ng Ä‘áº·c trÆ°ng táº¡i má»—i nÃºt** â€ á»Ÿ Ä‘Ã¢y nÃªn hiá»ƒu lÃ  **khÃ´ng xÃ©t toÃ n bá»™ Ä‘áº·c trÆ°ng** mÃ  **chá»‰ xÃ©t má»™t sá»‘ lÆ°á»£ng (mtry) nhá», Ä‘Æ°á»£c chá»n ngáº«u nhiÃªn** á»Ÿ  **má»—i nÃºt** . Sá»‘ lÆ°á»£ng (m_\text{try}) cÃ³ thá»ƒ giá»¯ **cá»‘ Ä‘á»‹nh** cho cáº£ cÃ¢y/rá»«ng (chuáº©n RF), nhÆ°ng  **táº­p Ä‘áº·c trÆ°ng Ä‘Æ°á»£c rÃºt thÄƒm thÃ¬ thay Ä‘á»•i theo tá»«ng nÃºt** , vÃ  chÃ­nh Ä‘iá»u Ä‘Ã³ táº¡o Ä‘a dáº¡ng.


---



Ok, nÃ³i â€œdá»… nuá»‘tâ€ nÃ¨ ğŸ˜„

## VÃ¬ sao C Ä‘Ãºng?

**C: â€œThay vÃ¬ xÃ©t táº¥t cáº£ Ä‘áº·c trÆ°ng, má»—i nÃºt chá»‰ xÃ©t Má»˜T NHÃ“M Äáº¶C TRÆ¯NG NGáºªU NHIÃŠN (mtry).â€**

â†’ ÄÃ¢y gá»i lÃ  **feature bagging** â€“ máº¹o chÃ­nh cá»§a Random Forest Ä‘á»ƒ  **lÃ m cÃ¡c cÃ¢y khÃ¡c nhau** .

### HÃ¬nh dung Ä‘Æ¡n giáº£n

* Náº¿u **xÃ©t táº¥t cáº£ Ä‘áº·c trÆ°ng** á»Ÿ má»i nÃºt, â€œÄ‘áº·c trÆ°ng máº¡nh nháº¥tâ€ sáº½ **luÃ´n** Ä‘Æ°á»£c chá»n á»Ÿ gáº§n gá»‘c â†’ **cÃ¡c cÃ¢y giá»‘ng nhau** â†’ dá»± Ä‘oÃ¡n bá» phiáº¿u cÅ©ngâ€¦ giá»‘ng nhau â‡’  **Ã­t Ä‘a dáº¡ng** .
* Khi **má»—i nÃºt chá»‰ Ä‘Æ°á»£c bá»‘c thÄƒm vÃ i Ä‘áº·c trÆ°ng** (vÃ­ dá»¥ 2 trong tá»•ng 10):
  * Nhiá»u nÃºt **khÃ´ng tháº¥y** Ä‘áº·c trÆ°ng máº¡nh nháº¥t trong danh sÃ¡ch â†’ buá»™c pháº£i chá»n Ä‘áº·c trÆ°ng khÃ¡c.
  * Má»—i cÃ¢y Ä‘i theo **nhÃ¡nh khÃ¡c nhau** â†’ **Ä‘a dáº¡ng** â†‘, **tÆ°Æ¡ng quan giá»¯a cÃ¢y** â†“ â†’ gá»™p láº¡i ( **Ä‘a sá»‘/trung bÃ¬nh** ) sáº½ **á»•n Ä‘á»‹nh hÆ¡n** (giáº£m variance).

### VÃ­ dá»¥ 10s

Giáº£ sá»­ cÃ³ 5 Ä‘áº·c trÆ°ng: A (ráº¥t máº¡nh), B,C,D,E.

* Náº¿u xÃ©t **táº¥t cáº£ 5** á»Ÿ gá»‘c: cÃ¢y nÃ o cÅ©ng chá»n **A** â†’ cÃ¢y na nÃ¡ nhau.
* Náº¿u má»—i nÃºt chá»‰ xÃ©t  **mtry = 2** : Ä‘Ã´i khi gá»‘c **khÃ´ng cÃ³ A** trong danh sÃ¡ch â†’ cÃ¢y Ä‘Ã³ chá»n B hoáº·c Câ€¦ â†’ rá»«ng Ä‘a dáº¡ng.

### Ghi nhá»› nhanh

* **mtry nhá»** â†’ Ä‘a dáº¡ng â†‘ (má»—i cÃ¢y yáº¿u hÆ¡n chÃºt, cáº£ rá»«ng á»•n Ä‘á»‹nh hÆ¡n).
* **mtry lá»›n** â†’ má»—i cÃ¢y máº¡nh hÆ¡n nhÆ°ng giá»‘ng nhau hÆ¡n (Ä‘a dáº¡ng â†“).
* Kinh nghiá»‡m: phÃ¢n loáº¡i dÃ¹ng  **mtry â‰ˆ âˆšp** , há»“i quy dÃ¹ng **mtry â‰ˆ p/3** (tune thÃªm tÃ¹y bÃ i).

=> NÃªn C Ä‘Ãºng, vÃ¬ **giá»›i háº¡n & rÃºt thÄƒm Ä‘áº·c trÆ°ng á»Ÿ má»—i nÃºt** chÃ­nh lÃ  cÃ¡ch Random Forest táº¡o  **Ä‘a dáº¡ng giá»¯a cÃ¡c cÃ¢y** .



---

![1759071136852](image/.md/1759071136852.png)


**B. 4 â†’ 6 â†’ 5 â†’ 1 â†’ 3 â†’ 2.**

* **4** : Táº¡o N bootstrap tá»« dá»¯ liá»‡u gá»‘c.
* **6** : Vá»›i má»—i bootstrap, xÃ¢y má»™t cÃ¢y quyáº¿t Ä‘á»‹nh.
* **5** : á» má»—i nÃºt, chá»n ngáº«u nhiÃªn k (á»Ÿ Ä‘á» lÃ  2) Ä‘áº·c trÆ°ng ( *feature bagging* ).
* **1** : TÃ­nh Gini/Entropy Ä‘á»ƒ chá»n split tá»‘t nháº¥t.
* **3** : (náº¿u theo quy trÃ¬nh Ä‘á» bÃ i) loáº¡i Ä‘áº·c trÆ°ng Ä‘Ã£ chá»n trong nÃºt Ä‘Ã³.
* **2** : Láº·p quÃ¡ trÃ¬nh cho tá»›i khi Ä‘iá»u kiá»‡n dá»«ng thá»a.

---

![1759071289750](image/.md/1759071289750.png)


---

https://www.youtube.com/shorts/dpEO0RnrI38

---



**ÄÃ¡p Ã¡n Ä‘Ãºng: D.**

**VÃ¬ sao?**

Vá» máº·t thuáº­t toÃ¡n, rá»«ng ngáº«u nhiÃªn (RF) lÃ  táº­p há»£p cÃ¡c  **cÃ¢y quyáº¿t Ä‘á»‹nh** . Nhiá»u biáº¿n thá»ƒ cÃ¢y xá»­ lÃ½ thiáº¿u ngay **trong quÃ¡ trÃ¬nh xÃ¢y cÃ¢y** báº±ng cÃ¡c ká»¹ thuáº­t ná»™i suy/Ä‘á»‹nh tuyáº¿n, vÃ­ dá»¥:

* **Surrogate split (CART):** náº¿u táº¡i má»™t nÃºt máº«u bá»‹ thiáº¿u á»Ÿ biáº¿n tÃ¡ch chÃ­nh, cÃ¢y dÃ¹ng má»™t biáº¿n â€œsurrogateâ€ (Ä‘Æ°á»£c há»c sáºµn vÃ¬ cho hÆ°á»›ng ráº½ gáº§n giá»‘ng) Ä‘á»ƒ quyáº¿t Ä‘á»‹nh Ä‘i trÃ¡i/pháº£i.
* **PhÃ¢n luá»“ng theo trá»ng sá»‘ (C4.5):** khi gáº·p giÃ¡ trá»‹ thiáº¿u, máº«u Ä‘Æ°á»£c gá»­i xuá»‘ng **cáº£ hai nhÃ¡nh** vá»›i trá»ng sá»‘ theo phÃ¢n bá»‘ dá»¯ liá»‡u Ä‘Ã£ biáº¿t; dá»± Ä‘oÃ¡n lÃ  bá» phiáº¿u/trung bÃ¬nh  **cÃ³ trá»ng sá»‘** .
* ( **RF-specific** ) **Proximity imputation:** táº­n dá»¥ng Ä‘á»™ gáº§n (máº«u cÃ¹ng rÆ¡i vÃ o cÃ¡c lÃ¡) Ä‘á»ƒ Ä‘iá»n thiáº¿u láº·p bÃªn trong quy trÃ¬nh huáº¥n luyá»‡n.

=> Nhá»¯ng cÆ¡ cháº¿ nÃ y lÃ  **xá»­ lÃ½ ná»™i táº¡i** (ná»™i suy/Ä‘á»‹nh tuyáº¿n) chá»© khÃ´ng cáº§n Ä‘iá»n trÆ°á»›c.

**VÃ¬ sao cÃ¡c phÆ°Æ¡ng Ã¡n khÃ¡c sai?**

* **A.** Sai: nÃ³i â€œkhÃ´ng thá»ƒâ€ lÃ  quÃ¡ tuyá»‡t Ä‘á»‘i. Thuáº­t toÃ¡n cÃ¢y/RF *cÃ³* cÃ¡c cÆ¡ cháº¿ ná»™i táº¡i nÃªu trÃªn.
* **B.** Sai: Ä‘iá»n báº±ng trung bÃ¬nh lÃ  **tiá»n xá»­ lÃ½** (imputation ngoÃ i mÃ´ hÃ¬nh), khÃ´ng pháº£i kháº£ nÄƒng ná»™i táº¡i cá»§a RF.
* **C.** Sai: RF/cÃ¢y khÃ´ng â€œtá»± Ä‘á»™ng bá» quaâ€ máº«u thiáº¿u; náº¿u lÃ m váº­y vá»«a máº¥t dá»¯ liá»‡u vá»«a sai báº£n cháº¥t.

TÃ³m láº¡i, xÃ©t vá»  **cÆ¡ cháº¿ thuáº­t toÃ¡n** , phÆ°Æ¡ng Ã¡n **D** lÃ  chÃ­nh xÃ¡c.


---

# CÃ¢u 34



**CÃ¢u há»i (AIO25M04RF10):**

â€œSo vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p ensemble khÃ¡c nhÆ°  **Gradient Boosting** , **Random Forest** thÆ°á»ng cÃ³ **Æ°u Ä‘iá»ƒm** gÃ¬ khi xá»­ lÃ½ dá»¯ liá»‡u lá»›n vÃ  Ä‘a dáº¡ng?â€

**Chá»n Ä‘Ãºng:** **A** vÃ   **C** .

---

### A. *Random Forest khÃ³ bá»‹ overfitting hÆ¡n.* âœ…

* **ÄÃºng (thÆ°á»ng Ä‘Ãºng).** RF dÃ¹ng **bagging** + **láº¥y máº«u Ä‘áº·c trÆ°ng ngáº«u nhiÃªn** â†’ giáº£m **tÆ°Æ¡ng quan giá»¯a cÃ¢y** vÃ   **giáº£m phÆ°Æ¡ng sai** , nÃªn **Ã­t overfit** hÆ¡n má»™t cÃ¢y Ä‘Æ¡n láº» vÃ  thÆ°á»ng **á»•n Ä‘á»‹nh hÆ¡n** so vá»›i boosting (boosting dá»… â€œÄ‘uá»•i theoâ€ nhiá»…u náº¿u khÃ´ng regularize tá»‘t).
* **Pháº£n biá»‡n:** RF **khÃ´ng miá»…n nhiá»…m** overfit (vÃ­ dá»¥ cÃ¢y quÃ¡ sÃ¢u, lÃ¡ quÃ¡ nhá», quÃ¡ nhiá»u cÃ¢y váº«n cÃ³ thá»ƒ khá»›p nhiá»…u).

### B. *Random Forest cÃ³ thá»i gian huáº¥n luyá»‡n nhanh hÆ¡n.* âŒ

* **Sai/khÃ´ng luÃ´n Ä‘Ãºng.** RF **cÃ³ thá»ƒ** nhanh náº¿u  **cháº¡y song song** , nhÆ°ng **khÃ´ng Ä‘áº£m báº£o** nhanh hÆ¡n boosting vá» wall-clock. Boosting thÆ°á»ng dÃ¹ng **cÃ¢y nÃ´ng** vÃ  cÃ¡c thÆ° viá»‡n tá»‘i Æ°u (XGBoost/LightGBM) nÃªn **nhiá»u bÃ i toÃ¡n lá»›n láº¡i nhanh hÆ¡n** RF.
* **Káº¿t luáº­n:** tá»‘c Ä‘á»™  **phá»¥ thuá»™c cáº¥u hÃ¬nh & triá»ƒn khai** , khÃ´ng pháº£i Æ°u Ä‘iá»ƒm cá»‘ há»¯u.

### C. *Random Forest cÃ³ thá»ƒ song song hÃ³a dá»… dÃ ng hÆ¡n do cÃ¡c cÃ¢y Ä‘á»™c láº­p.* âœ…

* **ÄÃºng.** CÃ¡c cÃ¢y trong RF Ä‘Æ°á»£c huáº¥n luyá»‡n **Ä‘á»™c láº­p** trÃªn  **bootstrap khÃ¡c nhau** , nÃªn cÃ³ thá»ƒ **phÃ¢n luá»“ng/Ä‘Æ°a lÃªn nhiá»u CPU/GPU** ráº¥t â€œdá»… chá»‹uâ€ ( *embarrassingly parallel* ). Boosting thÃ¬ **tuáº§n tá»±** (cÃ¢y sau phá»¥ thuá»™c cÃ¢y trÆ°á»›c) nÃªn **khÃ³ song song hÃ³a** theo chiá»u cÃ¢y.

### D. *Random Forest Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n trong má»i trÆ°á»ng há»£p.* âŒ

* **Sai.** KhÃ´ng cÃ³ mÃ´ hÃ¬nh nÃ o tháº¯ng **má»i** bÃ i toÃ¡n. TrÃªn dá»¯ liá»‡u báº£ng nhiá»u khi **Gradient Boosting** (Ä‘Ã£ regularize vÃ  tune) **vÆ°á»£t RF** vá» Ä‘á»™ chÃ­nh xÃ¡c. ( *No Free Lunch* ).

**TÃ³m láº¡i:** Æ¯u Ä‘iá»ƒm Ä‘iá»ƒn hÃ¬nh cá»§a RF cho dá»¯ liá»‡u lá»›n/Ä‘a dáº¡ng lÃ  **Ä‘á»™ á»•n Ä‘á»‹nh, Ã­t overfit hÆ¡n (A)** vÃ   **dá»… song song hÃ³a (C)** ; **B** khÃ´ng báº£o Ä‘áº£m, **D** cháº¯c cháº¯n sai.


---

# CÃ¢u 38 


**Äá» bÃ i (viáº¿t láº¡i):**

*â€œSá»± khÃ¡c biá»‡t cá»‘t lÃµi giá»¯a **AdaBoost** vÃ  **Gradient Boosting** trong cÃ¡ch chÃºng cáº£i thiá»‡n mÃ´ hÃ¬nh qua cÃ¡c vÃ²ng láº·p lÃ  gÃ¬?â€*

CÃ¡c lá»±a chá»n:

A) AdaBoost nháº¥n máº¡nh sá»­a lá»—i á»Ÿ **nhá»¯ng máº«u bá»‹ dá»± Ä‘oÃ¡n sai** (máº«u â€œkhÃ³â€), cÃ²n Gradient Boosting **giáº£m tá»•ng loss** báº±ng cÃ¡ch dÃ¹ng **Ä‘áº¡o hÃ m** cá»§a hÃ m máº¥t mÃ¡t.

B) AdaBoost dÃ¹ng mÃ´ hÃ¬nh con yáº¿u, cÃ²n Gradient Boosting chá»‰ dÃ¹ng mÃ´ hÃ¬nh con  **máº¡nh** .

C) AdaBoost **khÃ´ng thá»ƒ** overfit, cÃ²n Gradient Boosting **dá»…** overfit.

D) Hai phÆ°Æ¡ng phÃ¡p cÃ³ **cÃ¹ng** cÃ¡ch tiáº¿p cáº­n Ä‘á»ƒ cáº£i thiá»‡n mÃ´ hÃ¬nh qua cÃ¡c bÆ°á»›c láº·p.

---

## Tráº£ lá»i ngáº¯n gá»n

**ÄÃ¡p Ã¡n Ä‘Ãºng: A.**

* **AdaBoost** : tÄƒng trá»ng sá»‘ cho **máº«u sai** Ä‘á»ƒ vÃ²ng sau há»c ká»¹ vÃ o cÃ¡c Ä‘iá»ƒm khÃ³ â†’ sá»­a lá»—i tá»«ng máº«u.
* **Gradient Boosting** : á»Ÿ má»—i vÃ²ng fit theo **negative gradient** (pseudo-residual) cá»§a **tá»•ng loss** â†’ tá»‘i Æ°u hoÃ¡ toÃ n cá»¥c theo hÆ°á»›ng giáº£m loss.

---

## Giáº£i thÃ­ch chi tiáº¿t

### AdaBoost (phÃ¢n loáº¡i, Ã½ tÆ°á»Ÿng chÃ­nh)

* Báº¯t Ä‘áº§u vá»›i trá»ng sá»‘ máº«u  **Ä‘á»u nhau** .
* á» vÃ²ng (m), train bá»™ há»c yáº¿u (h_m) vÃ  tÃ­nh **tá»‰ lá»‡ lá»—i cÃ³ trá»ng sá»‘** (\varepsilon_m).
* TÃ­nh trá»ng sá»‘ cÃ¢y: (\alpha_m=\tfrac{1}{2}\ln\frac{1-\varepsilon_m}{\varepsilon_m}).
* **TÄƒng trá»ng sá»‘** cÃ¡c máº«u  **bá»‹ dá»± Ä‘oÃ¡n sai** :

  [

  w_i^{(m+1)} \propto w_i^{(m)} \exp\big(\alpha_m \cdot \mathbb{1}[h_m(x_i)\ne y_i]\big)

  ]
* Tá»• há»£p dá»± Ä‘oÃ¡n: (\mathrm{sign}!\left(\sum_m \alpha_m h_m(x)\right)).

  â†’ Trá»ng tÃ¢m: **Ä‘iá»ƒn hÃ¬nh máº«u-centric** (táº­p trung vÃ o â€œmáº«u khÃ³â€).

> Vá»›i AdaBoost.R2 (há»“i quy): cÆ¡ cháº¿ tÆ°Æ¡ng tá»± nhÆ°ng dÃ¹ng sai sá»‘ chuáº©n hoÃ¡ vÃ  (\beta=\varepsilon/(1-\varepsilon)), (\alpha=\ln(1/\beta)).

### Gradient Boosting (khung tá»‘i Æ°u hoÃ¡)

* Xem mÃ´ hÃ¬nh nhÆ° hÃ m cá»™ng dá»“n: (F_m(x)=F_{m-1}(x)+\eta\gamma_m h_m(x)).
* á» vÃ²ng (m), tÃ­nh **pseudo-residuals** (negative gradient):

  [

  r_{i,m}= -\frac{\partial \mathcal{L}(y_i, F(x_i))}{\partial F}\Big| *{F=F* {m-1}}

  ]
* Fit bá»™ há»c yáº¿u (h_m) Ä‘á»ƒ xáº¥p xá»‰ (r_{i,m}); tÃ¬m (\gamma_m) (line search) vÃ  cáº­p nháº­t vá»›i **learning rate** (\eta).

  â†’ Trá»ng tÃ¢m: **loss-centric** (giáº£m **tá»•ng loss** báº±ng Ä‘áº¡o hÃ m).

---

## VÃ¬ sao cÃ¡c phÆ°Æ¡ng Ã¡n cÃ²n láº¡i sai?

* **B â€“ Sai.** Cáº£ hai Ä‘á»u dÃ¹ng **bá»™ há»c yáº¿u** (thÆ°á»ng lÃ  cÃ¢y nÃ´ng). Gradient Boosting **khÃ´ng yÃªu cáº§u** mÃ´ hÃ¬nh con máº¡nh.
* **C â€“ Sai.** **Cáº£ hai Ä‘á»u cÃ³ thá»ƒ overfit** náº¿u khÃ´ng regularize (quÃ¡ nhiá»u vÃ²ng, depth lá»›n, (\eta) cao).
  * Kháº¯c phá»¥c: giá»›i háº¡n Ä‘á»™ sÃ¢u, **shrinkage** ((\eta) nhá»), **subsample** (Stochastic GB),  **early stopping** .
* **D â€“ Sai.** DÃ¹ Ä‘á»u â€œboostingâ€ nhiá»u vÃ²ng,  **cÃ¡ch cáº£i thiá»‡n khÃ¡c nhau** : AdaBoost  **reweight máº«u** ; Gradient Boosting  **theo gradient cá»§a loss** .

---

## Ghi nhá»› nhanh

* **AdaBoost** = â€œ **Ä‘Ã¡nh máº¡nh vÃ o máº«u sai** â€.
* **Gradient Boosting** = â€œ **Ä‘i theo gradient Ä‘á»ƒ giáº£m tá»•ng loss** â€.
* Cáº£ hai: dÃ¹ng  **bá»™ há»c yáº¿u** , cÃ³ thá»ƒ overfit â†’ cáº§n regularization.
