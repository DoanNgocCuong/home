ƒê√¢y l√† code ƒë∆°n gi·∫£n nh·∫•t g·ªìm 3 ph·∫ßn LangChain ‚Üí LangSmith ‚Üí LangGraph:

# üöÄ **CODE ƒê·ªÄN GI·∫¢N NH·∫§T: LANGCHAIN ‚Üí LANGSMITH ‚Üí LANGGRAPH**

## **Setup Environment**
```bash
pip install langchain langchain-openai langsmith langgraph python-dotenv
```

## **Complete Simple Example**
```python
# simple_complete_example.py
import os
from dotenv import load_dotenv
from typing import TypedDict, List

# LangChain imports
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# LangSmith imports
from langsmith import Client
from langchain.callbacks.tracers import LangChainTracer

# LangGraph imports
from langgraph.graph import StateGraph, END

# Load environment variables
load_dotenv()

# =============================================================================
# PART 1: LANGCHAIN BASIC CHAIN
# =============================================================================
class SimpleLangChain:
    def __init__(self):
        self.llm = ChatOpenAI(
            model="gpt-3.5-turbo",
            temperature=0.7,
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )
        
    def create_simple_chain(self):
        """T·∫°o chain ƒë∆°n gi·∫£n"""
        template = """
        B·∫°n l√† tr·ª£ l√Ω AI th√¥ng minh.
        
        C√¢u h·ªèi: {question}
        Tr·∫£ l·ªùi ng·∫Øn g·ªçn:
        """
        
        prompt = PromptTemplate(
            input_variables=["question"],
            template=template
        )
        
        chain = LLMChain(llm=self.llm, prompt=prompt)
        return chain
    
    def run_chain(self, question):
        """Ch·∫°y chain"""
        chain = self.create_simple_chain()
        result = chain.run(question)
        return result

# =============================================================================
# PART 2: LANGSMITH MONITORING
# =============================================================================
class SimpleLangSmith:
    def __init__(self):
        # Setup LangSmith (n·∫øu c√≥ API key)
        if os.getenv("LANGSMITH_API_KEY"):
            os.environ["LANGCHAIN_TRACING_V2"] = "true"
            os.environ["LANGCHAIN_ENDPOINT"] = "https://api.smith.langchain.com"
            os.environ["LANGCHAIN_API_KEY"] = os.getenv("LANGSMITH_API_KEY")
            os.environ["LANGCHAIN_PROJECT"] = "simple-practice"
            
            self.client = Client()
            self.tracer = LangChainTracer(project_name="simple-practice")
            self.monitoring_enabled = True
        else:
            self.monitoring_enabled = False
            print("LangSmith monitoring disabled (no API key)")
    
    def create_monitored_chain(self):
        """T·∫°o chain c√≥ monitoring"""
        llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)
        
        template = """
        Tr·∫£ l·ªùi c√¢u h·ªèi: {question}
        
        C√¢u tr·∫£ l·ªùi:
        """
        
        prompt = PromptTemplate(
            input_variables=["question"],
            template=template
        )
        
        # Th√™m callback n·∫øu monitoring enabled
        callbacks = [self.tracer] if self.monitoring_enabled else []
        
        chain = LLMChain(
            llm=llm,
            prompt=prompt,
            callbacks=callbacks
        )
        
        return chain
    
    def run_with_monitoring(self, question):
        """Ch·∫°y v·ªõi monitoring"""
        chain = self.create_monitored_chain()
        result = chain.run(question)
        
        if self.monitoring_enabled:
            print("‚úÖ ƒê√£ ghi log v√†o LangSmith")
        
        return result

# =============================================================================
# PART 3: LANGGRAPH MULTI-AGENT
# =============================================================================
class AgentState(TypedDict):
    """State cho LangGraph"""
    messages: List[str]
    current_task: str
    result: str

class SimpleLangGraph:
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.3)
    
    def thinking_agent(self, state: AgentState):
        """Agent suy nghƒ©"""
        task = state["current_task"]
        
        # Simulate thinking
        thinking_result = f"ƒêang suy nghƒ© v·ªÅ: {task}"
        
        return {
            "messages": state["messages"] + [thinking_result],
            "current_task": task,
            "result": thinking_result
        }
    
    def answering_agent(self, state: AgentState):
        """Agent tr·∫£ l·ªùi"""
        task = state["current_task"]
        
        # Simple answering logic
        if "langchain" in task.lower():
            answer = "LangChain l√† framework ƒë·ªÉ x√¢y d·ª±ng ·ª©ng d·ª•ng LLM"
        elif "langsmith" in task.lower():
            answer = "LangSmith l√† c√¥ng c·ª• monitoring cho LangChain"
        elif "langgraph" in task.lower():
            answer = "LangGraph l√† framework ƒë·ªÉ x√¢y d·ª±ng multi-agent workflows"
        else:
            answer = f"T√¥i hi·ªÉu b·∫°n h·ªèi v·ªÅ: {task}"
        
        return {
            "messages": state["messages"] + [answer],
            "current_task": task,
            "result": answer
        }
    
    def create_simple_workflow(self):
        """T·∫°o workflow ƒë∆°n gi·∫£n"""
        # T·∫°o graph
        workflow = StateGraph(AgentState)
        
        # Th√™m nodes
        workflow.add_node("thinking", self.thinking_agent)
        workflow.add_node("answering", self.answering_agent)
        
        # Th√™m edges
        workflow.add_edge("thinking", "answering")
        workflow.add_edge("answering", END)
        
        # Set entry point
        workflow.set_entry_point("thinking")
        
        # Compile
        app = workflow.compile()
        return app
    
    def run_workflow(self, question):
        """Ch·∫°y workflow"""
        app = self.create_simple_workflow()
        
        initial_state = {
            "messages": [],
            "current_task": question,
            "result": ""
        }
        
        result = app.invoke(initial_state)
        return result

# =============================================================================
# MAIN EXECUTION
# =============================================================================
def main():
    print("üöÄ SIMPLE LANGCHAIN ‚Üí LANGSMITH ‚Üí LANGGRAPH EXAMPLE")
    print("=" * 60)
    
    # Test questions
    questions = [
        "LangChain l√† g√¨?",
        "LangSmith c√≥ t√°c d·ª•ng g√¨?", 
        "LangGraph ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o?"
    ]
    
    # =============================================================================
    # PART 1: Test LangChain
    # =============================================================================
    print("\nüìù PART 1: LANGCHAIN BASIC CHAIN")
    print("-" * 30)
    
    langchain_app = SimpleLangChain()
    
    for question in questions:
        print(f"\nQ: {question}")
        answer = langchain_app.run_chain(question)
        print(f"A: {answer}")
    
    # =============================================================================
    # PART 2: Test LangSmith
    # =============================================================================
    print("\nüìä PART 2: LANGSMITH MONITORING")
    print("-" * 30)
    
    langsmith_app = SimpleLangSmith()
    
    for question in questions:
        print(f"\nQ: {question}")
        answer = langsmith_app.run_with_monitoring(question)
        print(f"A: {answer}")
    
    # =============================================================================
    # PART 3: Test LangGraph
    # =============================================================================
    print("\nüîÑ PART 3: LANGGRAPH MULTI-AGENT")
    print("-" * 30)
    
    langgraph_app = SimpleLangGraph()
    
    for question in questions:
        print(f"\nQ: {question}")
        result = langgraph_app.run_workflow(question)
        print(f"Messages: {result['messages']}")
        print(f"Final Result: {result['result']}")

if __name__ == "__main__":
    main()
```

## **Environment Setup (.env)**
```env
# .env file
OPENAI_API_KEY=your_openai_api_key_here
LANGSMITH_API_KEY=your_langsmith_api_key_here
```

## **Ch·∫°y Code**
```bash
# 1. T·∫°o file .env v·ªõi API keys
# 2. Ch·∫°y code
python simple_complete_example.py
```

## **Output M·∫´u**
```
üöÄ SIMPLE LANGCHAIN ‚Üí LANGSMITH ‚Üí LANGGRAPH EXAMPLE
============================================================

üìù PART 1: LANGCHAIN BASIC CHAIN
------------------------------

Q: LangChain l√† g√¨?
A: LangChain l√† m·ªôt framework m√£ ngu·ªìn m·ªü ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ x√¢y d·ª±ng c√°c ·ª©ng d·ª•ng s·ª≠ d·ª•ng Large Language Models (LLMs)...

üìä PART 2: LANGSMITH MONITORING
------------------------------

Q: LangChain l√† g√¨?
A: LangChain l√† framework Python m·∫°nh m·∫Ω...
‚úÖ ƒê√£ ghi log v√†o LangSmith

üîÑ PART 3: LANGGRAPH MULTI-AGENT
------------------------------

Q: LangChain l√† g√¨?
Messages: ['ƒêang suy nghƒ© v·ªÅ: LangChain l√† g√¨?', 'LangChain l√† framework ƒë·ªÉ x√¢y d·ª±ng ·ª©ng d·ª•ng LLM']
Final Result: LangChain l√† framework ƒë·ªÉ x√¢y d·ª±ng ·ª©ng d·ª•ng LLM
```

## **T√≠nh nƒÉng c·ªßa Code:**

### **üîó LangChain (Part 1):**
- Basic LLM chain v·ªõi prompt template
- X·ª≠ l√Ω input/output ƒë∆°n gi·∫£n

### **üìä LangSmith (Part 2):**
- T·ª± ƒë·ªông tracking v√† logging
- Monitoring performance
- Ch·∫°y ƒë∆∞·ª£c ngay c·∫£ khi kh√¥ng c√≥ API key

### **ü§ñ LangGraph (Part 3):**
- Multi-agent workflow
- State management
- Graph-based orchestration

## **M·ªü r·ªông d·ªÖ d√†ng:**
1. **Th√™m tools**: Integrate calculator, search, etc.
2. **Ph·ª©c t·∫°p h√≥a workflow**: Th√™m conditional routing
3. **Custom evaluation**: Th√™m metrics v√†o LangSmith
4. **Production deployment**: Th√™m FastAPI wrapper

Code n√†y l√† foundation ho√†n h·∫£o ƒë·ªÉ b·∫Øt ƒë·∫ßu h·ªçc c·∫£ 3 frameworks! üöÄ