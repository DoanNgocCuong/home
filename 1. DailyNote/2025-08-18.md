![[Pasted image 20250818000619.png]]



Bộ Eval hôm chiều 18082025 - Vấn đề LỚN NHẤT CHÍNH LÀ: KO CÓ BỘ GROUD TRUTH CHUẨN => Dẫn đến kết quả trả ra là: như bên dưới lúc check> 1. vừa phải check ground truth chuẩn chưa mất quá nhiều time 2. Là check xem với user input đấy - groud truth đấy thì kết quả trả ra ổn chưa. 3. Là bị rối vì QUÁ NHIỀU LOẠI NHÃN (rỗng, loại 1, và loại nhiều) - MAY MÀ CÓ FILE METRIC REPORT TRƯỚC ĐÓ 4. LÀ NGHĨ VIỆC SAO ĐÓNG GÓI FILE VÀ QUẢN LÝ VERSION CHO HIỆU QUẢ

update chạy test eval cho tập FALSE của Onion, leanSpeak Chạy với 3 loại nhãn ban đầu: ko có, có 1, mix => tương đương với việc: tập rỗng, tập 1 phần tử và tập nhiều phần tử. Kết quả chạy đang được tính theo:

1. 70% đúng cho 1 Job Roles từ lần chạy trước
2. 30% lần này gồm: 241 không match, 346 matched.
- Trong 241 không match thì có 58 cái AI trả ra không match, 183 cái AI trả ra match.
- Trong 346 cái matched thì có 117 cái matched và 229 cái không matched Sau đó từ cái số 2 này mới tính cái Hybrid


+, Recall (bao phủ) = TP / (TP + FN) = số đúng tìm được / tổng số đúng (chính là công thức Quốc đang dùng).

+, Precision (độ chính xác) = TP / (TP + FP) = số đúng tìm được / tổng số hệ thống dự đoán.

+, F1-score = 2 × (Precision × Recall) / (Precision + Recall) = trung bình điều hòa giữa Precision và Recall.

+, Accuracy (độ chính xác tổng thể) = (TP + TN) / (TP + TN + FP + FN) → Tỷ lệ dự đoán đúng trên toàn bộ mẫu.



4.1. Macro-averaging (trung bình theo mẫu)
Tính Precision, Recall, F1 cho từng dòng riêng, sau đó lấy trung bình.
Ý nghĩa: coi trọng từng sample ngang nhau, dù có nhiều hay ít job-role.

4.2. Micro-averaging (trung bình theo instance)
Cộng tổng TP, FP, FN của toàn bộ dataset → rồi tính Precision, Recall, F1.


























---

# Công ty : 

1. Sáng: 
- Update phần chạy Job Roles các thứ: code để evaluate. 