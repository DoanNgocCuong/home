
"smart_sources:3_AI Engineering/5.3 AI Agent/1. Long Term Memory User/Read 0. Reference.md": {"path":"3_AI Engineering/5.3 AI Agent/1. Long Term Memory User/Read 0. Reference.md","embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.06379611,0.0233666,0.00311912,0.00933927,-0.00889624,0.01047807,0.01912073,0.00272771,0.02544086,-0.04946347,0.0304195,-0.08749643,0.07335547,0.0441682,0.07479601,0.01241656,-0.01931405,0.04554466,0.03273378,-0.04664811,0.05874645,-0.03633841,0.02734952,0.00403354,-0.01536419,0.0234835,0.01820435,-0.04958207,0.02704772,-0.19210859,0.02700875,0.05534438,-0.00932082,0.02193429,0.01556025,0.00849642,-0.02965345,0.04520923,-0.04153971,0.04051383,0.02684029,-0.00801573,0.00780441,-0.04336844,0.05228899,-0.03133298,0.00692706,-0.04806926,-0.03137903,-0.08718386,-0.02623943,-0.00864851,0.04762476,0.02397599,0.00072544,-0.00045386,0.07816277,0.08932018,0.02572802,-0.01553977,0.0498726,0.07803164,-0.2155021,0.09398647,-0.01049533,0.03540074,-0.00837462,-0.02079895,0.02027303,0.08608784,-0.05657894,0.00079056,0.01187721,0.00250472,0.01104946,0.06052058,0.0359739,-0.02911033,0.01064892,-0.08024756,0.01112259,0.03324794,-0.06137037,-0.02792018,-0.07172725,-0.06918065,0.00604101,-0.05332565,-0.01978561,-0.04203242,0.00510101,0.03379039,0.00553766,0.0347004,0.03516948,-0.03370206,0.0259054,0.0450649,-0.11357271,0.11239754,0.01184866,-0.00892886,0.00986139,0.00084048,0.01103566,0.00273892,-0.00237706,-0.06047474,-0.05433897,0.03133054,-0.04788554,-0.00134257,0.02082812,-0.02546393,-0.00667165,0.02682939,0.05289253,-0.02899344,0.05030617,-0.04346267,-0.00717562,0.0047521,0.02589379,0.01944433,0.03328625,-0.05305715,0.03383033,0.07038609,0.01149637,0.04452225,0.0821038,-0.00170943,-0.03402558,-0.00927103,0.01299979,-0.01788425,-0.0036411,-0.03514312,-0.05724071,-0.08219746,-0.04738554,0.01125506,0.04379415,-0.02665674,-0.10378859,0.07808813,-0.01714312,0.02410222,-0.03303267,-0.01797665,0.00747776,0.0388674,0.04268686,-0.02128381,0.01694869,-0.0129168,0.103421,0.0853813,-0.1242787,0.0254313,0.02756169,-0.06221975,-0.05825659,0.12596479,0.01635612,-0.08510536,-0.04926211,-0.03565035,0.03063438,0.0146361,0.05509831,0.01445894,-0.08139621,-0.01849552,0.01691056,0.00626217,-0.01402512,-0.01316729,-0.01259995,-0.00236193,-0.09398095,-0.06403727,0.01603444,0.00786676,-0.00866172,-0.03494518,0.02988726,-0.03835407,0.00636447,-0.04177816,0.02302408,0.06320895,-0.00108677,0.03127762,-0.07267127,0.04022685,0.00714144,-0.02904472,-0.00510932,-0.08423214,0.01671612,-0.00117798,-0.02530975,0.00547765,-0.00598253,0.00450057,-0.03396718,-0.01077109,0.06112317,0.02457223,-0.08748592,-0.00877358,0.05414551,-0.02066807,-0.08226653,0.01905326,0.02003873,0.03677814,-0.01720504,-0.01948557,0.035422,0.02610464,-0.07324267,-0.19199541,0.00833409,-0.00375513,-0.04651156,0.04825029,-0.05405575,0.07450745,-0.01088269,0.10577309,0.06500401,0.03888892,-0.04516226,-0.0181366,0.03432696,0.03336636,0.0207365,0.02743179,0.08726191,-0.02417924,0.04454629,-0.00117427,-0.00118007,-0.04843921,-0.09959637,0.02724123,0.01786762,0.17408083,-0.00633408,0.00527025,0.02606693,-0.00284284,0.00356434,-0.04000182,-0.13046382,0.09561614,-0.00495627,0.04783897,-0.01758833,0.00264291,-0.0689774,-0.04892122,0.04460176,-0.02972724,-0.05957846,-0.05002112,-0.04513372,-0.02218162,-0.01330827,-0.07379218,-0.00278701,0.04627298,0.00687731,-0.04362004,0.00055995,-0.01337015,-0.03478194,-0.04806392,0.00648903,-0.03684249,0.05667929,0.00399116,-0.02790685,-0.00041335,-0.02478309,0.01158868,-0.01985088,0.03896701,-0.00262331,0.01578032,0.01350046,-0.05010009,0.12921186,0.0260927,-0.01296283,0.0871113,-0.0514142,0.03203557,-0.0393397,0.02886237,0.01311526,0.00940989,-0.04449802,0.00160587,0.00044905,0.0590065,0.01646937,0.04131428,-0.02247751,0.05857732,0.06202988,0.03886913,0.02865248,-0.04254949,-0.02819923,0.0748097,-0.03215494,-0.2694793,0.02837043,0.00939181,0.08948099,0.00136068,-0.0327491,-0.00716157,-0.04970015,-0.03180406,0.00752521,0.00418341,0.00538552,0.01645348,0.0020381,-0.00841658,-0.01265649,0.05784482,-0.04263388,0.06377947,-0.01692509,-0.04564947,-0.00279384,0.19282034,-0.01087488,0.03888865,0.03178574,-0.02721223,-0.0374264,-0.01180059,-0.08093004,-0.00984602,-0.01229655,0.10584773,-0.03094096,0.03037732,0.14473316,-0.06456241,0.00735045,0.02458784,0.06769166,0.02131939,0.02475626,-0.00755894,0.02319704,0.08721457,0.02198545,0.00320082,-0.05510081,-0.07029865,0.02491482,0.01973782,-0.04126323,-0.04284732,-0.03517944,0.07164564,0.04612639,0.00265762,-0.03461276,-0.0430739,-0.00838175,-0.00190785,0.00306136,0.05155037,0.06497138,0.00988868],"last_embed":{"hash":"e08b7dfd63166ef31d68846814a2970d3c995995d8252c3f2d79d7a8ed7188fd","tokens":462}}},"last_read":{"hash":"e08b7dfd63166ef31d68846814a2970d3c995995d8252c3f2d79d7a8ed7188fd","at":1744208995257},"class_name":"SmartSource","outlinks":[{"title":"Welcome to the ðŸ¤— AI Agents Course - Hugging Face Agents Course","target":"https://huggingface.co/learn/agents-course/unit0/introduction","line":1},{"title":"The Top 10 arXiv Papers About AI Agents (especially Voice AI Agents) | Deepgram","target":"https://deepgram.com/learn/top-arxiv-papers-about-ai-agents-and-voice-ai-agents","line":3},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nShort-term memory, or thread -scoped memory, can be recalled at any time from within a single conversational thread with a user. LangGraph manages short- term memory as a part of your agent's 51. State is persisted to a database using a checkpointer so the thread can be resumed at any time. Short-term memory updates when the graph is invoked or a step is completed, and the State is read at the start of each step.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Short,the%20start%20of%20each%20step","line":28},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nLangGraph manages short-term memory as part of the agent's state, persisted via thread-scoped checkpoints. This state can normally include the conversation history along with other stateful data, such as uploaded files, retrieved documents, or generated artifacts. By storing these in the graph's state, the bot can access the full context for a given conversation while maintaining separation between different threads.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=LangGraph%20manages%20short,maintaining%20separation%20between%20different%20threads","line":36},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nShort-term memory, or thread -scoped memory, can be recalled at any time from within a single conversational thread with a user. LangGraph manages short- term memory as a part of your agent's 51. State is persisted to a database using a checkpointer so the thread can be resumed at any time. Short-term memory updates when the graph is invoked or a step is completed, and the State is read at the start of each step.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Short,the%20start%20of%20each%20step","line":44},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nLong conversations pose a challenge to today's LLMs. The full history may not even fit inside an LLM's context window, resulting in an irrecoverable error. Even if your LLM technically supports the full context length, most LLMs still perform poorly over long contexts. They get \"distracted\" by stale or off-topic content, all while suffering from slower response times and higher costs.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Long%20conversations%20pose%20a%20challenge,response%20times%20and%20higher%20costs","line":52},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nChat models accept context using messages, which include developer provided instructions (a system message) and user inputs (human messages). In chat applications, messages alternate between human inputs and model responses, resulting in a list of messages that grows longer over time. Because context windows are limited and token-rich message lists can be costly, many applications can benefit from using techniques to manually remove or forget stale information.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Chat%20models%20accept%20context%20using,remove%20or%20forget%20stale%20information","line":60},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nSummarizing past conversationsÂ¶\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Summarizing%20past%20conversations%C2%B6","line":68},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\ndef summarize_conversation(state: State):\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=def%20summarize_conversation","line":76},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nLong-term memory is shared across conversational threads. It can be recalled at any time and in any thread. Memories are scoped to any custom namespace, not just within a single thread ID. LangGraph provides stores (reference doc) to let you save and recall long-term memories.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Long,term%20memories","line":84},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nLong-term memory in LangGraph allows systems to retain information across different conversations or sessions. Unlike short-term memory, which is thread-\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Long,term%20memory%2C%20which%20is%20thread","line":92},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nLangGraph stores long-term memories as JSON documents in a store ( 54). Each memory is organized under a custom `namespace` (similar to a folder) and a distinct `key` (like a filename). Namespaces often include user or org IDs or other labels that makes it easier to organize information. This structure enables hierarchical organization of memories. Cross-namespace searching is then supported through content filters. See the example below for an example.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=LangGraph%20stores%20long,example%20below%20for%20an%20example","line":100},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\n# InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production use. store = InMemoryStore(index={\"embed\": embed, \"dims\": 2}) user_id = \"my-user\" application_context = \"chitchat\" namespace = (user_id, application_context) store.put( namespace, \"a-memory\",\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=,memory","line":108},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nuser_id = \"my-user\" application_context = \"chitchat\" namespace = (user_id, application_context) store.put( namespace, \"a-memory\", { \"rules\": [ \"User likes short, direct language\",\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=user_id%20%3D%20%22my,User%20likes%20short%2C%20direct%20language","line":116},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\n# get the \"memory\" by ID item = store.get(namespace, \"a-memory\") # search for \"memories\" within this namespace, filtering on content equivalence, sorted by vector similarity items = store.search( namespace, filter={\"my-key\": \"my-value\"}, query=\"language preferences\" )\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=,value%22%7D%2C%20query%3D%22language%20preferences%22","line":124},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nLong-term memory is shared across conversational threads. It can be recalled at any time and in any thread. Memories are scoped to any custom namespace, not just within a single thread ID. LangGraph provides stores ( 54) to let you save and recall long-term memories.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Long,term%20memories","line":132},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nDifferent applications require various types of memory. Although the analogy isn't perfect, examining human memory types can be insightful. Some research (e.g., the CoALA paper) have even mapped these human memory types to those used in AI agents.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Different%20applications%20require%20various%20types,those%20used%20in%20AI%20agents","line":140},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nMemory Type What is Stored Human Example Agent Example Semantic Facts Things I learned in school Facts about a user Episodic Experiences Things I did Past agent actions Procedural Instructions Instincts or motor skills Agent system prompt\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Memory%20Type%20What%20is%20Stored,motor%20skills%20Agent%20system%20prompt","line":148},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nSemantic memory, both in humans and AI agents, involves the retention of specific facts and concepts. In humans, it can include information learned in school and the understanding of concepts and their relationships. For AI agents, semantic memory is often used to personalize applications by remembering facts or concepts from past interactions.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Semantic%20memory%2C%20both%20in%20humans,or%20concepts%20from%20past%20interactions","line":156},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\n# ProfileÂ¶\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=","line":164},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nAlternatively, memories can be a collection of documents that are continuously updated and extended over time. Each individual memory can be more narrowly scoped and easier to generate, which means that you're less likely to lose information over time. It's easier for an LLM to generate new objects for new information than reconcile new information with an existing profile. As a result, a document collection tends to lead to higher recall downstream.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Alternatively%2C%20memories%20can%20be%20a,lead%20to%20higher%20recall%20downstream","line":172},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\npairs you've selected to represent your domain.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=pairs%20you%27ve%20selected%20to%20represent,your%20domain","line":180},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nHowever, this shifts some complexity memory updating. The model must now delete or update existing items in the list, which can be tricky. In addition, some models may default to over-inserting and others may default to over-updating. See the Trustcall package for one way to manage this and consider evaluation (e.g., with a tool like LangSmith) to help you tune the behavior.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=However%2C%20this%20shifts%20some%20complexity,help%20you%20tune%20the%20behavior","line":188},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nWhen do you want to update memories?\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=When%20do%20you%20want%20to,update%20memories","line":196},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://redis.io&sz=32","line":204},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://redis.io&sz=32","line":212},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.graphlit.com&sz=32","line":220},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.graphlit.com&sz=32","line":228},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://docs.mem0.ai&sz=32","line":236},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://docs.mem0.ai&sz=32","line":244},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://microsoft.github.io&sz=32","line":252},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://microsoft.github.io&sz=32","line":260},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://redis.io&sz=32","line":268},{"title":"\r\n\r\nnews.ycombinator.com\r\n\r\nShow HN: Mem0 â€“ open-source Memory Layer for AI apps | Hacker News\r\n\r\nHi this looks interesting. From your description it looks like mem0 remembers details and context of previous chats but not the actual text of chats. Is this a correct assumption?\r\n\r\n","target":"https://news.ycombinator.com/item?id=41447317#:~:text=Hi%20this%20looks%20interesting,Is%20this%20a%20correct%20assumption","line":276},{"title":"\r\n\r\nnews.ycombinator.com\r\n\r\nShow HN: Mem0 â€“ open-source Memory Layer for AI apps | Hacker News\r\n\r\n3. Content management: Claude has minimum length requirements for caching (1024 characters for Sonnet, 2048 for Haiku). Mem0 can handle information of any length, from short facts to longer contexts. 4. Customization: Developers have greater control over Mem0's memory management, including options for prioritizing or deprioritizing information based on relevance or time. Claude's caching system offers less direct control. 5. Information retrieval: Mem0 is designed for more precise and targeted information retrieval, while Claude's cache works with broader contextual blocks.\r\n\r\n","target":"https://news.ycombinator.com/item?id=41447317#:~:text=3,works%20with%20broader%20contextual%20blocks","line":284},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.graphlit.com&sz=32","line":292},{"title":"\r\n\r\nnews.ycombinator.com\r\n\r\nShow HN: Mem0 â€“ open-source Memory Layer for AI apps | Hacker News\r\n\r\nAs mentioned in the post, we use a hybrid datastore approach that handles these cases effectively and that's where the graph aspect comes into picture.\r\n\r\n","target":"https://news.ycombinator.com/item?id=41447317#:~:text=As%20mentioned%20in%20the%20post%2C,graph%20aspect%20comes%20into%20picture","line":300},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://redis.io&sz=32","line":308},{"title":"\r\n\r\nnews.ycombinator.com\r\n\r\nShow HN: Mem0 â€“ open-source Memory Layer for AI apps | Hacker News\r\n\r\n1. Purpose and duration: Claude's cache is designed for short-term memory, clearing every 5 minutes. In contrast, Mem0 is built for long-term information storage, retaining data indefinitely unless instructed otherwise. 2. Flexibility and control: Mem0 offers more flexibility, allowing developers to update, delete, or modify stored information as needed. Claude's cache is more static - new information creates additional entries rather than updating existing ones. 3. Content management: Claude has minimum length requirements for caching (1024 characters for Sonnet, 2048 for Haiku). Mem0 can handle information of any length, from short facts to longer contexts. 4. Customization: Developers have\r\n\r\n","target":"https://news.ycombinator.com/item?id=41447317#:~:text=1,Customization%3A%20Developers%20have","line":316},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.graphlit.com&sz=32","line":324},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://microsoft.github.io&sz=32","line":332},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.graphlit.com&sz=32","line":340},{"title":"\r\n\r\nnews.ycombinator.com\r\n\r\nShow HN: Mem0 â€“ open-source Memory Layer for AI apps | Hacker News\r\n\r\ndesigned for more precise and targeted information retrieval, while Claude's cache works with broader contextual blocks.\r\n\r\n","target":"https://news.ycombinator.com/item?id=41447317#:~:text=designed%20for%20more%20precise%20and,works%20with%20broader%20contextual%20blocks","line":348},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://redis.io&sz=32","line":356},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.anthropic.com&sz=32","line":364},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":372},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.lukew.com&sz=32","line":380},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.lukew.com&sz=32","line":388},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":396},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.lukew.com&sz=32","line":404},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.getzep.com&sz=32","line":412},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":420},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":428},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":436},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":444},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":452},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":458},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":464},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":472},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.generational.pub&sz=32","line":480},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":488},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":496},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":504},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":512},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":520},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":528},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":536},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.me.bot&sz=32","line":544},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":552},{"title":"\r\n\r\nlangchain-ai.github\r\n\r\n5\r\n\r\n\r\n\r\n","target":"https://langchain-ai.github.io/","line":564},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://docs.mem0.ai&sz=32","line":572},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.graphlit.com&sz=32","line":580},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":584},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://medium.com&sz=32","line":592},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://microsoft.github.io&sz=32","line":600},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://redis.io&sz=32","line":604},{"title":"\r\n\r\nnews.ycombinator\r\n\r\n2\r\n\r\n\r\n\r\n","target":"https://news.ycombinator.com/","line":612},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.cognee.ai&sz=32","line":620},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":624},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.lukew.com&sz=32","line":628},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":632},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.anthropic.com&sz=32","line":640},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":651},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":659},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":667},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":675},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":683},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":691},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://en.wikipedia.org&sz=32","line":699},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://en.wikipedia.org&sz=32","line":707},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://en.wikipedia.org&sz=32","line":715},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":723},{"title":"\r\n\r\nopenreview.net\r\n\r\nLanguage model with Plug-in Knowldge Memory | OpenReview\r\n\r\nof knowledge PLM needs to solve certain task. In this paper, we introduce PlugLM, a pre-training model with differentiable plug-in memory(DPM). The key intuition behind is to decouple the knowledge storage from model parameters with an editable and scalable key-value memory and leverage knowledge in an explainable manner by knowledge retrieval in the DPM. We conduct extensive experiments under various settings to justify this design choice. In domain adaptation setting, PlugLM could be easily adapted to different domains with plugable in-domain memory---obtaining 3.95 F1 improvements across four domains, without any in-domain training. PlugLM could also keep absorbing new knowledge\r\n\r\n","target":"https://openreview.net/forum?id=Plr5l7r0jY6#:~:text=of%20knowledge%20PLM%20needs%20to,also%20keep%20absorbing%20new%20knowledge","line":731},{"title":"\r\n\r\nopenreview.net\r\n\r\nLanguage model with Plug-in Knowldge Memory | OpenReview\r\n\r\nadaptation setting, PlugLM could be easily adapted to different domains with plugable in-domain memory---obtaining 3.95 F1 improvements across four domains, without any in-domain training. PlugLM could also keep absorbing new knowledge after pre-training is done by knowledge updating operation in the DPM without re-training. Finally, we show that by incorporating training samples into DPM with knowledge prompting, PlugLM could further be improved by the instruction of in-task knowledge.\r\n\r\n","target":"https://openreview.net/forum?id=Plr5l7r0jY6#:~:text=adaptation%20setting%2C%20PlugLM%20could%20be,task%20knowledge","line":739},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":747},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":755},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":763},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":771},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":777},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":783},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":789},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":795},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":801},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":809},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":817},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":825},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":833},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://ar5iv.labs.arxiv.org&sz=32","line":841},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://medium.com&sz=32","line":849},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://ar5iv.labs.arxiv.org&sz=32","line":857},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://medium.com&sz=32","line":865},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":873},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":881},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":889},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":897},{"title":"\r\n\r\nopenreview.net\r\n\r\n200 The event memory module is designed to perceive 201 historical events to generate coherent responses 202 across interval time. As shown in Figure 2, this 203 event memory module is segmented into two major 204 sub-modules that focus separately on long-term 205 and short-term memory. 206 2.2.1 Long-term Memory 207 Memory Storage. The long-term memory mod\u0002208 ule aims to extract and encode events from past 209 sessions. Specifically, this involves recording\r\n\r\n","target":"https://openreview.net/pdf?id=lwCxVgVYoK#:~:text=200%20The%20event%20memory%20module,Specifically%2C%20this%20involves%20recording","line":905},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":911},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://medium.com&sz=32","line":919},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://medium.com&sz=32","line":927},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://medium.com&sz=32","line":935},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":943},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":951},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":959},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":967},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":975},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":983},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":991},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":999},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":1007},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":1013},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://medium.com&sz=32","line":1019}],"blocks":{"#":[1,22],"#---frontmatter---":[6,22],"#Deep Research: Nguá»“n 12/3/2025":[23,1028],"#Deep Research: Nguá»“n 12/3/2025#{1}":[25,1028]},"last_import":{"mtime":1744208869620,"size":78928,"at":1744208900183,"hash":"e08b7dfd63166ef31d68846814a2970d3c995995d8252c3f2d79d7a8ed7188fd"}},"smart_blocks:3_AI Engineering/5.3 AI Agent/1. Long Term Memory User/Read 0. Reference.md#": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.06509677,0.02260819,0.00051595,0.01045671,-0.01046861,0.01048704,0.02108741,0.00193395,0.02459164,-0.04853017,0.03081558,-0.08814798,0.0720927,0.04474189,0.07615288,0.01269067,-0.01815487,0.04488172,0.03303267,-0.04630628,0.05840012,-0.0343151,0.02683597,0.00448667,-0.01556726,0.02359483,0.01907963,-0.05110621,0.02556405,-0.18991807,0.02528889,0.0558033,-0.00808752,0.02380891,0.01372515,0.01007189,-0.0297216,0.04794152,-0.04022629,0.04079521,0.02713764,-0.00875782,0.00965708,-0.04011879,0.05297729,-0.03336344,0.00361819,-0.04713712,-0.0328282,-0.08699771,-0.02641899,-0.00976903,0.04814199,0.02389462,0.00228649,-0.00000261,0.07850377,0.08789159,0.02528414,-0.01201628,0.0485927,0.07847357,-0.21460398,0.09574018,-0.01281122,0.03362923,-0.00714051,-0.02158376,0.02053553,0.08318534,-0.05543648,0.00046687,0.01249048,0.00059271,0.01216826,0.06080354,0.03899432,-0.02987188,0.01072284,-0.08027459,0.0098011,0.0325053,-0.0622855,-0.02933524,-0.07336403,-0.06994157,0.00798882,-0.05351045,-0.01993999,-0.04187306,0.00503567,0.03195211,0.00517064,0.03437353,0.03541612,-0.03572331,0.02530686,0.04601799,-0.11210229,0.11394161,0.01194399,-0.00991476,0.00742205,0.00139766,0.00917822,0.003478,-0.00250827,-0.06050938,-0.05574447,0.03206079,-0.04904096,-0.00053921,0.02156682,-0.02360943,-0.00648856,0.02850268,0.05292429,-0.02986091,0.05122678,-0.04623897,-0.00551003,0.00489635,0.02566179,0.02127772,0.03220541,-0.05218223,0.03550643,0.07258441,0.00853275,0.04595318,0.082248,-0.00044773,-0.03614568,-0.00884695,0.01034348,-0.01902649,-0.00551654,-0.03450646,-0.05857298,-0.08051534,-0.04919479,0.01043232,0.04525911,-0.02729747,-0.10211881,0.07674515,-0.01689393,0.0257221,-0.03257746,-0.0189843,0.00891462,0.04091361,0.04243836,-0.01900001,0.01721521,-0.01381799,0.10246935,0.08494833,-0.12295136,0.02629418,0.03037595,-0.06238373,-0.05844164,0.12450781,0.0150101,-0.08701415,-0.05037793,-0.03660996,0.03074779,0.01666935,0.05452,0.01263466,-0.0792445,-0.01634231,0.01569739,0.00882801,-0.01372628,-0.01410896,-0.01197942,-0.00323881,-0.09400197,-0.06358506,0.01289677,0.00910333,-0.00989821,-0.03592259,0.02973535,-0.03976624,0.00857449,-0.04331563,0.02265667,0.06186379,-0.0029649,0.0324792,-0.07225469,0.03971567,0.00680814,-0.02904308,-0.00491965,-0.08506294,0.0175746,-0.00067755,-0.02794697,0.00612256,-0.00570249,0.00680125,-0.03584937,-0.01176996,0.06283734,0.0244761,-0.0859432,-0.00802531,0.0559086,-0.02228567,-0.08233954,0.01788972,0.02116349,0.03658796,-0.01737905,-0.01982605,0.03410434,0.0277556,-0.0728988,-0.19309402,0.00989959,-0.00424607,-0.04690945,0.04867501,-0.05563863,0.07678583,-0.01038703,0.10719901,0.06749696,0.03855366,-0.04509009,-0.01766418,0.03500181,0.03187905,0.02105945,0.02543018,0.08758944,-0.02072049,0.04116758,-0.000392,0.00005555,-0.05057021,-0.10194398,0.02856808,0.01872526,0.17087579,-0.00307225,0.00674143,0.02595216,-0.00258412,0.00357974,-0.03904344,-0.132735,0.09355785,-0.005505,0.04879387,-0.01842667,0.00114789,-0.06902105,-0.04675441,0.04374861,-0.02640224,-0.0587628,-0.04963081,-0.04365795,-0.02446772,-0.01265668,-0.07543983,-0.0034587,0.04879921,0.00845603,-0.04514086,0.00121776,-0.01399364,-0.03697894,-0.04751973,0.00513305,-0.03665251,0.05598991,0.00432696,-0.02801178,0.0004448,-0.02421101,0.01121465,-0.01658026,0.03600091,-0.00157336,0.015914,0.01423893,-0.04988572,0.12971914,0.02496795,-0.0122754,0.08429116,-0.05272267,0.03312669,-0.03940512,0.026838,0.01334416,0.00774621,-0.04179009,-0.00000506,0.00062118,0.05759786,0.01731331,0.04011786,-0.0222177,0.05972471,0.06340976,0.039184,0.02885544,-0.04212041,-0.03129944,0.07694202,-0.03233101,-0.26834691,0.02775036,0.00970872,0.08945321,-0.0020266,-0.03174422,-0.00695815,-0.0499328,-0.03077801,0.00713386,0.00346225,0.00554772,0.01624434,0.00108455,-0.0101274,-0.01289738,0.05697296,-0.04344239,0.06503188,-0.01522731,-0.04484271,-0.0022335,0.1950873,-0.01457731,0.03762298,0.03150176,-0.02754389,-0.03760412,-0.01194227,-0.07926305,-0.00744775,-0.01376485,0.10483386,-0.03023188,0.02893741,0.1430991,-0.0654662,0.00845682,0.02444433,0.06687012,0.02206265,0.02577461,-0.00662748,0.02305469,0.088047,0.02206781,0.00250087,-0.05405048,-0.07128894,0.02321123,0.02103946,-0.0415303,-0.04230943,-0.03560168,0.07012779,0.04675297,0.00094534,-0.03519387,-0.04308563,-0.00607441,-0.00033487,0.00431576,0.05099497,0.06394462,0.01200055],"last_embed":{"hash":"9c0f1a45e824513e55edd3b7a549fa72fda1911e4d74dbdc3d5f4f7ccd9991c7","tokens":460}}},"text":null,"length":0,"last_read":{"hash":"9c0f1a45e824513e55edd3b7a549fa72fda1911e4d74dbdc3d5f4f7ccd9991c7","at":1744208994749},"key":"3_AI Engineering/5.3 AI Agent/1. Long Term Memory User/Read 0. Reference.md#","lines":[1,22],"size":1915,"outlinks":[{"title":"Welcome to the ðŸ¤— AI Agents Course - Hugging Face Agents Course","target":"https://huggingface.co/learn/agents-course/unit0/introduction","line":1},{"title":"The Top 10 arXiv Papers About AI Agents (especially Voice AI Agents) | Deepgram","target":"https://deepgram.com/learn/top-arxiv-papers-about-ai-agents-and-voice-ai-agents","line":3}],"class_name":"SmartBlock"},
"smart_blocks:3_AI Engineering/5.3 AI Agent/1. Long Term Memory User/Read 0. Reference.md#---frontmatter---": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.04915151,0.06332608,0.01180709,0.01224104,-0.00989646,0.01741605,0.05202859,0.00955215,0.07116628,-0.04966531,0.02452759,-0.10366514,0.0864099,0.05809419,0.04900579,0.01279152,-0.01995171,0.04682777,0.05517406,-0.05124613,0.05951143,-0.05140297,0.01045891,0.02956242,-0.01419348,0.00721586,-0.00830623,-0.00330625,0.00373037,-0.19485833,0.01528986,0.06182948,-0.02456407,0.00515137,0.00100784,-0.00260725,-0.01014795,0.00826089,-0.03875399,0.03608534,0.06049396,0.02827288,-0.00067509,-0.04370876,0.05061715,-0.06259578,0.00251448,-0.03061214,-0.02406041,-0.04307061,-0.00510137,0.01708342,0.04499644,0.01616827,0.02616094,0.01460158,0.04818174,0.07272715,0.02613823,-0.04600968,0.09250007,0.08560643,-0.23723012,0.0715526,0.00790631,0.03978819,-0.00336665,-0.02764372,0.03119246,0.08065289,-0.05538164,0.00960214,0.01469545,0.03387379,0.04247434,0.03756697,0.01599667,-0.00973616,0.00763123,-0.06620827,0.03542485,0.04214469,-0.05834752,-0.03302734,-0.06087388,-0.06617064,0.00334192,-0.03996841,0.01170912,-0.0432777,0.03625341,0.02624912,0.0109947,0.05067611,0.01757297,-0.01023858,0.04434871,0.05543706,-0.1467201,0.11866083,-0.00508532,-0.00834877,0.03513603,-0.021884,0.02188139,0.0215473,-0.00885718,-0.05853387,-0.04149159,0.04028808,-0.05485592,0.0030874,0.01212845,-0.01532448,0.01968025,0.03711877,0.04785942,-0.02133405,0.01989552,-0.03204315,-0.02923193,0.03264169,-0.00634161,-0.00683515,0.01147688,-0.04040306,0.02192613,0.07913706,0.01815468,0.01554398,0.05602057,-0.01155347,-0.01617969,-0.01094642,0.00462786,-0.01664514,-0.00754832,-0.0653702,-0.05665841,-0.11288467,-0.05649797,-0.00557669,0.04208268,-0.02922044,-0.10668639,0.05455484,0.01847769,0.02471451,-0.04418941,-0.01288752,0.00904772,0.02578005,0.04150185,-0.04481513,-0.00427044,0.00154792,0.06345983,0.1010055,-0.09631562,0.01532941,0.00648547,-0.04610648,-0.04845341,0.11909555,-0.02071757,-0.0845985,-0.03371184,-0.01347714,0.04534797,-0.01266303,0.063883,0.05204807,-0.11467534,-0.04973483,0.00772482,0.01500648,-0.01714895,-0.01421381,-0.00943808,-0.01610237,-0.07054441,-0.04734898,0.00882275,0.03510015,0.02657474,-0.03601097,0.01358735,0.00146021,0.01944209,-0.00939295,-0.01328351,0.0805294,0.01821707,0.01160757,-0.07661569,-0.0032299,-0.0006889,-0.03521795,-0.00690745,-0.07395802,0.06553895,-0.01695817,-0.04510011,0.01234921,-0.00541456,-0.02550853,-0.04768584,-0.02254659,0.02435793,0.05256428,-0.05636608,-0.00979699,0.03816595,-0.0079686,-0.07119803,0.01538174,0.00468689,0.04308275,0.00462742,0.00483362,0.03420648,0.01782166,-0.05011012,-0.19224241,-0.01937789,0.00802302,-0.02282778,0.08591533,-0.05458495,0.02599322,-0.01368126,0.07581042,0.03395436,0.00471151,-0.03243161,-0.0471863,0.04839277,-0.00960981,0.01992926,0.03769674,0.06794643,0.0070541,0.04782369,-0.00526557,0.0082311,-0.06640298,-0.11546687,0.03054977,0.01554212,0.17741556,-0.01863983,-0.00401321,0.02432504,0.03229588,-0.00826577,-0.01486078,-0.09763446,0.0977235,0.01111357,0.00550617,0.01512937,0.02134114,-0.04432499,-0.03474804,0.03119983,-0.03475513,-0.09410349,-0.03563936,-0.04391975,-0.04096631,-0.00825776,-0.07969514,0.01118662,0.02108653,0.02541564,-0.00211222,0.0101375,0.01449128,-0.03067925,-0.03158569,0.01059859,-0.02930834,0.05253645,-0.0085393,-0.04073625,0.00363905,0.00851931,0.02560411,-0.04988679,0.04413942,0.00394299,-0.00300227,0.02726647,-0.04503313,0.10586736,0.01615911,-0.01994517,0.09282278,-0.02895829,-0.00086118,-0.06034711,0.03114167,0.01872702,-0.01557265,-0.05579812,0.02142811,-0.00496552,0.04378972,-0.00592544,0.03384412,-0.01359396,0.05389996,0.04577014,0.01717667,-0.00037396,-0.04541074,-0.00731663,0.03447005,-0.03566919,-0.28816769,0.03203998,-0.01691715,0.07504426,-0.00534459,-0.00288456,-0.00597247,-0.01810898,-0.03383222,0.03618877,0.00629444,0.0236197,0.0047104,-0.01347214,-0.0065865,-0.03166704,0.04478994,-0.04918662,0.07895587,-0.00299208,-0.03352331,-0.01206356,0.1980589,-0.00557752,0.03439059,0.05434414,0.0058559,0.00200772,0.00928534,-0.06206319,-0.01842834,-0.00230229,0.13399076,-0.05072396,0.0312426,0.13520716,-0.08130633,-0.01597867,0.03868283,0.06405857,0.0129792,0.04008099,-0.04749436,0.01415226,0.10810298,0.02764795,-0.00368653,-0.0620146,-0.0461171,0.00598894,-0.01907557,-0.03779077,-0.05740911,-0.03156155,0.08156344,0.02311353,-0.01590206,-0.03709494,-0.04077951,-0.01339018,-0.04537945,-0.00648808,0.06173217,0.02821842,-0.0130344],"last_embed":{"hash":"89ea9c5b473c9752dc1bd68bc97fc3f50c02b2f1c9b9062f8d3a22abd722b870","tokens":457}}},"text":null,"length":0,"last_read":{"hash":"89ea9c5b473c9752dc1bd68bc97fc3f50c02b2f1c9b9062f8d3a22abd722b870","at":1744208994872},"key":"3_AI Engineering/5.3 AI Agent/1. Long Term Memory User/Read 0. Reference.md#---frontmatter---","lines":[6,22],"size":1444,"outlinks":[],"class_name":"SmartBlock"},
"smart_blocks:3_AI Engineering/5.3 AI Agent/1. Long Term Memory User/Read 0. Reference.md#Deep Research: Nguá»“n 12/3/2025": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.05438983,-0.01077278,0.01918778,0.00562505,-0.0270531,-0.01027752,0.02728305,-0.01817,0.07021029,-0.03389563,-0.01327199,-0.00240759,0.09205657,0.1132955,-0.00549129,0.00949968,0.00773916,0.00585561,0.03449062,-0.04591952,0.01297872,-0.06884666,0.01915563,0.00471134,0.01775805,0.03297872,0.01909979,-0.0275675,-0.02355116,-0.2466201,0.04378625,-0.00382709,-0.02618113,0.02951986,-0.06019065,-0.00949527,0.01044887,0.01991838,0.02045733,0.06940959,0.0256989,0.03201445,-0.01068323,0.01496083,-0.01129566,-0.01591829,-0.01832223,-0.06126782,-0.00241446,-0.03660074,-0.00578543,-0.0373069,0.0666001,-0.0128987,-0.00195512,0.08347148,0.06308104,0.08907419,0.01200157,-0.01047299,0.05556103,0.00158971,-0.171313,0.05793714,-0.02707838,0.06010647,-0.0457078,-0.01882868,-0.00181167,0.04075054,-0.01371575,0.00549329,0.00472583,0.04758035,0.03814137,-0.02325715,0.04082032,0.00281196,0.04705457,-0.0397904,-0.05094252,0.03361064,-0.05567441,-0.01196344,-0.05256129,-0.0673532,-0.00975094,-0.01640101,0.06104694,-0.03011939,-0.00332521,0.0082883,0.04825208,0.06384277,-0.04888553,0.01447299,0.07095789,0.07887129,-0.06717873,0.14661503,-0.04476746,0.03897849,0.0148286,0.01325718,-0.00566006,-0.01801866,-0.01842667,-0.06972415,-0.11358918,0.05707944,0.00615574,0.00088479,0.01763793,-0.02058826,0.06172023,-0.00918052,0.04862654,-0.01098967,-0.02366389,0.01748594,-0.0010943,0.03753699,-0.00502756,-0.03036602,0.027802,0.00201339,0.05839713,0.02556246,0.01601786,0.05339349,0.05527646,0.01815663,-0.03340403,0.04288195,0.00061128,-0.03068729,0.02915346,-0.02422804,0.00588157,-0.05634274,-0.02883082,-0.01650461,0.04433271,-0.01013529,-0.08220029,0.17017789,0.0255897,0.00915936,-0.03525878,-0.07343284,-0.03021721,0.01997668,0.01497969,-0.03551497,0.0238395,0.0063983,0.053045,0.09623657,-0.06639937,0.06200737,-0.05622265,-0.03384422,-0.00939467,0.06939729,0.03285803,-0.05621139,-0.04219739,0.02141017,-0.02084021,-0.01846014,0.04933573,0.01601474,-0.02708311,-0.06926968,-0.00117856,-0.00342628,-0.05121819,-0.04554483,-0.0003353,0.03125603,-0.04814668,-0.07205942,-0.00166784,-0.00190496,-0.05657291,-0.02852495,-0.02148351,-0.02340886,0.01473931,0.02850769,-0.02537102,0.07893267,0.05211342,-0.00084932,-0.06066079,0.02131317,-0.05689031,-0.04084422,-0.05277324,-0.04800422,0.06888656,0.00304747,-0.02057775,0.0392535,0.00059797,-0.02679499,-0.07508034,-0.02560339,0.01104667,0.00165738,-0.0694344,-0.04261208,-0.0230298,0.0356946,-0.04744495,-0.03225693,0.01335163,0.0383049,0.04166288,-0.04471729,0.04139362,0.00736381,-0.05465758,-0.23146397,-0.03368529,-0.01373823,-0.00101112,0.08027175,-0.0784762,0.02254123,-0.02832783,0.06169657,0.00650578,0.00675639,-0.04475984,-0.06689275,-0.025009,0.0012482,0.02944542,-0.00805092,0.06030095,-0.05413537,0.01335035,0.02876174,-0.00584272,0.00165367,-0.09746943,0.03140648,0.00818493,0.21469378,-0.04888321,-0.00599294,0.01476715,0.00999727,-0.03214093,-0.01856582,-0.08141558,0.0741123,0.02385827,-0.02056954,0.0361744,-0.00944489,-0.04742436,-0.05929524,0.04722652,0.00867243,-0.10354357,-0.02702802,-0.01285483,-0.03064646,-0.07600187,-0.007172,-0.02550492,0.0306243,-0.04583276,-0.01524984,0.08482002,0.00799986,-0.06581061,-0.03064972,0.01158559,-0.0206852,0.04449274,-0.006643,-0.03440105,-0.02236894,0.01295476,0.07386947,0.01359593,0.04955063,-0.01278283,-0.01242993,-0.03979893,-0.01176667,0.13379396,-0.05627281,-0.03746771,0.06567748,-0.01574127,-0.02363086,-0.08874924,-0.03737061,0.04125444,0.03226663,-0.04711404,0.02977309,0.04275347,0.04038801,0.01644998,0.04101593,0.02545525,0.06971539,0.05667898,0.05001713,0.05714183,-0.04807829,0.00652854,0.01234558,-0.0213247,-0.262927,0.06057669,-0.00685831,0.03297353,0.00428572,0.0348959,0.03874769,0.01441563,-0.07496922,0.00739466,0.00753813,0.03149924,0.02916056,-0.00147323,0.01157903,0.03252164,0.0682753,0.01069763,0.05511614,-0.03775172,0.02374415,0.0029456,0.19390434,-0.00016551,0.04901962,0.04931851,-0.00698143,0.03028096,0.04867656,-0.0314317,-0.00338191,-0.0257644,0.12887402,-0.00901615,0.09414272,0.0120784,-0.03437793,0.0404077,0.08595491,0.03227684,-0.02166433,0.0294075,-0.00936658,0.01359198,0.07853693,0.01577205,-0.05449307,-0.05309077,-0.07062941,0.02887248,-0.0329904,-0.02751956,0.01343138,-0.04210511,0.01551211,-0.03971037,-0.00791032,-0.02598673,-0.02047746,0.00021342,0.01066976,-0.02064595,0.04904103,-0.02823224,-0.05099939],"last_embed":{"hash":"7e63a235547baecadfb1f315183b853668d3f0db3d6e13d02011c2978be0911a","tokens":417}}},"text":null,"length":0,"last_read":{"hash":"7e63a235547baecadfb1f315183b853668d3f0db3d6e13d02011c2978be0911a","at":1744208995125},"key":"3_AI Engineering/5.3 AI Agent/1. Long Term Memory User/Read 0. Reference.md#Deep Research: Nguá»“n 12/3/2025","lines":[23,1028],"size":76443,"outlinks":[{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nShort-term memory, or thread -scoped memory, can be recalled at any time from within a single conversational thread with a user. LangGraph manages short- term memory as a part of your agent's 51. State is persisted to a database using a checkpointer so the thread can be resumed at any time. Short-term memory updates when the graph is invoked or a step is completed, and the State is read at the start of each step.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Short,the%20start%20of%20each%20step","line":6},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nLangGraph manages short-term memory as part of the agent's state, persisted via thread-scoped checkpoints. This state can normally include the conversation history along with other stateful data, such as uploaded files, retrieved documents, or generated artifacts. By storing these in the graph's state, the bot can access the full context for a given conversation while maintaining separation between different threads.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=LangGraph%20manages%20short,maintaining%20separation%20between%20different%20threads","line":14},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nShort-term memory, or thread -scoped memory, can be recalled at any time from within a single conversational thread with a user. LangGraph manages short- term memory as a part of your agent's 51. State is persisted to a database using a checkpointer so the thread can be resumed at any time. Short-term memory updates when the graph is invoked or a step is completed, and the State is read at the start of each step.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Short,the%20start%20of%20each%20step","line":22},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nLong conversations pose a challenge to today's LLMs. The full history may not even fit inside an LLM's context window, resulting in an irrecoverable error. Even if your LLM technically supports the full context length, most LLMs still perform poorly over long contexts. They get \"distracted\" by stale or off-topic content, all while suffering from slower response times and higher costs.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Long%20conversations%20pose%20a%20challenge,response%20times%20and%20higher%20costs","line":30},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nChat models accept context using messages, which include developer provided instructions (a system message) and user inputs (human messages). In chat applications, messages alternate between human inputs and model responses, resulting in a list of messages that grows longer over time. Because context windows are limited and token-rich message lists can be costly, many applications can benefit from using techniques to manually remove or forget stale information.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Chat%20models%20accept%20context%20using,remove%20or%20forget%20stale%20information","line":38},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nSummarizing past conversationsÂ¶\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Summarizing%20past%20conversations%C2%B6","line":46},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\ndef summarize_conversation(state: State):\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=def%20summarize_conversation","line":54},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nLong-term memory is shared across conversational threads. It can be recalled at any time and in any thread. Memories are scoped to any custom namespace, not just within a single thread ID. LangGraph provides stores (reference doc) to let you save and recall long-term memories.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Long,term%20memories","line":62},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nLong-term memory in LangGraph allows systems to retain information across different conversations or sessions. Unlike short-term memory, which is thread-\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Long,term%20memory%2C%20which%20is%20thread","line":70},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nLangGraph stores long-term memories as JSON documents in a store ( 54). Each memory is organized under a custom `namespace` (similar to a folder) and a distinct `key` (like a filename). Namespaces often include user or org IDs or other labels that makes it easier to organize information. This structure enables hierarchical organization of memories. Cross-namespace searching is then supported through content filters. See the example below for an example.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=LangGraph%20stores%20long,example%20below%20for%20an%20example","line":78},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\n# InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production use. store = InMemoryStore(index={\"embed\": embed, \"dims\": 2}) user_id = \"my-user\" application_context = \"chitchat\" namespace = (user_id, application_context) store.put( namespace, \"a-memory\",\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=,memory","line":86},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nuser_id = \"my-user\" application_context = \"chitchat\" namespace = (user_id, application_context) store.put( namespace, \"a-memory\", { \"rules\": [ \"User likes short, direct language\",\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=user_id%20%3D%20%22my,User%20likes%20short%2C%20direct%20language","line":94},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\n# get the \"memory\" by ID item = store.get(namespace, \"a-memory\") # search for \"memories\" within this namespace, filtering on content equivalence, sorted by vector similarity items = store.search( namespace, filter={\"my-key\": \"my-value\"}, query=\"language preferences\" )\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=,value%22%7D%2C%20query%3D%22language%20preferences%22","line":102},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nLong-term memory is shared across conversational threads. It can be recalled at any time and in any thread. Memories are scoped to any custom namespace, not just within a single thread ID. LangGraph provides stores ( 54) to let you save and recall long-term memories.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Long,term%20memories","line":110},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nDifferent applications require various types of memory. Although the analogy isn't perfect, examining human memory types can be insightful. Some research (e.g., the CoALA paper) have even mapped these human memory types to those used in AI agents.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Different%20applications%20require%20various%20types,those%20used%20in%20AI%20agents","line":118},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nMemory Type What is Stored Human Example Agent Example Semantic Facts Things I learned in school Facts about a user Episodic Experiences Things I did Past agent actions Procedural Instructions Instincts or motor skills Agent system prompt\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Memory%20Type%20What%20is%20Stored,motor%20skills%20Agent%20system%20prompt","line":126},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nSemantic memory, both in humans and AI agents, involves the retention of specific facts and concepts. In humans, it can include information learned in school and the understanding of concepts and their relationships. For AI agents, semantic memory is often used to personalize applications by remembering facts or concepts from past interactions.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Semantic%20memory%2C%20both%20in%20humans,or%20concepts%20from%20past%20interactions","line":134},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\n# ProfileÂ¶\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=","line":142},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nAlternatively, memories can be a collection of documents that are continuously updated and extended over time. Each individual memory can be more narrowly scoped and easier to generate, which means that you're less likely to lose information over time. It's easier for an LLM to generate new objects for new information than reconcile new information with an existing profile. As a result, a document collection tends to lead to higher recall downstream.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Alternatively%2C%20memories%20can%20be%20a,lead%20to%20higher%20recall%20downstream","line":150},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\npairs you've selected to represent your domain.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=pairs%20you%27ve%20selected%20to%20represent,your%20domain","line":158},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nHowever, this shifts some complexity memory updating. The model must now delete or update existing items in the list, which can be tricky. In addition, some models may default to over-inserting and others may default to over-updating. See the Trustcall package for one way to manage this and consider evaluation (e.g., with a tool like LangSmith) to help you tune the behavior.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=However%2C%20this%20shifts%20some%20complexity,help%20you%20tune%20the%20behavior","line":166},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nWhen do you want to update memories?\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=When%20do%20you%20want%20to,update%20memories","line":174},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://redis.io&sz=32","line":182},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://redis.io&sz=32","line":190},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.graphlit.com&sz=32","line":198},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.graphlit.com&sz=32","line":206},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://docs.mem0.ai&sz=32","line":214},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://docs.mem0.ai&sz=32","line":222},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://microsoft.github.io&sz=32","line":230},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://microsoft.github.io&sz=32","line":238},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://redis.io&sz=32","line":246},{"title":"\r\n\r\nnews.ycombinator.com\r\n\r\nShow HN: Mem0 â€“ open-source Memory Layer for AI apps | Hacker News\r\n\r\nHi this looks interesting. From your description it looks like mem0 remembers details and context of previous chats but not the actual text of chats. Is this a correct assumption?\r\n\r\n","target":"https://news.ycombinator.com/item?id=41447317#:~:text=Hi%20this%20looks%20interesting,Is%20this%20a%20correct%20assumption","line":254},{"title":"\r\n\r\nnews.ycombinator.com\r\n\r\nShow HN: Mem0 â€“ open-source Memory Layer for AI apps | Hacker News\r\n\r\n3. Content management: Claude has minimum length requirements for caching (1024 characters for Sonnet, 2048 for Haiku). Mem0 can handle information of any length, from short facts to longer contexts. 4. Customization: Developers have greater control over Mem0's memory management, including options for prioritizing or deprioritizing information based on relevance or time. Claude's caching system offers less direct control. 5. Information retrieval: Mem0 is designed for more precise and targeted information retrieval, while Claude's cache works with broader contextual blocks.\r\n\r\n","target":"https://news.ycombinator.com/item?id=41447317#:~:text=3,works%20with%20broader%20contextual%20blocks","line":262},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.graphlit.com&sz=32","line":270},{"title":"\r\n\r\nnews.ycombinator.com\r\n\r\nShow HN: Mem0 â€“ open-source Memory Layer for AI apps | Hacker News\r\n\r\nAs mentioned in the post, we use a hybrid datastore approach that handles these cases effectively and that's where the graph aspect comes into picture.\r\n\r\n","target":"https://news.ycombinator.com/item?id=41447317#:~:text=As%20mentioned%20in%20the%20post%2C,graph%20aspect%20comes%20into%20picture","line":278},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://redis.io&sz=32","line":286},{"title":"\r\n\r\nnews.ycombinator.com\r\n\r\nShow HN: Mem0 â€“ open-source Memory Layer for AI apps | Hacker News\r\n\r\n1. Purpose and duration: Claude's cache is designed for short-term memory, clearing every 5 minutes. In contrast, Mem0 is built for long-term information storage, retaining data indefinitely unless instructed otherwise. 2. Flexibility and control: Mem0 offers more flexibility, allowing developers to update, delete, or modify stored information as needed. Claude's cache is more static - new information creates additional entries rather than updating existing ones. 3. Content management: Claude has minimum length requirements for caching (1024 characters for Sonnet, 2048 for Haiku). Mem0 can handle information of any length, from short facts to longer contexts. 4. Customization: Developers have\r\n\r\n","target":"https://news.ycombinator.com/item?id=41447317#:~:text=1,Customization%3A%20Developers%20have","line":294},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.graphlit.com&sz=32","line":302},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://microsoft.github.io&sz=32","line":310},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.graphlit.com&sz=32","line":318},{"title":"\r\n\r\nnews.ycombinator.com\r\n\r\nShow HN: Mem0 â€“ open-source Memory Layer for AI apps | Hacker News\r\n\r\ndesigned for more precise and targeted information retrieval, while Claude's cache works with broader contextual blocks.\r\n\r\n","target":"https://news.ycombinator.com/item?id=41447317#:~:text=designed%20for%20more%20precise%20and,works%20with%20broader%20contextual%20blocks","line":326},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://redis.io&sz=32","line":334},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.anthropic.com&sz=32","line":342},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":350},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.lukew.com&sz=32","line":358},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.lukew.com&sz=32","line":366},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":374},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.lukew.com&sz=32","line":382},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.getzep.com&sz=32","line":390},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":398},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":406},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":414},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":422},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":430},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":436},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":442},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":450},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.generational.pub&sz=32","line":458},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":466},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":474},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":482},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":490},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":498},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":506},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":514},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.me.bot&sz=32","line":522},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":530},{"title":"\r\n\r\nlangchain-ai.github\r\n\r\n5\r\n\r\n\r\n\r\n","target":"https://langchain-ai.github.io/","line":542},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://docs.mem0.ai&sz=32","line":550},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.graphlit.com&sz=32","line":558},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":562},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://medium.com&sz=32","line":570},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://microsoft.github.io&sz=32","line":578},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://redis.io&sz=32","line":582},{"title":"\r\n\r\nnews.ycombinator\r\n\r\n2\r\n\r\n\r\n\r\n","target":"https://news.ycombinator.com/","line":590},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.cognee.ai&sz=32","line":598},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":602},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.lukew.com&sz=32","line":606},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":610},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.anthropic.com&sz=32","line":618},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":629},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":637},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":645},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":653},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":661},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":669},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://en.wikipedia.org&sz=32","line":677},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://en.wikipedia.org&sz=32","line":685},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://en.wikipedia.org&sz=32","line":693},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":701},{"title":"\r\n\r\nopenreview.net\r\n\r\nLanguage model with Plug-in Knowldge Memory | OpenReview\r\n\r\nof knowledge PLM needs to solve certain task. In this paper, we introduce PlugLM, a pre-training model with differentiable plug-in memory(DPM). The key intuition behind is to decouple the knowledge storage from model parameters with an editable and scalable key-value memory and leverage knowledge in an explainable manner by knowledge retrieval in the DPM. We conduct extensive experiments under various settings to justify this design choice. In domain adaptation setting, PlugLM could be easily adapted to different domains with plugable in-domain memory---obtaining 3.95 F1 improvements across four domains, without any in-domain training. PlugLM could also keep absorbing new knowledge\r\n\r\n","target":"https://openreview.net/forum?id=Plr5l7r0jY6#:~:text=of%20knowledge%20PLM%20needs%20to,also%20keep%20absorbing%20new%20knowledge","line":709},{"title":"\r\n\r\nopenreview.net\r\n\r\nLanguage model with Plug-in Knowldge Memory | OpenReview\r\n\r\nadaptation setting, PlugLM could be easily adapted to different domains with plugable in-domain memory---obtaining 3.95 F1 improvements across four domains, without any in-domain training. PlugLM could also keep absorbing new knowledge after pre-training is done by knowledge updating operation in the DPM without re-training. Finally, we show that by incorporating training samples into DPM with knowledge prompting, PlugLM could further be improved by the instruction of in-task knowledge.\r\n\r\n","target":"https://openreview.net/forum?id=Plr5l7r0jY6#:~:text=adaptation%20setting%2C%20PlugLM%20could%20be,task%20knowledge","line":717},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":725},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":733},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":741},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":749},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":755},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":761},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":767},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":773},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":779},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":787},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":795},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":803},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":811},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://ar5iv.labs.arxiv.org&sz=32","line":819},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://medium.com&sz=32","line":827},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://ar5iv.labs.arxiv.org&sz=32","line":835},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://medium.com&sz=32","line":843},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":851},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":859},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":867},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":875},{"title":"\r\n\r\nopenreview.net\r\n\r\n200 The event memory module is designed to perceive 201 historical events to generate coherent responses 202 across interval time. As shown in Figure 2, this 203 event memory module is segmented into two major 204 sub-modules that focus separately on long-term 205 and short-term memory. 206 2.2.1 Long-term Memory 207 Memory Storage. The long-term memory mod\u0002208 ule aims to extract and encode events from past 209 sessions. Specifically, this involves recording\r\n\r\n","target":"https://openreview.net/pdf?id=lwCxVgVYoK#:~:text=200%20The%20event%20memory%20module,Specifically%2C%20this%20involves%20recording","line":883},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":889},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://medium.com&sz=32","line":897},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://medium.com&sz=32","line":905},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://medium.com&sz=32","line":913},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":921},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":929},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":937},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":945},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":953},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":961},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":969},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":977},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":985},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":991},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://medium.com&sz=32","line":997}],"class_name":"SmartBlock"},
"smart_blocks:3_AI Engineering/5.3 AI Agent/1. Long Term Memory User/Read 0. Reference.md#Deep Research: Nguá»“n 12/3/2025#{1}": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.05479624,-0.01218625,0.01954662,0.00412814,-0.02849231,-0.00877759,0.02790232,-0.01875464,0.0709074,-0.03364028,-0.01558186,-0.00189885,0.09350228,0.11386558,-0.00536682,0.00907823,0.0075202,0.0064154,0.0337797,-0.04623769,0.0124498,-0.06891181,0.01910991,0.0039984,0.01767244,0.03205623,0.0197817,-0.02718214,-0.02444421,-0.24650693,0.04427834,-0.00421852,-0.02707621,0.02841779,-0.06107618,-0.00905528,0.00960259,0.02075223,0.01919094,0.06952305,0.02532487,0.03158382,-0.01046446,0.01328037,-0.01178782,-0.01663793,-0.01794533,-0.06181755,-0.00071933,-0.03518315,-0.00456155,-0.03917878,0.06520578,-0.01348196,-0.00372106,0.08307513,0.06247334,0.08979521,0.01279043,-0.01007923,0.05425049,0.00043039,-0.17015803,0.05791686,-0.02752838,0.06059879,-0.04485082,-0.01824825,-0.0019933,0.0405403,-0.01424947,0.00592021,0.00476647,0.04893597,0.03757569,-0.02492885,0.03957462,0.0014894,0.04742007,-0.03951908,-0.0517236,0.03378872,-0.05386355,-0.01215351,-0.0515909,-0.06800719,-0.00978933,-0.01588729,0.06167583,-0.02993845,-0.00464406,0.0073958,0.04689307,0.06270887,-0.04966768,0.01553733,0.07122613,0.07626509,-0.06646679,0.14907172,-0.04538747,0.04123487,0.01618516,0.01254928,-0.00486724,-0.02111145,-0.01845987,-0.06920312,-0.11341361,0.05700091,0.00655067,0.00023625,0.01790965,-0.02154375,0.06127887,-0.00927691,0.048023,-0.01120664,-0.02391294,0.01804197,0.00001579,0.03665426,-0.00398,-0.03218324,0.02842478,0.00220505,0.05884637,0.02495481,0.01718131,0.05277697,0.05514762,0.01843812,-0.03262382,0.04339484,0.00150414,-0.03203802,0.03029327,-0.02386884,0.0065777,-0.05634823,-0.02738737,-0.01768532,0.0436466,-0.00963461,-0.08279359,0.17250204,0.02382587,0.01095415,-0.0363805,-0.07375424,-0.03218416,0.01937423,0.01501578,-0.03406947,0.02522426,0.00772804,0.0529855,0.09566065,-0.06421801,0.06248247,-0.05845472,-0.03426376,-0.00812228,0.06992844,0.03213625,-0.0564789,-0.04196457,0.02172177,-0.02069551,-0.01823663,0.0478939,0.01613822,-0.02670356,-0.07050353,-0.00121165,-0.00506511,-0.05174984,-0.04399494,-0.00039178,0.0330209,-0.04726052,-0.07113132,-0.00166914,-0.0016747,-0.05600743,-0.02942878,-0.02128558,-0.02340316,0.01402597,0.02863229,-0.02664023,0.07812176,0.05318474,-0.00247919,-0.05966633,0.02170368,-0.05667127,-0.04036121,-0.05126294,-0.04571008,0.06905451,0.00261226,-0.02161491,0.03895404,0.0015801,-0.02723074,-0.0753378,-0.02506912,0.01214028,0.00117553,-0.06900182,-0.04246907,-0.02179024,0.03586684,-0.0476522,-0.03227823,0.01233268,0.03810169,0.04092003,-0.04422799,0.04022782,0.00739747,-0.0535354,-0.2317827,-0.03293209,-0.01324738,0.00071942,0.07991257,-0.07874301,0.02203164,-0.02883541,0.06256703,0.00683187,0.00726632,-0.04445307,-0.06665496,-0.02450158,0.00148134,0.03012523,-0.00760903,0.06060093,-0.05266358,0.0135263,0.02921,-0.00734228,0.00328903,-0.09750827,0.03275337,0.00882238,0.21477966,-0.04915528,-0.00702592,0.01445808,0.00968594,-0.03138445,-0.01809168,-0.08173376,0.07474361,0.02321994,-0.02213666,0.03561522,-0.00944985,-0.04727152,-0.06002511,0.04813888,0.00910837,-0.10571469,-0.02705346,-0.01280677,-0.03215795,-0.07604816,-0.00690729,-0.02601268,0.03069223,-0.0460237,-0.01371371,0.08584587,0.00844895,-0.06557649,-0.029575,0.01036584,-0.02073797,0.04208546,-0.0063724,-0.03476276,-0.02345852,0.01378477,0.0742574,0.01309343,0.0497178,-0.01328522,-0.01265767,-0.03952688,-0.01114036,0.13401955,-0.05517214,-0.03801725,0.06475425,-0.01496209,-0.02484705,-0.08911987,-0.03797978,0.03995585,0.03300938,-0.04624698,0.02998665,0.0429638,0.03817876,0.01700824,0.04252547,0.02631341,0.07027515,0.05642482,0.04898595,0.05742949,-0.0456894,0.0087458,0.01118975,-0.02037437,-0.26205644,0.06135061,-0.00744622,0.03132394,0.00508826,0.03378047,0.0402702,0.01502233,-0.07442959,0.00612305,0.00772411,0.03099539,0.03063814,-0.00176136,0.01168044,0.03300955,0.06900458,0.01107546,0.0552855,-0.03860663,0.02246195,0.00216844,0.19317751,-0.00036067,0.04866283,0.04955907,-0.00596758,0.03128703,0.04986912,-0.03058582,-0.00367679,-0.02713207,0.12855662,-0.00891021,0.09429747,0.01231162,-0.034325,0.03949893,0.08515283,0.03074447,-0.0221358,0.02837673,-0.00916163,0.01338903,0.07834227,0.01515759,-0.05329167,-0.05310902,-0.07098792,0.02760816,-0.03313421,-0.02682013,0.01489652,-0.04190322,0.01463811,-0.04045055,-0.00736001,-0.02454978,-0.02046726,0.00071334,0.01264332,-0.01958559,0.04772696,-0.02858543,-0.05101004],"last_embed":{"hash":"ffdbe110a0ba92234371a5ce38e63b6be0e9d982b50b65e3e8ebe63ad8ac9fb4","tokens":416}}},"text":null,"length":0,"last_read":{"hash":"ffdbe110a0ba92234371a5ce38e63b6be0e9d982b50b65e3e8ebe63ad8ac9fb4","at":1744208995258},"key":"3_AI Engineering/5.3 AI Agent/1. Long Term Memory User/Read 0. Reference.md#Deep Research: Nguá»“n 12/3/2025#{1}","lines":[25,1028],"size":76407,"outlinks":[{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nShort-term memory, or thread -scoped memory, can be recalled at any time from within a single conversational thread with a user. LangGraph manages short- term memory as a part of your agent's 51. State is persisted to a database using a checkpointer so the thread can be resumed at any time. Short-term memory updates when the graph is invoked or a step is completed, and the State is read at the start of each step.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Short,the%20start%20of%20each%20step","line":4},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nLangGraph manages short-term memory as part of the agent's state, persisted via thread-scoped checkpoints. This state can normally include the conversation history along with other stateful data, such as uploaded files, retrieved documents, or generated artifacts. By storing these in the graph's state, the bot can access the full context for a given conversation while maintaining separation between different threads.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=LangGraph%20manages%20short,maintaining%20separation%20between%20different%20threads","line":12},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nShort-term memory, or thread -scoped memory, can be recalled at any time from within a single conversational thread with a user. LangGraph manages short- term memory as a part of your agent's 51. State is persisted to a database using a checkpointer so the thread can be resumed at any time. Short-term memory updates when the graph is invoked or a step is completed, and the State is read at the start of each step.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Short,the%20start%20of%20each%20step","line":20},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nLong conversations pose a challenge to today's LLMs. The full history may not even fit inside an LLM's context window, resulting in an irrecoverable error. Even if your LLM technically supports the full context length, most LLMs still perform poorly over long contexts. They get \"distracted\" by stale or off-topic content, all while suffering from slower response times and higher costs.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Long%20conversations%20pose%20a%20challenge,response%20times%20and%20higher%20costs","line":28},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nChat models accept context using messages, which include developer provided instructions (a system message) and user inputs (human messages). In chat applications, messages alternate between human inputs and model responses, resulting in a list of messages that grows longer over time. Because context windows are limited and token-rich message lists can be costly, many applications can benefit from using techniques to manually remove or forget stale information.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Chat%20models%20accept%20context%20using,remove%20or%20forget%20stale%20information","line":36},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nSummarizing past conversationsÂ¶\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Summarizing%20past%20conversations%C2%B6","line":44},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\ndef summarize_conversation(state: State):\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=def%20summarize_conversation","line":52},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nLong-term memory is shared across conversational threads. It can be recalled at any time and in any thread. Memories are scoped to any custom namespace, not just within a single thread ID. LangGraph provides stores (reference doc) to let you save and recall long-term memories.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Long,term%20memories","line":60},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nLong-term memory in LangGraph allows systems to retain information across different conversations or sessions. Unlike short-term memory, which is thread-\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Long,term%20memory%2C%20which%20is%20thread","line":68},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nLangGraph stores long-term memories as JSON documents in a store ( 54). Each memory is organized under a custom `namespace` (similar to a folder) and a distinct `key` (like a filename). Namespaces often include user or org IDs or other labels that makes it easier to organize information. This structure enables hierarchical organization of memories. Cross-namespace searching is then supported through content filters. See the example below for an example.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=LangGraph%20stores%20long,example%20below%20for%20an%20example","line":76},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\n# InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production use. store = InMemoryStore(index={\"embed\": embed, \"dims\": 2}) user_id = \"my-user\" application_context = \"chitchat\" namespace = (user_id, application_context) store.put( namespace, \"a-memory\",\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=,memory","line":84},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nuser_id = \"my-user\" application_context = \"chitchat\" namespace = (user_id, application_context) store.put( namespace, \"a-memory\", { \"rules\": [ \"User likes short, direct language\",\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=user_id%20%3D%20%22my,User%20likes%20short%2C%20direct%20language","line":92},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\n# get the \"memory\" by ID item = store.get(namespace, \"a-memory\") # search for \"memories\" within this namespace, filtering on content equivalence, sorted by vector similarity items = store.search( namespace, filter={\"my-key\": \"my-value\"}, query=\"language preferences\" )\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=,value%22%7D%2C%20query%3D%22language%20preferences%22","line":100},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nLong-term memory is shared across conversational threads. It can be recalled at any time and in any thread. Memories are scoped to any custom namespace, not just within a single thread ID. LangGraph provides stores ( 54) to let you save and recall long-term memories.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Long,term%20memories","line":108},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nDifferent applications require various types of memory. Although the analogy isn't perfect, examining human memory types can be insightful. Some research (e.g., the CoALA paper) have even mapped these human memory types to those used in AI agents.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Different%20applications%20require%20various%20types,those%20used%20in%20AI%20agents","line":116},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nMemory Type What is Stored Human Example Agent Example Semantic Facts Things I learned in school Facts about a user Episodic Experiences Things I did Past agent actions Procedural Instructions Instincts or motor skills Agent system prompt\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Memory%20Type%20What%20is%20Stored,motor%20skills%20Agent%20system%20prompt","line":124},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nSemantic memory, both in humans and AI agents, involves the retention of specific facts and concepts. In humans, it can include information learned in school and the understanding of concepts and their relationships. For AI agents, semantic memory is often used to personalize applications by remembering facts or concepts from past interactions.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Semantic%20memory%2C%20both%20in%20humans,or%20concepts%20from%20past%20interactions","line":132},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\n# ProfileÂ¶\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=","line":140},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nAlternatively, memories can be a collection of documents that are continuously updated and extended over time. Each individual memory can be more narrowly scoped and easier to generate, which means that you're less likely to lose information over time. It's easier for an LLM to generate new objects for new information than reconcile new information with an existing profile. As a result, a document collection tends to lead to higher recall downstream.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=Alternatively%2C%20memories%20can%20be%20a,lead%20to%20higher%20recall%20downstream","line":148},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\npairs you've selected to represent your domain.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=pairs%20you%27ve%20selected%20to%20represent,your%20domain","line":156},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nHowever, this shifts some complexity memory updating. The model must now delete or update existing items in the list, which can be tricky. In addition, some models may default to over-inserting and others may default to over-updating. See the Trustcall package for one way to manage this and consider evaluation (e.g., with a tool like LangSmith) to help you tune the behavior.\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=However%2C%20this%20shifts%20some%20complexity,help%20you%20tune%20the%20behavior","line":164},{"title":"\r\n\r\nlangchain-ai.github.io\r\n\r\nMemory\r\n\r\nWhen do you want to update memories?\r\n\r\n","target":"https://langchain-ai.github.io/langgraph/concepts/memory/#:~:text=When%20do%20you%20want%20to,update%20memories","line":172},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://redis.io&sz=32","line":180},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://redis.io&sz=32","line":188},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.graphlit.com&sz=32","line":196},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.graphlit.com&sz=32","line":204},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://docs.mem0.ai&sz=32","line":212},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://docs.mem0.ai&sz=32","line":220},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://microsoft.github.io&sz=32","line":228},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://microsoft.github.io&sz=32","line":236},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://redis.io&sz=32","line":244},{"title":"\r\n\r\nnews.ycombinator.com\r\n\r\nShow HN: Mem0 â€“ open-source Memory Layer for AI apps | Hacker News\r\n\r\nHi this looks interesting. From your description it looks like mem0 remembers details and context of previous chats but not the actual text of chats. Is this a correct assumption?\r\n\r\n","target":"https://news.ycombinator.com/item?id=41447317#:~:text=Hi%20this%20looks%20interesting,Is%20this%20a%20correct%20assumption","line":252},{"title":"\r\n\r\nnews.ycombinator.com\r\n\r\nShow HN: Mem0 â€“ open-source Memory Layer for AI apps | Hacker News\r\n\r\n3. Content management: Claude has minimum length requirements for caching (1024 characters for Sonnet, 2048 for Haiku). Mem0 can handle information of any length, from short facts to longer contexts. 4. Customization: Developers have greater control over Mem0's memory management, including options for prioritizing or deprioritizing information based on relevance or time. Claude's caching system offers less direct control. 5. Information retrieval: Mem0 is designed for more precise and targeted information retrieval, while Claude's cache works with broader contextual blocks.\r\n\r\n","target":"https://news.ycombinator.com/item?id=41447317#:~:text=3,works%20with%20broader%20contextual%20blocks","line":260},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.graphlit.com&sz=32","line":268},{"title":"\r\n\r\nnews.ycombinator.com\r\n\r\nShow HN: Mem0 â€“ open-source Memory Layer for AI apps | Hacker News\r\n\r\nAs mentioned in the post, we use a hybrid datastore approach that handles these cases effectively and that's where the graph aspect comes into picture.\r\n\r\n","target":"https://news.ycombinator.com/item?id=41447317#:~:text=As%20mentioned%20in%20the%20post%2C,graph%20aspect%20comes%20into%20picture","line":276},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://redis.io&sz=32","line":284},{"title":"\r\n\r\nnews.ycombinator.com\r\n\r\nShow HN: Mem0 â€“ open-source Memory Layer for AI apps | Hacker News\r\n\r\n1. Purpose and duration: Claude's cache is designed for short-term memory, clearing every 5 minutes. In contrast, Mem0 is built for long-term information storage, retaining data indefinitely unless instructed otherwise. 2. Flexibility and control: Mem0 offers more flexibility, allowing developers to update, delete, or modify stored information as needed. Claude's cache is more static - new information creates additional entries rather than updating existing ones. 3. Content management: Claude has minimum length requirements for caching (1024 characters for Sonnet, 2048 for Haiku). Mem0 can handle information of any length, from short facts to longer contexts. 4. Customization: Developers have\r\n\r\n","target":"https://news.ycombinator.com/item?id=41447317#:~:text=1,Customization%3A%20Developers%20have","line":292},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.graphlit.com&sz=32","line":300},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://microsoft.github.io&sz=32","line":308},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.graphlit.com&sz=32","line":316},{"title":"\r\n\r\nnews.ycombinator.com\r\n\r\nShow HN: Mem0 â€“ open-source Memory Layer for AI apps | Hacker News\r\n\r\ndesigned for more precise and targeted information retrieval, while Claude's cache works with broader contextual blocks.\r\n\r\n","target":"https://news.ycombinator.com/item?id=41447317#:~:text=designed%20for%20more%20precise%20and,works%20with%20broader%20contextual%20blocks","line":324},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://redis.io&sz=32","line":332},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.anthropic.com&sz=32","line":340},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":348},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.lukew.com&sz=32","line":356},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.lukew.com&sz=32","line":364},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":372},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.lukew.com&sz=32","line":380},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.getzep.com&sz=32","line":388},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":396},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":404},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":412},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":420},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":428},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":434},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":440},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":448},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.generational.pub&sz=32","line":456},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":464},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":472},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":480},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":488},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":496},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":504},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":512},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.me.bot&sz=32","line":520},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":528},{"title":"\r\n\r\nlangchain-ai.github\r\n\r\n5\r\n\r\n\r\n\r\n","target":"https://langchain-ai.github.io/","line":540},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://docs.mem0.ai&sz=32","line":548},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.graphlit.com&sz=32","line":556},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":560},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://medium.com&sz=32","line":568},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://microsoft.github.io&sz=32","line":576},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://redis.io&sz=32","line":580},{"title":"\r\n\r\nnews.ycombinator\r\n\r\n2\r\n\r\n\r\n\r\n","target":"https://news.ycombinator.com/","line":588},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.cognee.ai&sz=32","line":596},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":600},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.lukew.com&sz=32","line":604},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.qiscus.com&sz=32","line":608},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://www.anthropic.com&sz=32","line":616},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":627},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":635},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":643},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":651},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":659},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":667},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://en.wikipedia.org&sz=32","line":675},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://en.wikipedia.org&sz=32","line":683},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://en.wikipedia.org&sz=32","line":691},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":699},{"title":"\r\n\r\nopenreview.net\r\n\r\nLanguage model with Plug-in Knowldge Memory | OpenReview\r\n\r\nof knowledge PLM needs to solve certain task. In this paper, we introduce PlugLM, a pre-training model with differentiable plug-in memory(DPM). The key intuition behind is to decouple the knowledge storage from model parameters with an editable and scalable key-value memory and leverage knowledge in an explainable manner by knowledge retrieval in the DPM. We conduct extensive experiments under various settings to justify this design choice. In domain adaptation setting, PlugLM could be easily adapted to different domains with plugable in-domain memory---obtaining 3.95 F1 improvements across four domains, without any in-domain training. PlugLM could also keep absorbing new knowledge\r\n\r\n","target":"https://openreview.net/forum?id=Plr5l7r0jY6#:~:text=of%20knowledge%20PLM%20needs%20to,also%20keep%20absorbing%20new%20knowledge","line":707},{"title":"\r\n\r\nopenreview.net\r\n\r\nLanguage model with Plug-in Knowldge Memory | OpenReview\r\n\r\nadaptation setting, PlugLM could be easily adapted to different domains with plugable in-domain memory---obtaining 3.95 F1 improvements across four domains, without any in-domain training. PlugLM could also keep absorbing new knowledge after pre-training is done by knowledge updating operation in the DPM without re-training. Finally, we show that by incorporating training samples into DPM with knowledge prompting, PlugLM could further be improved by the instruction of in-task knowledge.\r\n\r\n","target":"https://openreview.net/forum?id=Plr5l7r0jY6#:~:text=adaptation%20setting%2C%20PlugLM%20could%20be,task%20knowledge","line":715},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":723},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":731},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":739},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":747},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":753},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":759},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":765},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":771},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":777},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":785},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":793},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":801},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":809},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://ar5iv.labs.arxiv.org&sz=32","line":817},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://medium.com&sz=32","line":825},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://ar5iv.labs.arxiv.org&sz=32","line":833},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://medium.com&sz=32","line":841},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":849},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":857},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":865},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":873},{"title":"\r\n\r\nopenreview.net\r\n\r\n200 The event memory module is designed to perceive 201 historical events to generate coherent responses 202 across interval time. As shown in Figure 2, this 203 event memory module is segmented into two major 204 sub-modules that focus separately on long-term 205 and short-term memory. 206 2.2.1 Long-term Memory 207 Memory Storage. The long-term memory mod\u0002208 ule aims to extract and encode events from past 209 sessions. Specifically, this involves recording\r\n\r\n","target":"https://openreview.net/pdf?id=lwCxVgVYoK#:~:text=200%20The%20event%20memory%20module,Specifically%2C%20this%20involves%20recording","line":881},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":887},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://medium.com&sz=32","line":895},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://medium.com&sz=32","line":903},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://medium.com&sz=32","line":911},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":919},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":927},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":935},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":943},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":951},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":959},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":967},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://arxiv.org&sz=32","line":975},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":983},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://aclanthology.org&sz=32","line":989},{"title":"\r\n\r\n![Favicon","target":"https://www.google.com/s2/favicons?domain=https://medium.com&sz=32","line":995}],"class_name":"SmartBlock"},
