Twelve Labs provides state-of-the-art video understanding APIs that extract rich insights and information from video content. 
: https://blog.langchain.dev/jockey-twelvelabs-langgraph/
: https://docs.twelvelabs.io/docs/multimodal-language-models


Trích dẫn bài báo: 
SOTA of Video Understanding: 
- Twelve Labs provides state-of-the-art video understanding APIs that extract rich insights and information from video content.
- When you watch a movie, you typically use multiple senses to experience it. For example, you use your eyes to see the actors and objects on the screen and your ears to hear the dialogue and sounds. Using only one sense, you would miss essential details like body language or conversation. Furthermore, your brain processes how the visual and audio elements change over time, understanding the temporal relationship between frames to grasp the complete story. For example, you're watching a scene where a person appears to cry. If viewed in isolation, you might conclude the person is sad. However, these tears come after a sequence showing the character winning a hard-earned award. In this case, the interpretation changes: the tears are joy, not sorrow. This illustrates how the temporal aspect — the context and sequence of events leading up to the tears — is essential for correctly determining the character's emotions.


--------
Video Understanding: 
- https://github.com/om-ai-lab/OmAgent