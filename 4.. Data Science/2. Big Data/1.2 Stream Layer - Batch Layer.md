
![[Pasted image 20241214232612.png]]

### Giải thích chi tiết file script

Đây là một script chạy các thành phần của hệ thống **Big Data**, gồm hai phần chính:
1. **Stream Layer (Xử lý dữ liệu thời gian thực).**
2. **Batch Layer (Xử lý dữ liệu theo lô).**

---

### **Chi tiết từng phần**

#### **1. Stream Layer**
Phần này khởi động và thiết lập các công cụ để xử lý dữ liệu thời gian thực.

| **Lệnh**                                                                                           | **Chức năng**                                                                                                                                 |
|----------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------|
| `zookeeper-server-start.bat C:/kafka_2.13_2.6.0/config/zookeeper.properties`                       | Khởi động **Zookeeper**, một dịch vụ hỗ trợ quản lý các cluster Kafka.                                                                      |
| `kafka-server-start.bat C:/kafka_2.13_2.6.0/config/server.properties`                              | Khởi động **Kafka server**, dịch vụ xử lý dữ liệu streaming (luồng dữ liệu).                                                                |
| `kafka-topics.bat --create --topic smartphoneTopic --bootstrap-server localhost:9092`              | Tạo một **topic** trong Kafka tên là `smartphoneTopic`.                                                                                     |
| `kafka-console-producer.bat --topic smartphoneTopic --bootstrap-server localhost:9092`             | Khởi chạy **producer** để gửi dữ liệu vào topic `smartphoneTopic`.                                                                          |
| `kafka-console-consumer.bat --topic smartphoneTopic --from-beginning --bootstrap-server localhost:9092` | Khởi chạy **consumer** để nhận và xử lý dữ liệu từ topic `smartphoneTopic`.                                                                 |
| `start-all`                                                                                        | Khởi động HDFS (Hadoop Distributed File System) và YARN (công cụ quản lý tài nguyên).                                                       |
| `hbase shell`                                                                                      | Mở **HBase shell** để tương tác với HBase, cơ sở dữ liệu NoSQL dùng lưu trữ dữ liệu thời gian thực.                                         |
| `hbase thrift start`                                                                               | Khởi chạy **Thrift server**, cho phép các ứng dụng bên ngoài kết nối với HBase thông qua API.                                               |

---

#### **2. Batch Layer**
Phần này dùng để xử lý dữ liệu theo lô, thường áp dụng cho các phân tích lớn và lưu trữ dữ liệu lịch sử.

| **Lệnh**                                                                                           | **Chức năng**                                                                                                                                 |
|----------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------|
| `docker-compose up -d`                                                                             | Khởi chạy Apache **Airflow** (công cụ lập lịch trình và điều phối các luồng công việc) bằng Docker.                                          |
| `spark-shell`                                                                                      | Mở **Spark Shell** để thực hiện các tác vụ xử lý dữ liệu lớn theo lô.                                                                        |
| `zookeeper-server-start.bat C:/kafka_2.13_2.6.0/config/zookeeper.properties`                       | (Tương tự Stream Layer) Khởi động **Zookeeper** để quản lý Kafka cluster.                                                                   |
| `kafka-server-start.bat C:/kafka_2.13_2.6.0/config/server.properties`                              | (Tương tự Stream Layer) Khởi động Kafka server để xử lý luồng dữ liệu.                                                                      |
| `kafka-console-producer.bat --topic smartphoneTopic --bootstrap-server localhost:9092`             | (Tương tự Stream Layer) Khởi chạy producer để gửi dữ liệu vào Kafka.                                                                        |
| `kafka-console-consumer.bat --topic smartphoneTopic --from-beginning --bootstrap-server localhost:9092` | (Tương tự Stream Layer) Khởi chạy consumer để nhận dữ liệu từ Kafka.                                                                        |
| `start-all`                                                                                        | Khởi động HDFS và YARN (giống Stream Layer).                                                                                                |

---

### **Tóm tắt các thành phần**

| **Thành phần**      | **Vai trò**                                                                                                                                                          |
|---------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Zookeeper**       | Quản lý trạng thái Kafka Cluster và điều phối các node trong cluster.                                                                                              |
| **Kafka**           | Hệ thống xử lý dữ liệu luồng, dùng để lưu trữ và truyền dữ liệu giữa các hệ thống khác nhau.                                                                         |
| **HDFS**            | Hệ thống lưu trữ phân tán, lưu dữ liệu để xử lý trong Batch Layer.                                                                                                 |
| **YARN**            | Quản lý tài nguyên trong cluster Hadoop (quản lý CPU, RAM cho các tác vụ).                                                                                         |
| **HBase**           | Cơ sở dữ liệu NoSQL lưu trữ dữ liệu thời gian thực (real-time view).                                                                                               |
| **Thrift Server**   | Dịch vụ giao tiếp với HBase qua các giao thức như HTTP hoặc RPC.                                                                                                   |
| **Airflow**         | Điều phối các tác vụ (ví dụ: xử lý theo lô, ETL).                                                                                                                   |
| **Spark**           | Công cụ xử lý dữ liệu lớn, dùng để tính toán và phân tích dữ liệu trong Batch Layer.                                                                                |

---

### **Cách hoạt động tổng quan**
1. **Stream Layer**:
   - Kafka nhận và xử lý dữ liệu thời gian thực (dữ liệu smartphone).
   - Dữ liệu được lưu tạm trong Kafka, rồi ghi vào HBase (lưu trữ real-time view).

2. **Batch Layer**:
   - Dữ liệu từ Kafka hoặc HDFS được xử lý theo lô bằng Spark.
   - Airflow quản lý các quy trình ETL và chuyển kết quả vào cơ sở dữ liệu khác để phân tích.

---

### **Lưu ý**
- **Đường dẫn cụ thể** (`C:/kafka_2.13_2.6.0`) phải được thay đổi tùy vào hệ thống của bạn.
- **Docker Compose**: Airflow chạy trong container, vì vậy cần Docker được cài đặt trước.

Dưới đây là giải thích **cực kỳ đơn giản** về các công cụ trong hệ thống Big Data, được trình bày dưới dạng bảng để dễ hiểu:

---

### **1. Apache Kafka**

|**Công cụ**|**Apache Kafka**|
|---|---|
|**Chức năng chính**|Chuyển dữ liệu giữa các hệ thống theo thời gian thực (giống như bưu điện chuyển thư).|
|**Thành phần**|- **Producer**: Gửi dữ liệu vào hệ thống.- **Consumer**: Lấy dữ liệu ra từ hệ thống.- **Topic**: "Hộp thư" chứa dữ liệu.|
|**Ví dụ dễ hiểu**|Khi bạn nhắn tin qua Messenger, Kafka giống như hệ thống chuyển tin nhắn từ người gửi đến người nhận.|
|**Vai trò**|- Lưu và chuyển dữ liệu.- Xử lý dữ liệu luồng (streaming).|

---

### **2. Zookeeper**

|**Công cụ**|**Apache Zookeeper**|
|---|---|
|**Chức năng chính**|Quản lý các dịch vụ trong hệ thống phân tán (giống như "quản gia" của Kafka).|
|**Vai trò**|- Quản lý thông tin của Kafka Cluster.- Đảm bảo các node (máy tính) trong hệ thống phối hợp nhịp nhàng.|
|**Ví dụ dễ hiểu**|Giống như "điều phối viên" của một đội bóng đá, giúp các cầu thủ phối hợp ăn ý.|

---

### **3. HDFS (Hadoop Distributed File System)**

|**Công cụ**|**HDFS**|
|---|---|
|**Chức năng chính**|Lưu trữ dữ liệu lớn trên nhiều máy tính (giống như một ổ cứng khổng lồ).|
|**Cách hoạt động**|- Dữ liệu được chia nhỏ thành các mảnh nhỏ (blocks).- Các mảnh nhỏ này được lưu trên nhiều máy.|
|**Ví dụ dễ hiểu**|Giống như khi bạn lưu một bộ phim dài trên nhiều USB khác nhau để tiết kiệm dung lượng.|
|**Vai trò**|- Lưu trữ dữ liệu lớn như file log, video, dữ liệu cảm biến,...|

---

### **4. YARN (Yet Another Resource Negotiator)**

|**Công cụ**|**YARN**|
|---|---|
|**Chức năng chính**|Quản lý tài nguyên (CPU, RAM) cho các tác vụ (giống như "quản lý tài nguyên máy chủ").|
|**Cách hoạt động**|- Khi một ứng dụng cần tài nguyên, YARN sẽ cấp phát tài nguyên đó.- Đảm bảo mọi tác vụ đều chạy ổn định.|
|**Ví dụ dễ hiểu**|Giống như quản lý nhà bếp trong nhà hàng, phân chia bếp và nguyên liệu cho từng món ăn.|

---

### **5. HBase**

|**Công cụ**|**HBase**|
|---|---|
|**Chức năng chính**|Cơ sở dữ liệu NoSQL, lưu trữ và truy vấn dữ liệu lớn theo thời gian thực.|
|**Cách hoạt động**|- Lưu dữ liệu dưới dạng bảng, nhưng hỗ trợ lưu trữ và truy vấn nhanh chóng.- Tích hợp tốt với HDFS.|
|**Ví dụ dễ hiểu**|Giống như một bảng tính Excel khổng lồ, có thể ghi và đọc dữ liệu cực nhanh.|
|**Vai trò**|Lưu trữ dữ liệu thời gian thực như giá cổ phiếu, cảm biến IoT,...|

---

### **6. Apache Spark**

|**Công cụ**|**Apache Spark**|
|---|---|
|**Chức năng chính**|Xử lý dữ liệu lớn cực nhanh, hỗ trợ cả thời gian thực và theo lô (batch processing).|
|**Thành phần chính**|- Spark Core: Xử lý dữ liệu.- Spark SQL: Truy vấn dữ liệu dạng SQL.- Spark Streaming: Xử lý dữ liệu thời gian thực.|
|**Ví dụ dễ hiểu**|Giống như một đầu bếp tốc độ cao, có thể nấu nhiều món ăn (dữ liệu) trong thời gian ngắn.|
|**Vai trò**|- Phân tích dữ liệu lớn.- Tính toán nhanh chóng.|

---

### **7. Apache Airflow**

|**Công cụ**|**Apache Airflow**|
|---|---|
|**Chức năng chính**|Quản lý và tự động hóa các luồng công việc (workflow).|
|**Cách hoạt động**|- Bạn định nghĩa các tác vụ (tasks) và thứ tự chạy của chúng.- Airflow sẽ tự động chạy các tác vụ này theo lịch trình.|
|**Ví dụ dễ hiểu**|Giống như một người quản lý dự án, sắp xếp công việc cho từng thành viên và đảm bảo mọi thứ đúng hạn.|
|**Vai trò**|- Lập lịch và điều phối các tác vụ ETL (Extract, Transform, Load).|

---

### **Tóm tắt bảng tổng quan**

|**Công cụ**|**Vai trò chính**|**Ví dụ dễ hiểu**|
|---|---|---|
|Kafka|Chuyển dữ liệu giữa các hệ thống theo thời gian thực.|Chuyển tin nhắn Messenger giữa người gửi và người nhận.|
|Zookeeper|Điều phối và quản lý Kafka cluster.|Quản lý đội bóng đá để các cầu thủ phối hợp hiệu quả.|
|HDFS|Lưu trữ dữ liệu lớn trên nhiều máy.|Lưu file phim lớn trên nhiều USB khác nhau.|
|YARN|Quản lý tài nguyên (CPU, RAM) cho các ứng dụng.|Quản lý nhà bếp, phân chia bếp cho từng món ăn.|
|HBase|Lưu trữ và truy vấn dữ liệu lớn theo thời gian thực.|Một bảng tính Excel khổng lồ, truy vấn siêu nhanh.|
|Spark|Xử lý dữ liệu lớn nhanh chóng, hỗ trợ thời gian thực và theo lô.|Đầu bếp tốc độ cao nấu nhiều món cùng lúc.|
|Airflow|Quản lý và tự động hóa các luồng công việc.|Quản lý dự án, sắp xếp và tự động hóa công việc.|

---

Nếu bạn cần thêm thông tin hoặc giải thích cụ thể về cách sử dụng, mình sẵn sàng hỗ trợ! 😊


Dưới đây là bảng tổng hợp thông tin các **port** trong HDFS và chức năng của chúng:

|**Công cụ/Thành phần**|**Port**|**Chức năng**|
|---|---|---|
|**NameNode RPC**|`8020`|Giao tiếp chính giữa NameNode và client hoặc các DataNode.|
|**NameNode Web Interface**|`9870`|Giao diện quản trị web của NameNode (truy cập thông tin cluster qua trình duyệt).|
|**DataNode IPC**|`50020`|Giao tiếp chính giữa DataNode và NameNode.|
|**DataNode Web Interface**|`9864`|Giao diện quản trị web của DataNode (thông tin block, dung lượng).|
|**Secondary NameNode Web**|`9868`|Giao diện web của Secondary NameNode (nếu có).|
|**YARN ResourceManager RPC**|`8032`|Giao tiếp giữa ResourceManager và các NodeManager hoặc client (trong YARN).|
|**YARN Web Interface**|`8088`|Giao diện web quản trị ResourceManager.|
|**NodeManager Web Interface**|`8042`|Giao diện web của NodeManager (trong YARN).|

### Lưu ý:

1. Các port trên có thể được thay đổi trong file cấu hình của Hadoop (`core-site.xml`, `hdfs-site.xml`, `yarn-site.xml`).
2. Mặc định, tất cả giao diện web và giao tiếp RPC đều hoạt động trên **HTTP** hoặc **HTTPS** nếu được bật.
3. Đảm bảo các port được mở trong tường lửa để các thành phần của cluster có thể kết nối được.

Nếu cần thêm thông tin chi tiết về cách cấu hình, hãy cho mình biết nhé!


---
#### **Stream Layer**

[](https://github.com/DoanNgocCuong/Big-Data-Project_2#1-stream-layer)

- Start Apache zookeeper

```batchfile
zookeeper-server-start.bat C:/kafka_2.13_2.6.0/config/zookeeper.properties
```

- Start Kafka server

```batchfile
kafka-server-start.bat C:/kafka_2.13_2.6.0/config/server.properties
```

- Create Kafka topic

```batchfile
kafka-topics.bat --create --topic smartphoneTopic --bootstrap-server localhost:9092
```

- Run the kafka producer

```batchfile
kafka-console-producer.bat --topic smartphoneTopic --bootstrap-server localhost:9092
```

- Run the kafka consumer

```batchfile
kafka-console-consumer.bat --topic smartphoneTopic --from-beginning --bootstrap-server localhost:9092
```

- Start HDFS and yarn (start-all or start-dfs and start-yarn)

```batchfile
start-all  
```

- Start Hbase

```batchfile
start-hbase  
```

- Run thrift server (for Hbase)

```batchfile
hbase thrift start
```

after all this run `stream_pipeline.py` script.

and then open the spring boot appliation in your idea and run it (you can access to the web app locally on `localhost:8081/`)


### **Bảng tóm tắt các bước chạy Stream Layer**

|**Bước**|**Lệnh thực thi**|**Mô tả**|
|---|---|---|
|**1. Start Apache Zookeeper**|`zookeeper-server-start.bat C:/kafka_2.13_2.6.0/config/zookeeper.properties`|Khởi chạy Zookeeper để quản lý Kafka.|
|**2. Start Kafka Server**|`kafka-server-start.bat C:/kafka_2.13_2.6.0/config/server.properties`|Khởi chạy Kafka Broker để xử lý message.|
|**3. Create Kafka Topic**|`kafka-topics.bat --create --topic smartphoneTopic --bootstrap-server localhost:9092`|Tạo một topic Kafka tên là `smartphoneTopic` để lưu trữ message.|
|**4. Run Kafka Producer**|`kafka-console-producer.bat --topic smartphoneTopic --bootstrap-server localhost:9092`|Chạy producer để gửi message tới topic `smartphoneTopic`.|
|**5. Run Kafka Consumer**|`kafka-console-consumer.bat --topic smartphoneTopic --from-beginning --bootstrap-server localhost:9092`|Chạy consumer để nhận message từ topic `smartphoneTopic`.|
|**6. Start HDFS and YARN**|`start-all`|Khởi động HDFS và YARN để quản lý lưu trữ phân tán và xử lý dữ liệu.|
|**7. Start HBase**|`start-hbase`|Khởi động HBase để lưu trữ dữ liệu phi cấu trúc.|
|**8. Run Thrift Server**|`hbase thrift start`|Chạy Thrift Server để cung cấp giao diện REST hoặc giao tiếp qua RPC cho HBase.|
|**9. Run Python Pipeline**|`python stream_pipeline.py`|Chạy script `stream_pipeline.py` để xử lý dữ liệu stream từ Kafka và lưu trữ vào HDFS hoặc HBase.|
|**10. Start Spring Boot App**|Chạy Spring Boot App trong IDE. Truy cập tại `http://localhost:8081/`.|Khởi chạy ứng dụng Spring Boot để hiển thị dashboard và xử lý yêu cầu từ người dùng.|

### **Ghi chú**

- Đảm bảo các công cụ như Kafka, Zookeeper, HBase, HDFS được cài đặt và cấu hình đúng.
- Kiểm tra log nếu gặp lỗi khi chạy từng bước.
Dưới đây là danh sách các **port** để kiểm tra giao diện người dùng (UI) của các thành phần:

| **Thành phần**           | **Port**        | **URL để truy cập UI**           | **Mô tả giao diện**                                                                    |
| ------------------------ | --------------- | -------------------------------- | -------------------------------------------------------------------------------------- |
| **Kafka Control Center** | 9021            | `http://localhost:9021`          | Quản lý Kafka, giám sát topic, producer và consumer.                                   |
| **HDFS (NameNode)**      | 9870            | `http://localhost:9870`          | Theo dõi trạng thái của HDFS NameNode.                                                 |
| **HBase Thrift Server**  | 9095            | Cần cấu hình thêm nếu muốn UI    | Giao diện quản lý HBase qua Thrift (thường phải triển khai thêm một giao diện cụ thể). |
| **Airflow Web UI**       | 8080            | `http://localhost:8080`          | Xem và quản lý DAG trong Apache Airflow.                                               |
| **Spring Boot App**      | 8081            | `http://localhost:8081`          | Giao diện chính của ứng dụng, hiển thị dashboard và kết quả xử lý dữ liệu.             |
| **Spark Master UI**      | 9090            | `http://localhost:9090`          | Giám sát các tác vụ và worker của Spark Master.                                        |
| **Spark Worker UI**      | 8080 (mặc định) | `http://localhost:<worker-port>` | Xem thông tin chi tiết các worker.                                                     |
| **Cassandra DB**         | Không có UI     | N/A                              | Cassandra không cung cấp UI mặc định, có thể sử dụng công cụ bên thứ ba như DataStax.  |

### **Lưu ý:**

- Nếu gặp lỗi truy cập, kiểm tra cấu hình trong file `docker-compose.yml` để đảm bảo các port đã được ánh xạ chính xác.
- Đảm bảo rằng các dịch vụ tương ứng đã được khởi động thành công trước khi truy cập UI.