
![[Pasted image 20241214232612.png]]

### Giải thích chi tiết file script

Đây là một script chạy các thành phần của hệ thống **Big Data**, gồm hai phần chính:
1. **Stream Layer (Xử lý dữ liệu thời gian thực).**
2. **Batch Layer (Xử lý dữ liệu theo lô).**
		- Hadoop lưu trữ  HDFS và xử lý dữ liệu Map reduces

---

### **Chi tiết từng phần**

#### **1. Stream Layer**
Phần này khởi động và thiết lập các công cụ để xử lý dữ liệu thời gian thực.

| **Lệnh**                                                                                           | **Chức năng**                                                                                                                                 |
|----------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------|
| `zookeeper-server-start.bat C:/kafka_2.13_2.6.0/config/zookeeper.properties`                       | Khởi động **Zookeeper**, một dịch vụ hỗ trợ quản lý các cluster Kafka.                                                                      |
| `kafka-server-start.bat C:/kafka_2.13_2.6.0/config/server.properties`                              | Khởi động **Kafka server**, dịch vụ xử lý dữ liệu streaming (luồng dữ liệu).                                                                |
| `kafka-topics.bat --create --topic smartphoneTopic --bootstrap-server localhost:9092`              | Tạo một **topic** trong Kafka tên là `smartphoneTopic`.                                                                                     |
| `kafka-console-producer.bat --topic smartphoneTopic --bootstrap-server localhost:9092`             | Khởi chạy **producer** để gửi dữ liệu vào topic `smartphoneTopic`.                                                                          |
| `kafka-console-consumer.bat --topic smartphoneTopic --from-beginning --bootstrap-server localhost:9092` | Khởi chạy **consumer** để nhận và xử lý dữ liệu từ topic `smartphoneTopic`.                                                                 |
| `start-all`                                                                                        | Khởi động HDFS (Hadoop Distributed File System) và YARN (công cụ quản lý tài nguyên).                                                       |
| `hbase shell`                                                                                      | Mở **HBase shell** để tương tác với HBase, cơ sở dữ liệu NoSQL dùng lưu trữ dữ liệu thời gian thực.                                         |
| `hbase thrift start`                                                                               | Khởi chạy **Thrift server**, cho phép các ứng dụng bên ngoài kết nối với HBase thông qua API.                                               |

---

#### **2. Batch Layer**
Phần này dùng để xử lý dữ liệu theo lô, thường áp dụng cho các phân tích lớn và lưu trữ dữ liệu lịch sử.

| **Lệnh**                                                                                           | **Chức năng**                                                                                                                                 |
|----------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------|
| `docker-compose up -d`                                                                             | Khởi chạy Apache **Airflow** (công cụ lập lịch trình và điều phối các luồng công việc) bằng Docker.                                          |
| `spark-shell`                                                                                      | Mở **Spark Shell** để thực hiện các tác vụ xử lý dữ liệu lớn theo lô.                                                                        |
| `zookeeper-server-start.bat C:/kafka_2.13_2.6.0/config/zookeeper.properties`                       | (Tương tự Stream Layer) Khởi động **Zookeeper** để quản lý Kafka cluster.                                                                   |
| `kafka-server-start.bat C:/kafka_2.13_2.6.0/config/server.properties`                              | (Tương tự Stream Layer) Khởi động Kafka server để xử lý luồng dữ liệu.                                                                      |
| `kafka-console-producer.bat --topic smartphoneTopic --bootstrap-server localhost:9092`             | (Tương tự Stream Layer) Khởi chạy producer để gửi dữ liệu vào Kafka.                                                                        |
| `kafka-console-consumer.bat --topic smartphoneTopic --from-beginning --bootstrap-server localhost:9092` | (Tương tự Stream Layer) Khởi chạy consumer để nhận dữ liệu từ Kafka.                                                                        |
| `start-all`                                                                                        | Khởi động HDFS và YARN (giống Stream Layer).                                                                                                |

---

### **Tóm tắt các thành phần**

| **Thành phần**      | **Vai trò**                                                                                                                                                          |
|---------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Zookeeper**       | Quản lý trạng thái Kafka Cluster và điều phối các node trong cluster.                                                                                              |
| **Kafka**           | Hệ thống xử lý dữ liệu luồng, dùng để lưu trữ và truyền dữ liệu giữa các hệ thống khác nhau.                                                                         |
| **HDFS**            | Hệ thống lưu trữ phân tán, lưu dữ liệu để xử lý trong Batch Layer.                                                                                                 |
| **YARN**            | Quản lý tài nguyên trong cluster Hadoop (quản lý CPU, RAM cho các tác vụ).                                                                                         |
| **HBase**           | Cơ sở dữ liệu NoSQL lưu trữ dữ liệu thời gian thực (real-time view).                                                                                               |
| **Thrift Server**   | Dịch vụ giao tiếp với HBase qua các giao thức như HTTP hoặc RPC.                                                                                                   |
| **Airflow**         | Điều phối các tác vụ (ví dụ: xử lý theo lô, ETL).                                                                                                                   |
| **Spark**           | Công cụ xử lý dữ liệu lớn, dùng để tính toán và phân tích dữ liệu trong Batch Layer.                                                                                |

---

### **Cách hoạt động tổng quan**
1. **Stream Layer**:
   - Kafka nhận và xử lý dữ liệu thời gian thực (dữ liệu smartphone).
   - Dữ liệu được lưu tạm trong Kafka, rồi ghi vào HBase (lưu trữ real-time view).

2. **Batch Layer**:
   - Dữ liệu từ Kafka hoặc HDFS được xử lý theo lô bằng Spark.
   - Airflow quản lý các quy trình ETL và chuyển kết quả vào cơ sở dữ liệu khác để phân tích.

---

### **Lưu ý**
- **Đường dẫn cụ thể** (`C:/kafka_2.13_2.6.0`) phải được thay đổi tùy vào hệ thống của bạn.
- **Docker Compose**: Airflow chạy trong container, vì vậy cần Docker được cài đặt trước.

Dưới đây là giải thích **cực kỳ đơn giản** về các công cụ trong hệ thống Big Data, được trình bày dưới dạng bảng để dễ hiểu:

---

### **1. Apache Kafka**

|**Công cụ**|**Apache Kafka**|
|---|---|
|**Chức năng chính**|Chuyển dữ liệu giữa các hệ thống theo thời gian thực (giống như bưu điện chuyển thư).|
|**Thành phần**|- **Producer**: Gửi dữ liệu vào hệ thống.- **Consumer**: Lấy dữ liệu ra từ hệ thống.- **Topic**: "Hộp thư" chứa dữ liệu.|
|**Ví dụ dễ hiểu**|Khi bạn nhắn tin qua Messenger, Kafka giống như hệ thống chuyển tin nhắn từ người gửi đến người nhận.|
|**Vai trò**|- Lưu và chuyển dữ liệu.- Xử lý dữ liệu luồng (streaming).|

---

### **2. Zookeeper**

|**Công cụ**|**Apache Zookeeper**|
|---|---|
|**Chức năng chính**|Quản lý các dịch vụ trong hệ thống phân tán (giống như "quản gia" của Kafka).|
|**Vai trò**|- Quản lý thông tin của Kafka Cluster.- Đảm bảo các node (máy tính) trong hệ thống phối hợp nhịp nhàng.|
|**Ví dụ dễ hiểu**|Giống như "điều phối viên" của một đội bóng đá, giúp các cầu thủ phối hợp ăn ý.|

---

### **3. HDFS (Hadoop Distributed File System)**

|**Công cụ**|**HDFS**|
|---|---|
|**Chức năng chính**|Lưu trữ dữ liệu lớn trên nhiều máy tính (giống như một ổ cứng khổng lồ).|
|**Cách hoạt động**|- Dữ liệu được chia nhỏ thành các mảnh nhỏ (blocks).- Các mảnh nhỏ này được lưu trên nhiều máy.|
|**Ví dụ dễ hiểu**|Giống như khi bạn lưu một bộ phim dài trên nhiều USB khác nhau để tiết kiệm dung lượng.|
|**Vai trò**|- Lưu trữ dữ liệu lớn như file log, video, dữ liệu cảm biến,...|

---

### **4. YARN (Yet Another Resource Negotiator)**

|**Công cụ**|**YARN**|
|---|---|
|**Chức năng chính**|Quản lý tài nguyên (CPU, RAM) cho các tác vụ (giống như "quản lý tài nguyên máy chủ").|
|**Cách hoạt động**|- Khi một ứng dụng cần tài nguyên, YARN sẽ cấp phát tài nguyên đó.- Đảm bảo mọi tác vụ đều chạy ổn định.|
|**Ví dụ dễ hiểu**|Giống như quản lý nhà bếp trong nhà hàng, phân chia bếp và nguyên liệu cho từng món ăn.|

---

### **5. HBase**

|**Công cụ**|**HBase**|
|---|---|
|**Chức năng chính**|Cơ sở dữ liệu NoSQL, lưu trữ và truy vấn dữ liệu lớn theo thời gian thực.|
|**Cách hoạt động**|- Lưu dữ liệu dưới dạng bảng, nhưng hỗ trợ lưu trữ và truy vấn nhanh chóng.- Tích hợp tốt với HDFS.|
|**Ví dụ dễ hiểu**|Giống như một bảng tính Excel khổng lồ, có thể ghi và đọc dữ liệu cực nhanh.|
|**Vai trò**|Lưu trữ dữ liệu thời gian thực như giá cổ phiếu, cảm biến IoT,...|

---

### **6. Apache Spark**

|**Công cụ**|**Apache Spark**|
|---|---|
|**Chức năng chính**|Xử lý dữ liệu lớn cực nhanh, hỗ trợ cả thời gian thực và theo lô (batch processing).|
|**Thành phần chính**|- Spark Core: Xử lý dữ liệu.- Spark SQL: Truy vấn dữ liệu dạng SQL.- Spark Streaming: Xử lý dữ liệu thời gian thực.|
|**Ví dụ dễ hiểu**|Giống như một đầu bếp tốc độ cao, có thể nấu nhiều món ăn (dữ liệu) trong thời gian ngắn.|
|**Vai trò**|- Phân tích dữ liệu lớn.- Tính toán nhanh chóng.|

---

### **7. Apache Airflow**

|**Công cụ**|**Apache Airflow**|
|---|---|
|**Chức năng chính**|Quản lý và tự động hóa các luồng công việc (workflow).|
|**Cách hoạt động**|- Bạn định nghĩa các tác vụ (tasks) và thứ tự chạy của chúng.- Airflow sẽ tự động chạy các tác vụ này theo lịch trình.|
|**Ví dụ dễ hiểu**|Giống như một người quản lý dự án, sắp xếp công việc cho từng thành viên và đảm bảo mọi thứ đúng hạn.|
|**Vai trò**|- Lập lịch và điều phối các tác vụ ETL (Extract, Transform, Load).|

---

### **Tóm tắt bảng tổng quan**

|**Công cụ**|**Vai trò chính**|**Ví dụ dễ hiểu**|
|---|---|---|
|Kafka|Chuyển dữ liệu giữa các hệ thống theo thời gian thực.|Chuyển tin nhắn Messenger giữa người gửi và người nhận.|
|Zookeeper|Điều phối và quản lý Kafka cluster.|Quản lý đội bóng đá để các cầu thủ phối hợp hiệu quả.|
|HDFS|Lưu trữ dữ liệu lớn trên nhiều máy.|Lưu file phim lớn trên nhiều USB khác nhau.|
|YARN|Quản lý tài nguyên (CPU, RAM) cho các ứng dụng.|Quản lý nhà bếp, phân chia bếp cho từng món ăn.|
|HBase|Lưu trữ và truy vấn dữ liệu lớn theo thời gian thực.|Một bảng tính Excel khổng lồ, truy vấn siêu nhanh.|
|Spark|Xử lý dữ liệu lớn nhanh chóng, hỗ trợ thời gian thực và theo lô.|Đầu bếp tốc độ cao nấu nhiều món cùng lúc.|
|Airflow|Quản lý và tự động hóa các luồng công việc.|Quản lý dự án, sắp xếp và tự động hóa công việc.|

---

Nếu bạn cần thêm thông tin hoặc giải thích cụ thể về cách sử dụng, mình sẵn sàng hỗ trợ! 😊


Dưới đây là bảng tổng hợp thông tin các **port** trong HDFS và chức năng của chúng:

|**Công cụ/Thành phần**|**Port**|**Chức năng**|
|---|---|---|
|**NameNode RPC**|`8020`|Giao tiếp chính giữa NameNode và client hoặc các DataNode.|
|**NameNode Web Interface**|`9870`|Giao diện quản trị web của NameNode (truy cập thông tin cluster qua trình duyệt).|
|**DataNode IPC**|`50020`|Giao tiếp chính giữa DataNode và NameNode.|
|**DataNode Web Interface**|`9864`|Giao diện quản trị web của DataNode (thông tin block, dung lượng).|
|**Secondary NameNode Web**|`9868`|Giao diện web của Secondary NameNode (nếu có).|
|**YARN ResourceManager RPC**|`8032`|Giao tiếp giữa ResourceManager và các NodeManager hoặc client (trong YARN).|
|**YARN Web Interface**|`8088`|Giao diện web quản trị ResourceManager.|
|**NodeManager Web Interface**|`8042`|Giao diện web của NodeManager (trong YARN).|

### Lưu ý:

1. Các port trên có thể được thay đổi trong file cấu hình của Hadoop (`core-site.xml`, `hdfs-site.xml`, `yarn-site.xml`).
2. Mặc định, tất cả giao diện web và giao tiếp RPC đều hoạt động trên **HTTP** hoặc **HTTPS** nếu được bật.
3. Đảm bảo các port được mở trong tường lửa để các thành phần của cluster có thể kết nối được.

Nếu cần thêm thông tin chi tiết về cách cấu hình, hãy cho mình biết nhé!


---
#### **Stream Layer**

[](https://github.com/DoanNgocCuong/Big-Data-Project_2#1-stream-layer)

- Start Apache zookeeper

```batchfile
zookeeper-server-start.bat C:/kafka_2.13_2.6.0/config/zookeeper.properties
```

- Start Kafka server

```batchfile
kafka-server-start.bat C:/kafka_2.13_2.6.0/config/server.properties
```

- Create Kafka topic

```batchfile
kafka-topics.bat --create --topic smartphoneTopic --bootstrap-server localhost:9092
```

- Run the kafka producer

```batchfile
kafka-console-producer.bat --topic smartphoneTopic --bootstrap-server localhost:9092
```

- Run the kafka consumer

```batchfile
kafka-console-consumer.bat --topic smartphoneTopic --from-beginning --bootstrap-server localhost:9092
```

- Start HDFS and yarn (start-all or start-dfs and start-yarn)

```batchfile
start-all  
```

- Start Hbase

```batchfile
start-hbase  
```

- Run thrift server (for Hbase)

```batchfile
hbase thrift start
```

after all this run `stream_pipeline.py` script.

and then open the spring boot appliation in your idea and run it (you can access to the web app locally on `localhost:8081/`)


### **Bảng tóm tắt các bước chạy Stream Layer**

|**Bước**|**Lệnh thực thi**|**Mô tả**|
|---|---|---|
|**1. Start Apache Zookeeper**|`zookeeper-server-start.bat C:/kafka_2.13_2.6.0/config/zookeeper.properties`|Khởi chạy Zookeeper để quản lý Kafka.|
|**2. Start Kafka Server**|`kafka-server-start.bat C:/kafka_2.13_2.6.0/config/server.properties`|Khởi chạy Kafka Broker để xử lý message.|
|**3. Create Kafka Topic**|`kafka-topics.bat --create --topic smartphoneTopic --bootstrap-server localhost:9092`|Tạo một topic Kafka tên là `smartphoneTopic` để lưu trữ message.|
|**4. Run Kafka Producer**|`kafka-console-producer.bat --topic smartphoneTopic --bootstrap-server localhost:9092`|Chạy producer để gửi message tới topic `smartphoneTopic`.|
|**5. Run Kafka Consumer**|`kafka-console-consumer.bat --topic smartphoneTopic --from-beginning --bootstrap-server localhost:9092`|Chạy consumer để nhận message từ topic `smartphoneTopic`.|
|**6. Start HDFS and YARN**|`start-all`|Khởi động HDFS và YARN để quản lý lưu trữ phân tán và xử lý dữ liệu.|
|**7. Start HBase**|`start-hbase`|Khởi động HBase để lưu trữ dữ liệu phi cấu trúc.|
|**8. Run Thrift Server**|`hbase thrift start`|Chạy Thrift Server để cung cấp giao diện REST hoặc giao tiếp qua RPC cho HBase.|
|**9. Run Python Pipeline**|`python stream_pipeline.py`|Chạy script `stream_pipeline.py` để xử lý dữ liệu stream từ Kafka và lưu trữ vào HDFS hoặc HBase.|
|**10. Start Spring Boot App**|Chạy Spring Boot App trong IDE. Truy cập tại `http://localhost:8081/`.|Khởi chạy ứng dụng Spring Boot để hiển thị dashboard và xử lý yêu cầu từ người dùng.|

### **Ghi chú**

- Đảm bảo các công cụ như Kafka, Zookeeper, HBase, HDFS được cài đặt và cấu hình đúng.
- Kiểm tra log nếu gặp lỗi khi chạy từng bước.
Dưới đây là danh sách các **port** để kiểm tra giao diện người dùng (UI) của các thành phần:

| **Thành phần**           | **Port**        | **URL để truy cập UI**           | **Mô tả giao diện**                                                                    |
| ------------------------ | --------------- | -------------------------------- | -------------------------------------------------------------------------------------- |
| **Kafka Control Center** | 9021            | `http://localhost:9021`          | Quản lý Kafka, giám sát topic, producer và consumer.                                   |
| **HDFS (NameNode)**      | 9870            | `http://localhost:9870`          | Theo dõi trạng thái của HDFS NameNode.                                                 |
| **HBase Thrift Server**  | 9095            | Cần cấu hình thêm nếu muốn UI    | Giao diện quản lý HBase qua Thrift (thường phải triển khai thêm một giao diện cụ thể). |
| **Airflow Web UI**       | 8080            | `http://localhost:8080`          | Xem và quản lý DAG trong Apache Airflow.                                               |
| **Spring Boot App**      | 8081            | `http://localhost:8081`          | Giao diện chính của ứng dụng, hiển thị dashboard và kết quả xử lý dữ liệu.             |
| **Spark Master UI**      | 9090            | `http://localhost:9090`          | Giám sát các tác vụ và worker của Spark Master.                                        |
| **Spark Worker UI**      | 8080 (mặc định) | `http://localhost:<worker-port>` | Xem thông tin chi tiết các worker.                                                     |
| **Cassandra DB**         | Không có UI     | N/A                              | Cassandra không cung cấp UI mặc định, có thể sử dụng công cụ bên thứ ba như DataStax.  |
|                          |                 |                                  |                                                                                        |
|                          |                 |                                  |                                                                                        |
|                          |                 |                                  |                                                                                        |
|                          |                 |                                  |                                                                                        |

### **Lưu ý:**

- Nếu gặp lỗi truy cập, kiểm tra cấu hình trong file `docker-compose.yml` để đảm bảo các port đã được ánh xạ chính xác.
- Đảm bảo rằng các dịch vụ tương ứng đã được khởi động thành công trước khi truy cập UI.

Dựa vào logs, tôi thấy các services đang chạy và lắng nghe trên các ports sau:

1. **HBase Master**:
```
- 16010 (Web UI): "Jetty bound to port 16010"
- 16020 (RPC): "Bind to /172.25.0.5:16020"
```

2. **YARN ResourceManager**:
```
- 8088 (Web UI): "Jetty bound to port 8088"
- 8032 (Client): "IPC Server listener on 8032"
- 8033 (Admin): "IPC Server listener on 8033"
```

3. **YARN NodeManager**:
```
- 8042 (Web UI): "Started ServerConnector...{0.0.0.0:8042}"
```

4. **Hadoop NameNode**:
```
- 9000 (RPC): Datanode đang cố kết nối tới "hadoop-namenode:9000"
```

5. **Zookeeper**:
```
- 2181: Các kết nối ZK đang hoạt động
```

So sánh với file docker-compose:
```yaml
hadoop-namenode:
  ports:
    - "9870:9870"  # Web UI
    - "9000:9000"  # RPC
    - "8020:8020"  # IPC

yarn-resourcemanager:
  ports:
    - "8088:8088"  # Web UI

hbase-master:
  ports:
    - "16000:16000"  # HBase Master RPC
    - "16010:16010"  # HBase Master Web UI
    - "16020:16020"  # HBase RegionServer RPC
    - "16030:16030"  # HBase RegionServer Web UI
```

Tất cả các port cần thiết đều đã được expose và đang hoạt động. Tuy nhiên, có một số warning và lỗi cần lưu ý:

1. HBase Master có warning:
```
WARN  [master/ec326e803d17:16000:becomeActiveMaster] wal.WALProcedureStore: Unable to read tracker
```

2. Hadoop DataNode có vấn đề kết nối:
```
WARN datanode.DataNode: Problem connecting to server: hadoop-namenode/172.25.0.3:9000
```

Để khắc phục, bạn có thể thử:
1. Xóa volumes và restart:
```bash
docker-compose down -v
docker-compose up --build
```

2. Kiểm tra network connectivity giữa các containers:
```bash
docker network inspect stream-network
```


--- 
### Stream layer 

#### **Stream Layer**

[](https://github.com/DoanNgocCuong/Big-Data-Project_2#1-stream-layer)

- Start Apache zookeeper

```batchfile
zookeeper-server-start.bat C:/kafka_2.13_2.6.0/config/zookeeper.properties
```

- Start Kafka server

```batchfile
kafka-server-start.bat C:/kafka_2.13_2.6.0/config/server.properties
```

- Create Kafka topic

```batchfile
kafka-topics.bat --create --topic smartphoneTopic --bootstrap-server localhost:9092
```

- Run the kafka producer

```batchfile
kafka-console-producer.bat --topic smartphoneTopic --bootstrap-server localhost:9092
```

- Run the kafka consumer

```batchfile
kafka-console-consumer.bat --topic smartphoneTopic --from-beginning --bootstrap-server localhost:9092
```

- Start HDFS and yarn (start-all or start-dfs and start-yarn)

```batchfile
start-all  
```

- Start Hbase

```batchfile
start-hbase  
```

- Run thrift server (for Hbase)

```batchfile
hbase thrift start
```

after all this run `stream_pipeline.py` script.

and then open the spring boot appliation in your idea and run it (you can access to the web app locally on `localhost:8081/`)


Ah, để tôi giải thích về các ports và UI:

1. **Kafka (9092)**:
- Port 9092 là port để kết nối tới Kafka broker, KHÔNG có UI
- Để xem UI của Kafka, bạn cần thêm Kafka Manager (CMAK) hoặc Kafka UI:

```yaml
  # Thêm Kafka UI
  kafka-ui:
    image: provectuslabs/kafka-ui
    container_name: kafka-ui
    ports:
      - "8080:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
    depends_on:
      - kafka
    networks:
      - stream-network
```

2. **HBase Thrift (9090)**:
- Port 9090 chỉ là port API, KHÔNG có UI
- Để xem UI của HBase, dùng port 16010 (HBase Master Web UI)

3. **Các UI có sẵn**:
```yaml
# Các ports có UI:
- HBase Master UI: localhost:16010
- HBase RegionServer UI: localhost:16030
- Zookeeper Admin UI: localhost:8080 (nếu được cấu hình)
```

4. **Thêm monitoring tools**:
```yaml
  # Grafana để monitoring
  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    networks:
      - stream-network
```

Bạn có muốn tôi cập nhật lại file docker-compose với các UI tools không?





OK, đây là file docker-compose-stream.yml hoàn chỉnh:

```yaml
version: '3.8'

services:
  # 1. Zookeeper Service
  zookeeper:
    image: wurstmeister/zookeeper:3.4.6
    container_name: zookeeper
    ports:
      - "2181:2181"
    networks:
      - stream-network
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 30s
      timeout: 10s
      retries: 3

  # 2. Kafka Service
  kafka:
    image: wurstmeister/kafka:2.13-2.6.0
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CREATE_TOPICS: "smartphoneTopic:1:1"
    depends_on:
      zookeeper:
        condition: service_healthy
    networks:
      - stream-network

  # 3. Hadoop NameNode
  hadoop-namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-namenode
    ports:
      - "9870:9870"  # Web UI
      - "9000:9000"  # RPC
    environment:
      - CLUSTER_NAME=test-cluster
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    networks:
      - stream-network

  # 4. Hadoop DataNode
  hadoop-datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-datanode
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      - SERVICE_PRECONDITION=hadoop-namenode:9870
    depends_on:
      - hadoop-namenode
    networks:
      - stream-network

  # 5. YARN ResourceManager
  yarn-resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: yarn-resourcemanager
    ports:
      - "8088:8088"  # Web UI
    depends_on:
      - hadoop-namenode
    networks:
      - stream-network

  # 6. YARN NodeManager
  yarn-nodemanager:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: yarn-nodemanager
    depends_on:
      - yarn-resourcemanager
    networks:
      - stream-network

  # 7. HBase (All-in-one with Thrift)
  hbase:
    image: dajobe/hbase
    container_name: hbase
    ports:
      - "16000:16000"  # Master RPC
      - "16010:16010"  # Master Web UI
      - "16020:16020"  # RegionServer RPC
      - "16030:16030"  # RegionServer Web UI
      - "9090:9090"    # Thrift Server
    environment:
      HBASE_CONF_hbase_zookeeper_quorum: zookeeper
      HBASE_CONF_hbase_zookeeper_property_clientPort: 2181
      HBASE_MANAGES_ZK: "false"
      HBASE_CONF_hbase_master_port: 16000
      HBASE_CONF_hbase_master_info_port: 16010
      HBASE_CONF_hbase_regionserver_port: 16020
      HBASE_CONF_hbase_regionserver_info_port: 16030
      HBASE_CONF_hbase_thrift_port: 9090
    volumes:
      - hbase_data:/data
    depends_on:
      - zookeeper
      - hadoop-namenode
    networks:
      - stream-network
    command: ["sh", "-c", "start-hbase.sh && hbase thrift start -p 9090 && tail -f /dev/null"]

  # 8. Python Stream Pipeline
  python-app:
    image: python:3.8
    container_name: python-app
    volumes:
      - ./stream_pipeline.py:/app/stream_pipeline.py
      - ./requirements.txt:/app/requirements.txt
    working_dir: /app
    command: >
      bash -c "pip install -r requirements.txt &&
               python stream_pipeline.py"
    depends_on:
      - kafka
      - hbase
    networks:
      - stream-network

  # 9. Spring Boot Application
  spring-boot-app:
    image: openjdk:11-jre-slim
    container_name: spring-boot-app
    ports:
      - "8081:8081"
    volumes:
      - ./app.jar:/app/app.jar
    working_dir: /app
    command: ["java", "-jar", "app.jar"]
    depends_on:
      - kafka
      - hbase
      - python-app
    networks:
      - stream-network

  # 10. Flask Application (Alternative Web UI)
  flask-app:
    image: python:3.8
    container_name: flask-app
    ports:
      - "5000:5000"
    volumes:
      - ./flask_app:/app
    working_dir: /app
    command: >
      bash -c "pip install -r requirements.txt &&
               python app.py"
    depends_on:
      - python-app
    networks:
      - stream-network

networks:
  stream-network:
    driver: bridge

volumes:
  hadoop_namenode:
  hadoop_datanode:
  hbase_data:
```

Để chạy:

```bash
# Clone repository
git clone https://github.com/aymane-maghouti/Big-Data-Project

# Di chuyển vào thư mục
cd Big-Data-Project

# Dừng và xóa containers cũ
docker-compose down -v

# Build và chạy
docker-compose -f docker-compose-stream.yml up --build
```

Sau khi chạy xong, bạn có thể truy cập:
1. Spring Boot UI: `http://localhost:8081`
2. Flask UI: `http://localhost:5000`
3. HBase UI: `http://localhost:16010`
4. Hadoop NameNode UI: `http://localhost:9870`
5. YARN ResourceManager UI: `http://localhost:8088`

Lưu ý: Đảm bảo các file sau đã tồn tại trong thư mục:
- `stream_pipeline.py`
- `requirements.txt`
- `app.jar` (Spring Boot application)
- Thư mục `flask_app` với `app.py`




Dựa vào cấu trúc project, ta cần tổ chức thư mục như sau:

````
Big-Data-Project_2/              # Thư mục gốc
│
├── docker-compose-stream.yml    # File docker-compose
│
├── requirements.txt             # Dependencies cho Python
│
└── Main/
    └── Lambda/
        ├── producer.py          # Producer script
        │
        ├── ML_operations/       # ML models
        │   └── xgb_model.pkl
        │
        ├── Stream_data/         # Data streaming
        │   ├── stream_data.csv
        │   └── stream_data.py
        │
        ├── Stream_layer/        # Stream processing
        │   ├── insert_data_hbase.py
        │   ├── ML_consumer.py
        │   ├── stream_pipeline.py
        │   └── __init__.py
        │
        └── real_time_web_app(Flask)/    # Flask web app
            ├── app.py
            ├── get_Data_from_hbase.py
            ├── static/
            │   ├── css/
            │   │   └── style.css
            │   └── js/
            │       └── script.js
            └── templates/
                └── index.html
````

Tạo cấu trúc thư mục:

````bash
# Tạo thư mục gốc
mkdir -p Big-Data-Project_2

# Di chuyển vào thư mục gốc
cd Big-Data-Project_2

# Tạo requirements.txt
cat > requirements.txt << EOF
kafka-python
happybase
pandas
scikit-learn
numpy
thriftpy2
flask
EOF

# Tạo cấu trúc thư mục
mkdir -p Main/Lambda/{ML_operations,Stream_data,Stream_layer,real_time_web_app\(Flask\)/static/{css,js},real_time_web_app\(Flask\)/templates}

# Copy các file từ repository gốc
cp -r ../Big-Data-Project/Main/Lambda/* Main/Lambda/

# Copy docker-compose
cp docker-compose-stream.yml .
````

Kiểm tra cấu trúc:
````bash
tree Big-Data-Project_2
````
```
Main/
└── Lambda/
    ├── Stream_layer/
    │   ├── Dockerfile.stream
    │   ├── requirements.stream.txt
    │   └── stream_pipeline.py
    │
    └── real_time_web_app(Flask)/
        ├── Dockerfile.flask
        ├── requirements.flask.txt
        └── app.py
```


### **Tóm tắt bảng câu hỏi - câu trả lời**

| **Nhiệm vụ**               | **Lệnh / Hướng dẫn**                                                                                    |
| -------------------------- | ------------------------------------------------------------------------------------------------------- |
| Clone repository           | `git clone https://github.com/aymane-maghouti/Big-Data-Project`                                         |
| Start Zookeeper            | `zookeeper-server-start.bat C:/kafka_2.13_2.6.0/config/zookeeper.properties`                            |
| Start Kafka Server         | `kafka-server-start.bat C:/kafka_2.13_2.6.0/config/server.properties`                                   |
| Create Kafka Topic         | `kafka-topics.bat --create --topic smartphoneTopic --bootstrap-server localhost:9092`                   |
| Run Kafka Producer         | `kafka-console-producer.bat --topic smartphoneTopic --bootstrap-server localhost:9092`                  |
| Run Kafka Consumer         | `kafka-console-consumer.bat --topic smartphoneTopic --from-beginning --bootstrap-server localhost:9092` |
| Start HDFS and YARN        | `start-all` hoặc `start-dfs` và `start-yarn`                                                            |
| Start HBase                | `start-hbase`                                                                                           |
| Start HBase Thrift Server  | `hbase thrift start`                                                                                    |
| Run Stream Pipeline Script | `stream_pipeline.py`                                                                                    |
| Open Spring Boot App       | Mở trong IDE và truy cập `http://localhost:8081/`.                                                      |
| Flask Web App              | Được phát triển riêng, xem trong video demo.                                                            |