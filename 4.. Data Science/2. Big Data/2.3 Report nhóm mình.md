- [DoanNgocCuong/Big-Data-Project3-RealtimeStreamingEngineering](https://github.com/DoanNgocCuong/Big-Data-Project3-RealtimeStreamingEngineering)

![[Pasted image 20241216091835.png]]

Questions: 
1. What types of Dataset Processing or not do you save in to Hadoops ? - short answer
2. Batch Pipeline: 
- Data from Yelp Dataset. 
- To setup Batch Pipeline: We run docker-compose that file will start  sequence each technology by pulling images for docker hub. 
- 1. We setup Kafka batch:  (Apach Kafka Consumer) will get data from Kafka Producer and 
- 1. Next we start Airflow and Dags, we can access 8080 for view Data Airflow. After setup processing Kafka and Airflow finished, we can view at UI Airflow: Data will sent  
- 2. The next step, we set up Apach Spark Worker 8081 and Apach Spark Master porrt 7077 internal and 9090:8080 external. We access UI for view full information about Spark of pipelin. 
- 3. 